{
  "S01": {
    "thresh_0.090_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.783832311630249,
            "relevance": 3
          },
          {
            "score": 0.7830327749252319,
            "relevance": 4
          },
          {
            "score": 0.7828741073608398,
            "relevance": 5
          },
          {
            "score": 0.78242427110672,
            "relevance": 2
          },
          {
            "score": 0.7819439172744751,
            "relevance": 1
          },
          {
            "score": 0.7816896438598633,
            "relevance": 2
          },
          {
            "score": 0.775809645652771,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5505441723392566
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.49492815136909485,
            "relevance": 3
          },
          {
            "score": 0.45079904794692993,
            "relevance": 2
          },
          {
            "score": 0.4463385045528412,
            "relevance": 5
          },
          {
            "score": 0.4454416036605835,
            "relevance": 4
          },
          {
            "score": 0.44448405504226685,
            "relevance": 2
          },
          {
            "score": 0.4392605125904083,
            "relevance": 5
          },
          {
            "score": 0.419933944940567,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.090_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.783832311630249,
            "relevance": 3
          },
          {
            "score": 0.7830327749252319,
            "relevance": 4
          },
          {
            "score": 0.7828741073608398,
            "relevance": 5
          },
          {
            "score": 0.78242427110672,
            "relevance": 2
          },
          {
            "score": 0.7819439172744751,
            "relevance": 1
          },
          {
            "score": 0.7816896438598633,
            "relevance": 2
          },
          {
            "score": 0.775809645652771,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5505441723392566
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6478023529052734,
            "relevance": 3
          },
          {
            "score": 0.5810494422912598,
            "relevance": 2
          },
          {
            "score": 0.5728727579116821,
            "relevance": 5
          },
          {
            "score": 0.5613601207733154,
            "relevance": 2
          },
          {
            "score": 0.5612724423408508,
            "relevance": 4
          },
          {
            "score": 0.5561445951461792,
            "relevance": 5
          },
          {
            "score": 0.5248171091079712,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.090_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.783832311630249,
            "relevance": 3
          },
          {
            "score": 0.7830327749252319,
            "relevance": 4
          },
          {
            "score": 0.7828741073608398,
            "relevance": 5
          },
          {
            "score": 0.78242427110672,
            "relevance": 2
          },
          {
            "score": 0.7819439172744751,
            "relevance": 1
          },
          {
            "score": 0.7816896438598633,
            "relevance": 2
          },
          {
            "score": 0.775809645652771,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5505441723392566
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7247216701507568,
            "relevance": 3
          },
          {
            "score": 0.6504279375076294,
            "relevance": 2
          },
          {
            "score": 0.6407963037490845,
            "relevance": 5
          },
          {
            "score": 0.6252669095993042,
            "relevance": 2
          },
          {
            "score": 0.6247255206108093,
            "relevance": 4
          },
          {
            "score": 0.620055079460144,
            "relevance": 5
          },
          {
            "score": 0.583315372467041,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.090_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.783832311630249,
            "relevance": 3
          },
          {
            "score": 0.7830327749252319,
            "relevance": 4
          },
          {
            "score": 0.7828741073608398,
            "relevance": 5
          },
          {
            "score": 0.78242427110672,
            "relevance": 2
          },
          {
            "score": 0.7819439172744751,
            "relevance": 1
          },
          {
            "score": 0.7816896438598633,
            "relevance": 2
          },
          {
            "score": 0.775809645652771,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5505441723392566
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8083317279815674,
            "relevance": 3
          },
          {
            "score": 0.7307411432266235,
            "relevance": 2
          },
          {
            "score": 0.7201191186904907,
            "relevance": 5
          },
          {
            "score": 0.7014909982681274,
            "relevance": 2
          },
          {
            "score": 0.7005706429481506,
            "relevance": 4
          },
          {
            "score": 0.696281909942627,
            "relevance": 5
          },
          {
            "score": 0.6547164916992188,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.100_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.783832311630249,
            "relevance": 3
          },
          {
            "score": 0.7830327749252319,
            "relevance": 4
          },
          {
            "score": 0.7828741073608398,
            "relevance": 5
          },
          {
            "score": 0.78242427110672,
            "relevance": 2
          },
          {
            "score": 0.7819439172744751,
            "relevance": 1
          },
          {
            "score": 0.7816896438598633,
            "relevance": 2
          },
          {
            "score": 0.775809645652771,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5505441723392566
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.49567145109176636,
            "relevance": 3
          },
          {
            "score": 0.4513029158115387,
            "relevance": 2
          },
          {
            "score": 0.4467974305152893,
            "relevance": 5
          },
          {
            "score": 0.4457111656665802,
            "relevance": 4
          },
          {
            "score": 0.44477903842926025,
            "relevance": 2
          },
          {
            "score": 0.43958935141563416,
            "relevance": 5
          },
          {
            "score": 0.420184850692749,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.100_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.783832311630249,
            "relevance": 3
          },
          {
            "score": 0.7830327749252319,
            "relevance": 4
          },
          {
            "score": 0.7828741073608398,
            "relevance": 5
          },
          {
            "score": 0.78242427110672,
            "relevance": 2
          },
          {
            "score": 0.7819439172744751,
            "relevance": 1
          },
          {
            "score": 0.7816896438598633,
            "relevance": 2
          },
          {
            "score": 0.775809645652771,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5505441723392566
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6370209455490112,
            "relevance": 3
          },
          {
            "score": 0.5681271553039551,
            "relevance": 2
          },
          {
            "score": 0.5596386194229126,
            "relevance": 5
          },
          {
            "score": 0.5473212003707886,
            "relevance": 2
          },
          {
            "score": 0.5471429824829102,
            "relevance": 4
          },
          {
            "score": 0.542140007019043,
            "relevance": 5
          },
          {
            "score": 0.510035514831543,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.100_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.783832311630249,
            "relevance": 3
          },
          {
            "score": 0.7830327749252319,
            "relevance": 4
          },
          {
            "score": 0.7828741073608398,
            "relevance": 5
          },
          {
            "score": 0.78242427110672,
            "relevance": 2
          },
          {
            "score": 0.7819439172744751,
            "relevance": 1
          },
          {
            "score": 0.7816896438598633,
            "relevance": 2
          },
          {
            "score": 0.775809645652771,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5505441723392566
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7104042768478394,
            "relevance": 3
          },
          {
            "score": 0.6320116519927979,
            "relevance": 2
          },
          {
            "score": 0.6217746734619141,
            "relevance": 5
          },
          {
            "score": 0.6047152280807495,
            "relevance": 2
          },
          {
            "score": 0.6040080785751343,
            "relevance": 4
          },
          {
            "score": 0.5995382070541382,
            "relevance": 5
          },
          {
            "score": 0.5611993670463562,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.100_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.783832311630249,
            "relevance": 3
          },
          {
            "score": 0.7830327749252319,
            "relevance": 4
          },
          {
            "score": 0.7828741073608398,
            "relevance": 5
          },
          {
            "score": 0.78242427110672,
            "relevance": 2
          },
          {
            "score": 0.7819439172744751,
            "relevance": 1
          },
          {
            "score": 0.7816896438598633,
            "relevance": 2
          },
          {
            "score": 0.775809645652771,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5505441723392566
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.792951226234436,
            "relevance": 3
          },
          {
            "score": 0.7082172632217407,
            "relevance": 2
          },
          {
            "score": 0.6964915990829468,
            "relevance": 5
          },
          {
            "score": 0.6750580072402954,
            "relevance": 2
          },
          {
            "score": 0.673836350440979,
            "relevance": 4
          },
          {
            "score": 0.6698850393295288,
            "relevance": 5
          },
          {
            "score": 0.6251985430717468,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.110_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.783832311630249,
            "relevance": 3
          },
          {
            "score": 0.7830327749252319,
            "relevance": 4
          },
          {
            "score": 0.7828741073608398,
            "relevance": 5
          },
          {
            "score": 0.78242427110672,
            "relevance": 2
          },
          {
            "score": 0.7819439172744751,
            "relevance": 1
          },
          {
            "score": 0.7816896438598633,
            "relevance": 2
          },
          {
            "score": 0.775809645652771,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5505441723392566
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.49607330560684204,
            "relevance": 3
          },
          {
            "score": 0.4515322744846344,
            "relevance": 2
          },
          {
            "score": 0.4469873011112213,
            "relevance": 5
          },
          {
            "score": 0.44570156931877136,
            "relevance": 4
          },
          {
            "score": 0.4447981119155884,
            "relevance": 2
          },
          {
            "score": 0.43965378403663635,
            "relevance": 5
          },
          {
            "score": 0.4202013909816742,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.110_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.783832311630249,
            "relevance": 3
          },
          {
            "score": 0.7830327749252319,
            "relevance": 4
          },
          {
            "score": 0.7828741073608398,
            "relevance": 5
          },
          {
            "score": 0.78242427110672,
            "relevance": 2
          },
          {
            "score": 0.7819439172744751,
            "relevance": 1
          },
          {
            "score": 0.7816896438598633,
            "relevance": 2
          },
          {
            "score": 0.775809645652771,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5505441723392566
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6248660683631897,
            "relevance": 3
          },
          {
            "score": 0.5540194511413574,
            "relevance": 2
          },
          {
            "score": 0.5452480316162109,
            "relevance": 5
          },
          {
            "score": 0.5321831107139587,
            "relevance": 2
          },
          {
            "score": 0.5319185256958008,
            "relevance": 4
          },
          {
            "score": 0.527047872543335,
            "relevance": 5
          },
          {
            "score": 0.49428287148475647,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.110_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.783832311630249,
            "relevance": 3
          },
          {
            "score": 0.7830327749252319,
            "relevance": 4
          },
          {
            "score": 0.7828741073608398,
            "relevance": 5
          },
          {
            "score": 0.78242427110672,
            "relevance": 2
          },
          {
            "score": 0.7819439172744751,
            "relevance": 1
          },
          {
            "score": 0.7816896438598633,
            "relevance": 2
          },
          {
            "score": 0.775809645652771,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5505441723392566
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6936801075935364,
            "relevance": 3
          },
          {
            "score": 0.6113872528076172,
            "relevance": 2
          },
          {
            "score": 0.600584864616394,
            "relevance": 5
          },
          {
            "score": 0.5820927023887634,
            "relevance": 2
          },
          {
            "score": 0.5812294483184814,
            "relevance": 4
          },
          {
            "score": 0.5769621133804321,
            "relevance": 5
          },
          {
            "score": 0.5372104644775391,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.110_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.783832311630249,
            "relevance": 3
          },
          {
            "score": 0.7830327749252319,
            "relevance": 4
          },
          {
            "score": 0.7828741073608398,
            "relevance": 5
          },
          {
            "score": 0.78242427110672,
            "relevance": 2
          },
          {
            "score": 0.7819439172744751,
            "relevance": 1
          },
          {
            "score": 0.7816896438598633,
            "relevance": 2
          },
          {
            "score": 0.775809645652771,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5505441723392566
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.773618757724762,
            "relevance": 3
          },
          {
            "score": 0.6817048788070679,
            "relevance": 2
          },
          {
            "score": 0.6688997745513916,
            "relevance": 5
          },
          {
            "score": 0.6447475552558899,
            "relevance": 2
          },
          {
            "score": 0.643235445022583,
            "relevance": 4
          },
          {
            "score": 0.6396218538284302,
            "relevance": 5
          },
          {
            "score": 0.5920462608337402,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.120_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.783832311630249,
            "relevance": 3
          },
          {
            "score": 0.7830327749252319,
            "relevance": 4
          },
          {
            "score": 0.7828741073608398,
            "relevance": 5
          },
          {
            "score": 0.78242427110672,
            "relevance": 2
          },
          {
            "score": 0.7819439172744751,
            "relevance": 1
          },
          {
            "score": 0.7816896438598633,
            "relevance": 2
          },
          {
            "score": 0.775809645652771,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5505441723392566
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.4961126148700714,
            "relevance": 3
          },
          {
            "score": 0.45146653056144714,
            "relevance": 2
          },
          {
            "score": 0.44688767194747925,
            "relevance": 5
          },
          {
            "score": 0.445393443107605,
            "relevance": 4
          },
          {
            "score": 0.44452160596847534,
            "relevance": 2
          },
          {
            "score": 0.43943384289741516,
            "relevance": 5
          },
          {
            "score": 0.4199635088443756,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.120_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.783832311630249,
            "relevance": 3
          },
          {
            "score": 0.7830327749252319,
            "relevance": 4
          },
          {
            "score": 0.7828741073608398,
            "relevance": 5
          },
          {
            "score": 0.78242427110672,
            "relevance": 2
          },
          {
            "score": 0.7819439172744751,
            "relevance": 1
          },
          {
            "score": 0.7816896438598633,
            "relevance": 2
          },
          {
            "score": 0.775809645652771,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5505441723392566
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6113730669021606,
            "relevance": 3
          },
          {
            "score": 0.538793683052063,
            "relevance": 2
          },
          {
            "score": 0.5297729969024658,
            "relevance": 5
          },
          {
            "score": 0.5160304307937622,
            "relevance": 2
          },
          {
            "score": 0.5156848430633545,
            "relevance": 4
          },
          {
            "score": 0.5109521150588989,
            "relevance": 5
          },
          {
            "score": 0.4776553213596344,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.120_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.783832311630249,
            "relevance": 3
          },
          {
            "score": 0.7830327749252319,
            "relevance": 4
          },
          {
            "score": 0.7828741073608398,
            "relevance": 5
          },
          {
            "score": 0.78242427110672,
            "relevance": 2
          },
          {
            "score": 0.7819439172744751,
            "relevance": 1
          },
          {
            "score": 0.7816896438598633,
            "relevance": 2
          },
          {
            "score": 0.775809645652771,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5505441723392566
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6745771169662476,
            "relevance": 3
          },
          {
            "score": 0.5886737108230591,
            "relevance": 2
          },
          {
            "score": 0.5773602724075317,
            "relevance": 5
          },
          {
            "score": 0.5575698018074036,
            "relevance": 2
          },
          {
            "score": 0.5565632581710815,
            "relevance": 4
          },
          {
            "score": 0.5524965524673462,
            "relevance": 5
          },
          {
            "score": 0.5115585327148438,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.120_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.783832311630249,
            "relevance": 3
          },
          {
            "score": 0.7830327749252319,
            "relevance": 4
          },
          {
            "score": 0.7828741073608398,
            "relevance": 5
          },
          {
            "score": 0.78242427110672,
            "relevance": 2
          },
          {
            "score": 0.7819439172744751,
            "relevance": 1
          },
          {
            "score": 0.7816896438598633,
            "relevance": 2
          },
          {
            "score": 0.775809645652771,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5505441723392566
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7502120733261108,
            "relevance": 3
          },
          {
            "score": 0.6512966156005859,
            "relevance": 2
          },
          {
            "score": 0.6374742984771729,
            "relevance": 5
          },
          {
            "score": 0.6107915043830872,
            "relevance": 2
          },
          {
            "score": 0.6090104579925537,
            "relevance": 4
          },
          {
            "score": 0.6057242155075073,
            "relevance": 5
          },
          {
            "score": 0.5556148290634155,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.130_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.783832311630249,
            "relevance": 3
          },
          {
            "score": 0.7830327749252319,
            "relevance": 4
          },
          {
            "score": 0.7828741073608398,
            "relevance": 5
          },
          {
            "score": 0.78242427110672,
            "relevance": 2
          },
          {
            "score": 0.7819439172744751,
            "relevance": 1
          },
          {
            "score": 0.7816896438598633,
            "relevance": 2
          },
          {
            "score": 0.775809645652771,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5505441723392566
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.495770663022995,
            "relevance": 3
          },
          {
            "score": 0.4510866701602936,
            "relevance": 2
          },
          {
            "score": 0.4464796483516693,
            "relevance": 5
          },
          {
            "score": 0.44476988911628723,
            "relevance": 4
          },
          {
            "score": 0.44393250346183777,
            "relevance": 2
          },
          {
            "score": 0.4389117956161499,
            "relevance": 5
          },
          {
            "score": 0.41945314407348633,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.130_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.783832311630249,
            "relevance": 3
          },
          {
            "score": 0.7830327749252319,
            "relevance": 4
          },
          {
            "score": 0.7828741073608398,
            "relevance": 5
          },
          {
            "score": 0.78242427110672,
            "relevance": 2
          },
          {
            "score": 0.7819439172744751,
            "relevance": 1
          },
          {
            "score": 0.7816896438598633,
            "relevance": 2
          },
          {
            "score": 0.775809645652771,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5505441723392566
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5965970754623413,
            "relevance": 3
          },
          {
            "score": 0.5225352048873901,
            "relevance": 2
          },
          {
            "score": 0.513303279876709,
            "relevance": 5
          },
          {
            "score": 0.49896439909935,
            "relevance": 2
          },
          {
            "score": 0.4985444247722626,
            "relevance": 4
          },
          {
            "score": 0.4939534068107605,
            "relevance": 5
          },
          {
            "score": 0.46026384830474854,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.130_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.783832311630249,
            "relevance": 3
          },
          {
            "score": 0.7830327749252319,
            "relevance": 4
          },
          {
            "score": 0.7828741073608398,
            "relevance": 5
          },
          {
            "score": 0.78242427110672,
            "relevance": 2
          },
          {
            "score": 0.7819439172744751,
            "relevance": 1
          },
          {
            "score": 0.7816896438598633,
            "relevance": 2
          },
          {
            "score": 0.775809645652771,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5505441723392566
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6531722545623779,
            "relevance": 3
          },
          {
            "score": 0.5640419721603394,
            "relevance": 2
          },
          {
            "score": 0.55228590965271,
            "relevance": 5
          },
          {
            "score": 0.5313664674758911,
            "relevance": 2
          },
          {
            "score": 0.5302337408065796,
            "relevance": 4
          },
          {
            "score": 0.5263611078262329,
            "relevance": 5
          },
          {
            "score": 0.484499990940094,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.130_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.783832311630249,
            "relevance": 3
          },
          {
            "score": 0.7830327749252319,
            "relevance": 4
          },
          {
            "score": 0.7828741073608398,
            "relevance": 5
          },
          {
            "score": 0.78242427110672,
            "relevance": 2
          },
          {
            "score": 0.7819439172744751,
            "relevance": 1
          },
          {
            "score": 0.7816896438598633,
            "relevance": 2
          },
          {
            "score": 0.775809645652771,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5505441723392566
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7227168083190918,
            "relevance": 3
          },
          {
            "score": 0.6172254085540771,
            "relevance": 2
          },
          {
            "score": 0.6024901866912842,
            "relevance": 5
          },
          {
            "score": 0.573570966720581,
            "relevance": 2
          },
          {
            "score": 0.5715540647506714,
            "relevance": 4
          },
          {
            "score": 0.568572461605072,
            "relevance": 5
          },
          {
            "score": 0.5164045691490173,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    }
  },
  "S02": {
    "thresh_0.090_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.804154098033905,
            "relevance": 3
          },
          {
            "score": 0.804142415523529,
            "relevance": 5
          },
          {
            "score": 0.8037497997283936,
            "relevance": 2
          },
          {
            "score": 0.802972674369812,
            "relevance": 1
          },
          {
            "score": 0.8027463555335999,
            "relevance": 4
          },
          {
            "score": 0.8027359247207642,
            "relevance": 5
          },
          {
            "score": 0.7995274662971497,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.746619701385498,
            "relevance": 1
          },
          {
            "score": 0.7162151336669922,
            "relevance": 2
          },
          {
            "score": 0.7079015970230103,
            "relevance": 5
          },
          {
            "score": 0.7068303227424622,
            "relevance": 2
          },
          {
            "score": 0.6820653080940247,
            "relevance": 4
          },
          {
            "score": 0.6726218461990356,
            "relevance": 3
          },
          {
            "score": 0.6663795709609985,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.090_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.804154098033905,
            "relevance": 3
          },
          {
            "score": 0.804142415523529,
            "relevance": 5
          },
          {
            "score": 0.8037497997283936,
            "relevance": 2
          },
          {
            "score": 0.802972674369812,
            "relevance": 1
          },
          {
            "score": 0.8027463555335999,
            "relevance": 4
          },
          {
            "score": 0.8027359247207642,
            "relevance": 5
          },
          {
            "score": 0.7995274662971497,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9491293430328369,
            "relevance": 1
          },
          {
            "score": 0.9232289791107178,
            "relevance": 2
          },
          {
            "score": 0.9164975881576538,
            "relevance": 5
          },
          {
            "score": 0.914966881275177,
            "relevance": 2
          },
          {
            "score": 0.8921011090278625,
            "relevance": 4
          },
          {
            "score": 0.8828133344650269,
            "relevance": 3
          },
          {
            "score": 0.8761160373687744,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.090_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.804154098033905,
            "relevance": 3
          },
          {
            "score": 0.804142415523529,
            "relevance": 5
          },
          {
            "score": 0.8037497997283936,
            "relevance": 2
          },
          {
            "score": 0.802972674369812,
            "relevance": 1
          },
          {
            "score": 0.8027463555335999,
            "relevance": 4
          },
          {
            "score": 0.8027359247207642,
            "relevance": 5
          },
          {
            "score": 0.7995274662971497,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9992243051528931,
            "relevance": 1
          },
          {
            "score": 0.979386568069458,
            "relevance": 2
          },
          {
            "score": 0.9757373332977295,
            "relevance": 5
          },
          {
            "score": 0.9732055068016052,
            "relevance": 2
          },
          {
            "score": 0.9562399983406067,
            "relevance": 4
          },
          {
            "score": 0.9495495557785034,
            "relevance": 3
          },
          {
            "score": 0.9458609819412231,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.090_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.804154098033905,
            "relevance": 3
          },
          {
            "score": 0.804142415523529,
            "relevance": 5
          },
          {
            "score": 0.8037497997283936,
            "relevance": 2
          },
          {
            "score": 0.802972674369812,
            "relevance": 1
          },
          {
            "score": 0.8027463555335999,
            "relevance": 4
          },
          {
            "score": 0.8027359247207642,
            "relevance": 5
          },
          {
            "score": 0.7995274662971497,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.028115153312683,
            "relevance": 1
          },
          {
            "score": 1.0141912698745728,
            "relevance": 2
          },
          {
            "score": 1.0138182640075684,
            "relevance": 5
          },
          {
            "score": 1.0102005004882812,
            "relevance": 2
          },
          {
            "score": 0.9999799132347107,
            "relevance": 4
          },
          {
            "score": 0.9969494342803955,
            "relevance": 5
          },
          {
            "score": 0.996558427810669,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.100_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.804154098033905,
            "relevance": 3
          },
          {
            "score": 0.804142415523529,
            "relevance": 5
          },
          {
            "score": 0.8037497997283936,
            "relevance": 2
          },
          {
            "score": 0.802972674369812,
            "relevance": 1
          },
          {
            "score": 0.8027463555335999,
            "relevance": 4
          },
          {
            "score": 0.8027359247207642,
            "relevance": 5
          },
          {
            "score": 0.7995274662971497,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7516382932662964,
            "relevance": 1
          },
          {
            "score": 0.7207230925559998,
            "relevance": 2
          },
          {
            "score": 0.7120724320411682,
            "relevance": 5
          },
          {
            "score": 0.7111517190933228,
            "relevance": 2
          },
          {
            "score": 0.6858318448066711,
            "relevance": 4
          },
          {
            "score": 0.6761204600334167,
            "relevance": 3
          },
          {
            "score": 0.6695038676261902,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.100_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.804154098033905,
            "relevance": 3
          },
          {
            "score": 0.804142415523529,
            "relevance": 5
          },
          {
            "score": 0.8037497997283936,
            "relevance": 2
          },
          {
            "score": 0.802972674369812,
            "relevance": 1
          },
          {
            "score": 0.8027463555335999,
            "relevance": 4
          },
          {
            "score": 0.8027359247207642,
            "relevance": 5
          },
          {
            "score": 0.7995274662971497,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9567763805389404,
            "relevance": 1
          },
          {
            "score": 0.9294140934944153,
            "relevance": 2
          },
          {
            "score": 0.9217912554740906,
            "relevance": 5
          },
          {
            "score": 0.9205968379974365,
            "relevance": 2
          },
          {
            "score": 0.8959913849830627,
            "relevance": 4
          },
          {
            "score": 0.8858351111412048,
            "relevance": 3
          },
          {
            "score": 0.8779887557029724,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.100_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.804154098033905,
            "relevance": 3
          },
          {
            "score": 0.804142415523529,
            "relevance": 5
          },
          {
            "score": 0.8037497997283936,
            "relevance": 2
          },
          {
            "score": 0.802972674369812,
            "relevance": 1
          },
          {
            "score": 0.8027463555335999,
            "relevance": 4
          },
          {
            "score": 0.8027359247207642,
            "relevance": 5
          },
          {
            "score": 0.7995274662971497,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0101066827774048,
            "relevance": 1
          },
          {
            "score": 0.9888760447502136,
            "relevance": 2
          },
          {
            "score": 0.9843237996101379,
            "relevance": 5
          },
          {
            "score": 0.9821361303329468,
            "relevance": 2
          },
          {
            "score": 0.9633215069770813,
            "relevance": 4
          },
          {
            "score": 0.9556568264961243,
            "relevance": 3
          },
          {
            "score": 0.9506375193595886,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.100_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.804154098033905,
            "relevance": 3
          },
          {
            "score": 0.804142415523529,
            "relevance": 5
          },
          {
            "score": 0.8037497997283936,
            "relevance": 2
          },
          {
            "score": 0.802972674369812,
            "relevance": 1
          },
          {
            "score": 0.8027463555335999,
            "relevance": 4
          },
          {
            "score": 0.8027359247207642,
            "relevance": 5
          },
          {
            "score": 0.7995274662971497,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0420714616775513,
            "relevance": 1
          },
          {
            "score": 1.0272016525268555,
            "relevance": 2
          },
          {
            "score": 1.0261409282684326,
            "relevance": 5
          },
          {
            "score": 1.0227986574172974,
            "relevance": 2
          },
          {
            "score": 1.0111088752746582,
            "relevance": 4
          },
          {
            "score": 1.0068540573120117,
            "relevance": 3
          },
          {
            "score": 1.0060441493988037,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.110_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.804154098033905,
            "relevance": 3
          },
          {
            "score": 0.804142415523529,
            "relevance": 5
          },
          {
            "score": 0.8037497997283936,
            "relevance": 2
          },
          {
            "score": 0.802972674369812,
            "relevance": 1
          },
          {
            "score": 0.8027463555335999,
            "relevance": 4
          },
          {
            "score": 0.8027359247207642,
            "relevance": 5
          },
          {
            "score": 0.7995274662971497,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7560849785804749,
            "relevance": 1
          },
          {
            "score": 0.7246822118759155,
            "relevance": 2
          },
          {
            "score": 0.7156926393508911,
            "relevance": 5
          },
          {
            "score": 0.7149306535720825,
            "relevance": 2
          },
          {
            "score": 0.6890707612037659,
            "relevance": 4
          },
          {
            "score": 0.6790952682495117,
            "relevance": 3
          },
          {
            "score": 0.6720983982086182,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.110_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.804154098033905,
            "relevance": 3
          },
          {
            "score": 0.804142415523529,
            "relevance": 5
          },
          {
            "score": 0.8037497997283936,
            "relevance": 2
          },
          {
            "score": 0.802972674369812,
            "relevance": 1
          },
          {
            "score": 0.8027463555335999,
            "relevance": 4
          },
          {
            "score": 0.8027359247207642,
            "relevance": 5
          },
          {
            "score": 0.7995274662971497,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.963365375995636,
            "relevance": 1
          },
          {
            "score": 0.9344538450241089,
            "relevance": 2
          },
          {
            "score": 0.9258804321289062,
            "relevance": 5
          },
          {
            "score": 0.9250493049621582,
            "relevance": 2
          },
          {
            "score": 0.8986079096794128,
            "relevance": 4
          },
          {
            "score": 0.8875371217727661,
            "relevance": 3
          },
          {
            "score": 0.8784775733947754,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.110_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.804154098033905,
            "relevance": 3
          },
          {
            "score": 0.804142415523529,
            "relevance": 5
          },
          {
            "score": 0.8037497997283936,
            "relevance": 2
          },
          {
            "score": 0.802972674369812,
            "relevance": 1
          },
          {
            "score": 0.8027463555335999,
            "relevance": 4
          },
          {
            "score": 0.8027359247207642,
            "relevance": 5
          },
          {
            "score": 0.7995274662971497,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0199816226959229,
            "relevance": 1
          },
          {
            "score": 0.9972066879272461,
            "relevance": 2
          },
          {
            "score": 0.9916503429412842,
            "relevance": 5
          },
          {
            "score": 0.9898477792739868,
            "relevance": 2
          },
          {
            "score": 0.9689932465553284,
            "relevance": 4
          },
          {
            "score": 0.9602570533752441,
            "relevance": 3
          },
          {
            "score": 0.9537744522094727,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.110_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.804154098033905,
            "relevance": 3
          },
          {
            "score": 0.804142415523529,
            "relevance": 5
          },
          {
            "score": 0.8037497997283936,
            "relevance": 2
          },
          {
            "score": 0.802972674369812,
            "relevance": 1
          },
          {
            "score": 0.8027463555335999,
            "relevance": 4
          },
          {
            "score": 0.8027359247207642,
            "relevance": 5
          },
          {
            "score": 0.7995274662971497,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0552616119384766,
            "relevance": 1
          },
          {
            "score": 1.0392833948135376,
            "relevance": 2
          },
          {
            "score": 1.037418246269226,
            "relevance": 5
          },
          {
            "score": 1.0343984365463257,
            "relevance": 2
          },
          {
            "score": 1.0209977626800537,
            "relevance": 4
          },
          {
            "score": 1.015775442123413,
            "relevance": 3
          },
          {
            "score": 1.0135735273361206,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.120_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.804154098033905,
            "relevance": 3
          },
          {
            "score": 0.804142415523529,
            "relevance": 5
          },
          {
            "score": 0.8037497997283936,
            "relevance": 2
          },
          {
            "score": 0.802972674369812,
            "relevance": 1
          },
          {
            "score": 0.8027463555335999,
            "relevance": 4
          },
          {
            "score": 0.8027359247207642,
            "relevance": 5
          },
          {
            "score": 0.7995274662971497,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7599254846572876,
            "relevance": 1
          },
          {
            "score": 0.7280596494674683,
            "relevance": 2
          },
          {
            "score": 0.7187304496765137,
            "relevance": 5
          },
          {
            "score": 0.7181347012519836,
            "relevance": 2
          },
          {
            "score": 0.69175124168396,
            "relevance": 4
          },
          {
            "score": 0.6815156936645508,
            "relevance": 3
          },
          {
            "score": 0.6741344928741455,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.120_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.804154098033905,
            "relevance": 3
          },
          {
            "score": 0.804142415523529,
            "relevance": 5
          },
          {
            "score": 0.8037497997283936,
            "relevance": 2
          },
          {
            "score": 0.802972674369812,
            "relevance": 1
          },
          {
            "score": 0.8027463555335999,
            "relevance": 4
          },
          {
            "score": 0.8027359247207642,
            "relevance": 5
          },
          {
            "score": 0.7995274662971497,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9688040018081665,
            "relevance": 1
          },
          {
            "score": 0.9382539987564087,
            "relevance": 2
          },
          {
            "score": 0.9286715984344482,
            "relevance": 5
          },
          {
            "score": 0.9282298684120178,
            "relevance": 2
          },
          {
            "score": 0.8998585939407349,
            "relevance": 4
          },
          {
            "score": 0.8878295421600342,
            "relevance": 3
          },
          {
            "score": 0.877497673034668,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.120_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.804154098033905,
            "relevance": 3
          },
          {
            "score": 0.804142415523529,
            "relevance": 5
          },
          {
            "score": 0.8037497997283936,
            "relevance": 2
          },
          {
            "score": 0.802972674369812,
            "relevance": 1
          },
          {
            "score": 0.8027463555335999,
            "relevance": 4
          },
          {
            "score": 0.8027359247207642,
            "relevance": 5
          },
          {
            "score": 0.7995274662971497,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.028725266456604,
            "relevance": 1
          },
          {
            "score": 1.0042387247085571,
            "relevance": 2
          },
          {
            "score": 0.9975712299346924,
            "relevance": 5
          },
          {
            "score": 0.9961966872215271,
            "relevance": 2
          },
          {
            "score": 0.9730991125106812,
            "relevance": 4
          },
          {
            "score": 0.963189959526062,
            "relevance": 3
          },
          {
            "score": 0.9551090002059937,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.120_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.804154098033905,
            "relevance": 3
          },
          {
            "score": 0.804142415523529,
            "relevance": 5
          },
          {
            "score": 0.8037497997283936,
            "relevance": 2
          },
          {
            "score": 0.802972674369812,
            "relevance": 1
          },
          {
            "score": 0.8027463555335999,
            "relevance": 4
          },
          {
            "score": 0.8027359247207642,
            "relevance": 5
          },
          {
            "score": 0.7995274662971497,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0675586462020874,
            "relevance": 1
          },
          {
            "score": 1.0502797365188599,
            "relevance": 2
          },
          {
            "score": 1.0474776029586792,
            "relevance": 5
          },
          {
            "score": 1.044832468032837,
            "relevance": 2
          },
          {
            "score": 1.029443383216858,
            "relevance": 4
          },
          {
            "score": 1.0231016874313354,
            "relevance": 3
          },
          {
            "score": 1.0192961692810059,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.130_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.804154098033905,
            "relevance": 3
          },
          {
            "score": 0.804142415523529,
            "relevance": 5
          },
          {
            "score": 0.8037497997283936,
            "relevance": 2
          },
          {
            "score": 0.802972674369812,
            "relevance": 1
          },
          {
            "score": 0.8027463555335999,
            "relevance": 4
          },
          {
            "score": 0.8027359247207642,
            "relevance": 5
          },
          {
            "score": 0.7995274662971497,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7631303071975708,
            "relevance": 1
          },
          {
            "score": 0.730825662612915,
            "relevance": 2
          },
          {
            "score": 0.721157431602478,
            "relevance": 5
          },
          {
            "score": 0.720734715461731,
            "relevance": 2
          },
          {
            "score": 0.693845272064209,
            "relevance": 4
          },
          {
            "score": 0.683355450630188,
            "relevance": 3
          },
          {
            "score": 0.6755874156951904,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.130_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.804154098033905,
            "relevance": 3
          },
          {
            "score": 0.804142415523529,
            "relevance": 5
          },
          {
            "score": 0.8037497997283936,
            "relevance": 2
          },
          {
            "score": 0.802972674369812,
            "relevance": 1
          },
          {
            "score": 0.8027463555335999,
            "relevance": 4
          },
          {
            "score": 0.8027359247207642,
            "relevance": 5
          },
          {
            "score": 0.7995274662971497,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9730015993118286,
            "relevance": 1
          },
          {
            "score": 0.9407230615615845,
            "relevance": 2
          },
          {
            "score": 0.9300744533538818,
            "relevance": 5
          },
          {
            "score": 0.9300475120544434,
            "relevance": 2
          },
          {
            "score": 0.8996566534042358,
            "relevance": 4
          },
          {
            "score": 0.8866291046142578,
            "relevance": 3
          },
          {
            "score": 0.8749713897705078,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.130_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.804154098033905,
            "relevance": 3
          },
          {
            "score": 0.804142415523529,
            "relevance": 5
          },
          {
            "score": 0.8037497997283936,
            "relevance": 2
          },
          {
            "score": 0.802972674369812,
            "relevance": 1
          },
          {
            "score": 0.8027463555335999,
            "relevance": 4
          },
          {
            "score": 0.8027359247207642,
            "relevance": 5
          },
          {
            "score": 0.7995274662971497,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0362083911895752,
            "relevance": 1
          },
          {
            "score": 1.0098282098770142,
            "relevance": 2
          },
          {
            "score": 1.001936435699463,
            "relevance": 5
          },
          {
            "score": 1.001034140586853,
            "relevance": 2
          },
          {
            "score": 0.975480318069458,
            "relevance": 4
          },
          {
            "score": 0.9642945528030396,
            "relevance": 3
          },
          {
            "score": 0.9544796943664551,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.130_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.804154098033905,
            "relevance": 3
          },
          {
            "score": 0.804142415523529,
            "relevance": 5
          },
          {
            "score": 0.8037497997283936,
            "relevance": 2
          },
          {
            "score": 0.802972674369812,
            "relevance": 1
          },
          {
            "score": 0.8027463555335999,
            "relevance": 4
          },
          {
            "score": 0.8027359247207642,
            "relevance": 5
          },
          {
            "score": 0.7995274662971497,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0788236856460571,
            "relevance": 1
          },
          {
            "score": 1.0600190162658691,
            "relevance": 2
          },
          {
            "score": 1.0561288595199585,
            "relevance": 5
          },
          {
            "score": 1.053916573524475,
            "relevance": 2
          },
          {
            "score": 1.0362235307693481,
            "relevance": 4
          },
          {
            "score": 1.028592824935913,
            "relevance": 3
          },
          {
            "score": 1.022951364517212,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    }
  },
  "S03": {
    "thresh_0.090_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7674055099487305,
            "relevance": 5
          },
          {
            "score": 0.7671536207199097,
            "relevance": 5
          },
          {
            "score": 0.7666552066802979,
            "relevance": 2
          },
          {
            "score": 0.7664155960083008,
            "relevance": 3
          },
          {
            "score": 0.7645223140716553,
            "relevance": 1
          },
          {
            "score": 0.7645148038864136,
            "relevance": 2
          },
          {
            "score": 0.7638236284255981,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8966565328741524
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5133383274078369,
            "relevance": 4
          },
          {
            "score": 0.5087387561798096,
            "relevance": 5
          },
          {
            "score": 0.4960697293281555,
            "relevance": 1
          },
          {
            "score": 0.49209147691726685,
            "relevance": 5
          },
          {
            "score": 0.4795035421848297,
            "relevance": 3
          },
          {
            "score": 0.46974632143974304,
            "relevance": 2
          },
          {
            "score": 0.45983219146728516,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      }
    },
    "thresh_0.090_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7674055099487305,
            "relevance": 5
          },
          {
            "score": 0.7671536207199097,
            "relevance": 5
          },
          {
            "score": 0.7666552066802979,
            "relevance": 2
          },
          {
            "score": 0.7664155960083008,
            "relevance": 3
          },
          {
            "score": 0.7645223140716553,
            "relevance": 1
          },
          {
            "score": 0.7645148038864136,
            "relevance": 2
          },
          {
            "score": 0.7638236284255981,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8966565328741524
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.701967716217041,
            "relevance": 4
          },
          {
            "score": 0.6946158409118652,
            "relevance": 5
          },
          {
            "score": 0.6797037124633789,
            "relevance": 1
          },
          {
            "score": 0.6693891286849976,
            "relevance": 5
          },
          {
            "score": 0.6525824069976807,
            "relevance": 3
          },
          {
            "score": 0.6339224576950073,
            "relevance": 2
          },
          {
            "score": 0.6220002174377441,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      }
    },
    "thresh_0.090_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7674055099487305,
            "relevance": 5
          },
          {
            "score": 0.7671536207199097,
            "relevance": 5
          },
          {
            "score": 0.7666552066802979,
            "relevance": 2
          },
          {
            "score": 0.7664155960083008,
            "relevance": 3
          },
          {
            "score": 0.7645223140716553,
            "relevance": 1
          },
          {
            "score": 0.7645148038864136,
            "relevance": 2
          },
          {
            "score": 0.7638236284255981,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8966565328741524
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.783635139465332,
            "relevance": 4
          },
          {
            "score": 0.7764233350753784,
            "relevance": 5
          },
          {
            "score": 0.761536717414856,
            "relevance": 1
          },
          {
            "score": 0.7509325742721558,
            "relevance": 5
          },
          {
            "score": 0.7336819171905518,
            "relevance": 3
          },
          {
            "score": 0.7135517597198486,
            "relevance": 2
          },
          {
            "score": 0.7012108564376831,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      }
    },
    "thresh_0.090_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7674055099487305,
            "relevance": 5
          },
          {
            "score": 0.7671536207199097,
            "relevance": 5
          },
          {
            "score": 0.7666552066802979,
            "relevance": 2
          },
          {
            "score": 0.7664155960083008,
            "relevance": 3
          },
          {
            "score": 0.7645223140716553,
            "relevance": 1
          },
          {
            "score": 0.7645148038864136,
            "relevance": 2
          },
          {
            "score": 0.7638236284255981,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8966565328741524
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8597112894058228,
            "relevance": 4
          },
          {
            "score": 0.853868842124939,
            "relevance": 5
          },
          {
            "score": 0.8399690389633179,
            "relevance": 1
          },
          {
            "score": 0.8316080570220947,
            "relevance": 5
          },
          {
            "score": 0.815460205078125,
            "relevance": 3
          },
          {
            "score": 0.7967838048934937,
            "relevance": 2
          },
          {
            "score": 0.7846229076385498,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      }
    },
    "thresh_0.100_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7674055099487305,
            "relevance": 5
          },
          {
            "score": 0.7671536207199097,
            "relevance": 5
          },
          {
            "score": 0.7666552066802979,
            "relevance": 2
          },
          {
            "score": 0.7664155960083008,
            "relevance": 3
          },
          {
            "score": 0.7645223140716553,
            "relevance": 1
          },
          {
            "score": 0.7645148038864136,
            "relevance": 2
          },
          {
            "score": 0.7638236284255981,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8966565328741524
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5152106285095215,
            "relevance": 4
          },
          {
            "score": 0.5105044841766357,
            "relevance": 5
          },
          {
            "score": 0.49777162075042725,
            "relevance": 1
          },
          {
            "score": 0.4935823380947113,
            "relevance": 5
          },
          {
            "score": 0.4808894991874695,
            "relevance": 3
          },
          {
            "score": 0.47091227769851685,
            "relevance": 2
          },
          {
            "score": 0.46096768975257874,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      }
    },
    "thresh_0.100_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7674055099487305,
            "relevance": 5
          },
          {
            "score": 0.7671536207199097,
            "relevance": 5
          },
          {
            "score": 0.7666552066802979,
            "relevance": 2
          },
          {
            "score": 0.7664155960083008,
            "relevance": 3
          },
          {
            "score": 0.7645223140716553,
            "relevance": 1
          },
          {
            "score": 0.7645148038864136,
            "relevance": 2
          },
          {
            "score": 0.7638236284255981,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8966565328741524
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.696770191192627,
            "relevance": 4
          },
          {
            "score": 0.6888664960861206,
            "relevance": 5
          },
          {
            "score": 0.6735455989837646,
            "relevance": 1
          },
          {
            "score": 0.6621197462081909,
            "relevance": 5
          },
          {
            "score": 0.6446595191955566,
            "relevance": 3
          },
          {
            "score": 0.6247286796569824,
            "relevance": 2
          },
          {
            "score": 0.6125564575195312,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      }
    },
    "thresh_0.100_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7674055099487305,
            "relevance": 5
          },
          {
            "score": 0.7671536207199097,
            "relevance": 5
          },
          {
            "score": 0.7666552066802979,
            "relevance": 2
          },
          {
            "score": 0.7664155960083008,
            "relevance": 3
          },
          {
            "score": 0.7645223140716553,
            "relevance": 1
          },
          {
            "score": 0.7645148038864136,
            "relevance": 2
          },
          {
            "score": 0.7638236284255981,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8966565328741524
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7785638570785522,
            "relevance": 4
          },
          {
            "score": 0.7704921960830688,
            "relevance": 5
          },
          {
            "score": 0.7549498081207275,
            "relevance": 1
          },
          {
            "score": 0.7425521612167358,
            "relevance": 5
          },
          {
            "score": 0.7242064476013184,
            "relevance": 3
          },
          {
            "score": 0.7019047737121582,
            "relevance": 2
          },
          {
            "score": 0.6891165971755981,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      }
    },
    "thresh_0.100_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7674055099487305,
            "relevance": 5
          },
          {
            "score": 0.7671536207199097,
            "relevance": 5
          },
          {
            "score": 0.7666552066802979,
            "relevance": 2
          },
          {
            "score": 0.7664155960083008,
            "relevance": 3
          },
          {
            "score": 0.7645223140716553,
            "relevance": 1
          },
          {
            "score": 0.7645148038864136,
            "relevance": 2
          },
          {
            "score": 0.7638236284255981,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8966565328741524
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8578146696090698,
            "relevance": 4
          },
          {
            "score": 0.8508425951004028,
            "relevance": 5
          },
          {
            "score": 0.8360569477081299,
            "relevance": 1
          },
          {
            "score": 0.8252112865447998,
            "relevance": 5
          },
          {
            "score": 0.8074790239334106,
            "relevance": 3
          },
          {
            "score": 0.785539984703064,
            "relevance": 2
          },
          {
            "score": 0.7726767063140869,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      }
    },
    "thresh_0.110_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7674055099487305,
            "relevance": 5
          },
          {
            "score": 0.7671536207199097,
            "relevance": 5
          },
          {
            "score": 0.7666552066802979,
            "relevance": 2
          },
          {
            "score": 0.7664155960083008,
            "relevance": 3
          },
          {
            "score": 0.7645223140716553,
            "relevance": 1
          },
          {
            "score": 0.7645148038864136,
            "relevance": 2
          },
          {
            "score": 0.7638236284255981,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8966565328741524
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5167727470397949,
            "relevance": 4
          },
          {
            "score": 0.5119627714157104,
            "relevance": 5
          },
          {
            "score": 0.4991890490055084,
            "relevance": 1
          },
          {
            "score": 0.4947824478149414,
            "relevance": 5
          },
          {
            "score": 0.4820042550563812,
            "relevance": 3
          },
          {
            "score": 0.4718117415904999,
            "relevance": 2
          },
          {
            "score": 0.4618558883666992,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      }
    },
    "thresh_0.110_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7674055099487305,
            "relevance": 5
          },
          {
            "score": 0.7671536207199097,
            "relevance": 5
          },
          {
            "score": 0.7666552066802979,
            "relevance": 2
          },
          {
            "score": 0.7664155960083008,
            "relevance": 3
          },
          {
            "score": 0.7645223140716553,
            "relevance": 1
          },
          {
            "score": 0.7645148038864136,
            "relevance": 2
          },
          {
            "score": 0.7638236284255981,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8966565328741524
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6901664733886719,
            "relevance": 4
          },
          {
            "score": 0.6817090511322021,
            "relevance": 5
          },
          {
            "score": 0.666000485420227,
            "relevance": 1
          },
          {
            "score": 0.6534583568572998,
            "relevance": 5
          },
          {
            "score": 0.6353696584701538,
            "relevance": 3
          },
          {
            "score": 0.6141942739486694,
            "relevance": 2
          },
          {
            "score": 0.601797342300415,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      }
    },
    "thresh_0.110_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7674055099487305,
            "relevance": 5
          },
          {
            "score": 0.7671536207199097,
            "relevance": 5
          },
          {
            "score": 0.7666552066802979,
            "relevance": 2
          },
          {
            "score": 0.7664155960083008,
            "relevance": 3
          },
          {
            "score": 0.7645223140716553,
            "relevance": 1
          },
          {
            "score": 0.7645148038864136,
            "relevance": 2
          },
          {
            "score": 0.7638236284255981,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8966565328741524
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7713052034378052,
            "relevance": 4
          },
          {
            "score": 0.7623367309570312,
            "relevance": 5
          },
          {
            "score": 0.7461330890655518,
            "relevance": 1
          },
          {
            "score": 0.7318735122680664,
            "relevance": 5
          },
          {
            "score": 0.7124233245849609,
            "relevance": 3
          },
          {
            "score": 0.6879220008850098,
            "relevance": 2
          },
          {
            "score": 0.6747028827667236,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      }
    },
    "thresh_0.110_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7674055099487305,
            "relevance": 5
          },
          {
            "score": 0.7671536207199097,
            "relevance": 5
          },
          {
            "score": 0.7666552066802979,
            "relevance": 2
          },
          {
            "score": 0.7664155960083008,
            "relevance": 3
          },
          {
            "score": 0.7645223140716553,
            "relevance": 1
          },
          {
            "score": 0.7645148038864136,
            "relevance": 2
          },
          {
            "score": 0.7638236284255981,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8966565328741524
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8530112504959106,
            "relevance": 4
          },
          {
            "score": 0.8447906970977783,
            "relevance": 5
          },
          {
            "score": 0.8290495872497559,
            "relevance": 1
          },
          {
            "score": 0.815479040145874,
            "relevance": 5
          },
          {
            "score": 0.7960478067398071,
            "relevance": 3
          },
          {
            "score": 0.7706189155578613,
            "relevance": 2
          },
          {
            "score": 0.7570292949676514,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      }
    },
    "thresh_0.120_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7674055099487305,
            "relevance": 5
          },
          {
            "score": 0.7671536207199097,
            "relevance": 5
          },
          {
            "score": 0.7666552066802979,
            "relevance": 2
          },
          {
            "score": 0.7664155960083008,
            "relevance": 3
          },
          {
            "score": 0.7645223140716553,
            "relevance": 1
          },
          {
            "score": 0.7645148038864136,
            "relevance": 2
          },
          {
            "score": 0.7638236284255981,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8966565328741524
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5179970264434814,
            "relevance": 4
          },
          {
            "score": 0.5130864977836609,
            "relevance": 5
          },
          {
            "score": 0.5002949833869934,
            "relevance": 1
          },
          {
            "score": 0.49566563963890076,
            "relevance": 5
          },
          {
            "score": 0.4828217923641205,
            "relevance": 3
          },
          {
            "score": 0.47241994738578796,
            "relevance": 2
          },
          {
            "score": 0.4624718427658081,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      }
    },
    "thresh_0.120_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7674055099487305,
            "relevance": 5
          },
          {
            "score": 0.7671536207199097,
            "relevance": 5
          },
          {
            "score": 0.7666552066802979,
            "relevance": 2
          },
          {
            "score": 0.7664155960083008,
            "relevance": 3
          },
          {
            "score": 0.7645223140716553,
            "relevance": 1
          },
          {
            "score": 0.7645148038864136,
            "relevance": 2
          },
          {
            "score": 0.7638236284255981,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8966565328741524
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6821218132972717,
            "relevance": 4
          },
          {
            "score": 0.6731147170066833,
            "relevance": 5
          },
          {
            "score": 0.6570441722869873,
            "relevance": 1
          },
          {
            "score": 0.6433936357498169,
            "relevance": 5
          },
          {
            "score": 0.6247096061706543,
            "relevance": 3
          },
          {
            "score": 0.6023324728012085,
            "relevance": 2
          },
          {
            "score": 0.5897398591041565,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      }
    },
    "thresh_0.120_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7674055099487305,
            "relevance": 5
          },
          {
            "score": 0.7671536207199097,
            "relevance": 5
          },
          {
            "score": 0.7666552066802979,
            "relevance": 2
          },
          {
            "score": 0.7664155960083008,
            "relevance": 3
          },
          {
            "score": 0.7645223140716553,
            "relevance": 1
          },
          {
            "score": 0.7645148038864136,
            "relevance": 2
          },
          {
            "score": 0.7638236284255981,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8966565328741524
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.761740505695343,
            "relevance": 4
          },
          {
            "score": 0.7518479228019714,
            "relevance": 5
          },
          {
            "score": 0.7349858283996582,
            "relevance": 1
          },
          {
            "score": 0.7188202142715454,
            "relevance": 5
          },
          {
            "score": 0.6982730627059937,
            "relevance": 3
          },
          {
            "score": 0.6715807914733887,
            "relevance": 2
          },
          {
            "score": 0.6579551100730896,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      }
    },
    "thresh_0.120_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7674055099487305,
            "relevance": 5
          },
          {
            "score": 0.7671536207199097,
            "relevance": 5
          },
          {
            "score": 0.7666552066802979,
            "relevance": 2
          },
          {
            "score": 0.7664155960083008,
            "relevance": 3
          },
          {
            "score": 0.7645223140716553,
            "relevance": 1
          },
          {
            "score": 0.7645148038864136,
            "relevance": 2
          },
          {
            "score": 0.7638236284255981,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8966565328741524
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8449779152870178,
            "relevance": 4
          },
          {
            "score": 0.8353959918022156,
            "relevance": 5
          },
          {
            "score": 0.8186355829238892,
            "relevance": 1
          },
          {
            "score": 0.8021241426467896,
            "relevance": 5
          },
          {
            "score": 0.7808995246887207,
            "relevance": 3
          },
          {
            "score": 0.7518086433410645,
            "relevance": 2
          },
          {
            "score": 0.7374827265739441,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      }
    },
    "thresh_0.130_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7674055099487305,
            "relevance": 5
          },
          {
            "score": 0.7671536207199097,
            "relevance": 5
          },
          {
            "score": 0.7666552066802979,
            "relevance": 2
          },
          {
            "score": 0.7664155960083008,
            "relevance": 3
          },
          {
            "score": 0.7645223140716553,
            "relevance": 1
          },
          {
            "score": 0.7645148038864136,
            "relevance": 2
          },
          {
            "score": 0.7638236284255981,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8966565328741524
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5188578367233276,
            "relevance": 4
          },
          {
            "score": 0.513850212097168,
            "relevance": 5
          },
          {
            "score": 0.5010637640953064,
            "relevance": 1
          },
          {
            "score": 0.4962075352668762,
            "relevance": 5
          },
          {
            "score": 0.4833182990550995,
            "relevance": 3
          },
          {
            "score": 0.47271403670310974,
            "relevance": 2
          },
          {
            "score": 0.46279242634773254,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      }
    },
    "thresh_0.130_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7674055099487305,
            "relevance": 5
          },
          {
            "score": 0.7671536207199097,
            "relevance": 5
          },
          {
            "score": 0.7666552066802979,
            "relevance": 2
          },
          {
            "score": 0.7664155960083008,
            "relevance": 3
          },
          {
            "score": 0.7645223140716553,
            "relevance": 1
          },
          {
            "score": 0.7645148038864136,
            "relevance": 2
          },
          {
            "score": 0.7638236284255981,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8966565328741524
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6726170182228088,
            "relevance": 4
          },
          {
            "score": 0.6630713939666748,
            "relevance": 5
          },
          {
            "score": 0.6466687321662903,
            "relevance": 1
          },
          {
            "score": 0.6319323778152466,
            "relevance": 5
          },
          {
            "score": 0.612694501876831,
            "relevance": 3
          },
          {
            "score": 0.5891755819320679,
            "relevance": 2
          },
          {
            "score": 0.5764192342758179,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      }
    },
    "thresh_0.130_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7674055099487305,
            "relevance": 5
          },
          {
            "score": 0.7671536207199097,
            "relevance": 5
          },
          {
            "score": 0.7666552066802979,
            "relevance": 2
          },
          {
            "score": 0.7664155960083008,
            "relevance": 3
          },
          {
            "score": 0.7645223140716553,
            "relevance": 1
          },
          {
            "score": 0.7645148038864136,
            "relevance": 2
          },
          {
            "score": 0.7638236284255981,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8966565328741524
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7497774958610535,
            "relevance": 4
          },
          {
            "score": 0.7389459609985352,
            "relevance": 5
          },
          {
            "score": 0.7214379906654358,
            "relevance": 1
          },
          {
            "score": 0.703352689743042,
            "relevance": 5
          },
          {
            "score": 0.6817353963851929,
            "relevance": 3
          },
          {
            "score": 0.6529029607772827,
            "relevance": 2
          },
          {
            "score": 0.6389040946960449,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      }
    },
    "thresh_0.130_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7674055099487305,
            "relevance": 5
          },
          {
            "score": 0.7671536207199097,
            "relevance": 5
          },
          {
            "score": 0.7666552066802979,
            "relevance": 2
          },
          {
            "score": 0.7664155960083008,
            "relevance": 3
          },
          {
            "score": 0.7645223140716553,
            "relevance": 1
          },
          {
            "score": 0.7645148038864136,
            "relevance": 2
          },
          {
            "score": 0.7638236284255981,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8966565328741524
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8334116339683533,
            "relevance": 4
          },
          {
            "score": 0.8223676681518555,
            "relevance": 5
          },
          {
            "score": 0.8045350909233093,
            "relevance": 1
          },
          {
            "score": 0.7849071025848389,
            "relevance": 5
          },
          {
            "score": 0.7618260383605957,
            "relevance": 3
          },
          {
            "score": 0.7289779186248779,
            "relevance": 2
          },
          {
            "score": 0.7139239311218262,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      }
    }
  },
  "S04": {
    "thresh_0.090_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7939574718475342,
            "relevance": 2
          },
          {
            "score": 0.7934482097625732,
            "relevance": 3
          },
          {
            "score": 0.7933871746063232,
            "relevance": 5
          },
          {
            "score": 0.792614221572876,
            "relevance": 5
          },
          {
            "score": 0.79181307554245,
            "relevance": 1
          },
          {
            "score": 0.7903652191162109,
            "relevance": 4
          },
          {
            "score": 0.789715051651001,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39471190325945
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6746900081634521,
            "relevance": 2
          },
          {
            "score": 0.6602068543434143,
            "relevance": 2
          },
          {
            "score": 0.6569536328315735,
            "relevance": 1
          },
          {
            "score": 0.6365770101547241,
            "relevance": 3
          },
          {
            "score": 0.6244421601295471,
            "relevance": 5
          },
          {
            "score": 0.6218669414520264,
            "relevance": 4
          },
          {
            "score": 0.6079777479171753,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.0,
          "P@Full": 0.5714285714285714,
          "MRR": 0.25,
          "NDCG@3": 0.09288492328021003
        }
      }
    },
    "thresh_0.090_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7939574718475342,
            "relevance": 2
          },
          {
            "score": 0.7934482097625732,
            "relevance": 3
          },
          {
            "score": 0.7933871746063232,
            "relevance": 5
          },
          {
            "score": 0.792614221572876,
            "relevance": 5
          },
          {
            "score": 0.79181307554245,
            "relevance": 1
          },
          {
            "score": 0.7903652191162109,
            "relevance": 4
          },
          {
            "score": 0.789715051651001,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39471190325945
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8842558860778809,
            "relevance": 2
          },
          {
            "score": 0.8685908913612366,
            "relevance": 2
          },
          {
            "score": 0.8650439381599426,
            "relevance": 1
          },
          {
            "score": 0.8395408391952515,
            "relevance": 3
          },
          {
            "score": 0.8254333138465881,
            "relevance": 5
          },
          {
            "score": 0.820061445236206,
            "relevance": 4
          },
          {
            "score": 0.8029640913009644,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.0,
          "P@Full": 0.5714285714285714,
          "MRR": 0.25,
          "NDCG@3": 0.09288492328021003
        }
      }
    },
    "thresh_0.090_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7939574718475342,
            "relevance": 2
          },
          {
            "score": 0.7934482097625732,
            "relevance": 3
          },
          {
            "score": 0.7933871746063232,
            "relevance": 5
          },
          {
            "score": 0.792614221572876,
            "relevance": 5
          },
          {
            "score": 0.79181307554245,
            "relevance": 1
          },
          {
            "score": 0.7903652191162109,
            "relevance": 4
          },
          {
            "score": 0.789715051651001,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39471190325945
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9545562267303467,
            "relevance": 2
          },
          {
            "score": 0.9414052367210388,
            "relevance": 2
          },
          {
            "score": 0.9383096098899841,
            "relevance": 1
          },
          {
            "score": 0.9173884391784668,
            "relevance": 3
          },
          {
            "score": 0.9042851328849792,
            "relevance": 5
          },
          {
            "score": 0.8999806642532349,
            "relevance": 4
          },
          {
            "score": 0.8837383985519409,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.0,
          "P@Full": 0.5714285714285714,
          "MRR": 0.25,
          "NDCG@3": 0.09288492328021003
        }
      }
    },
    "thresh_0.090_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7939574718475342,
            "relevance": 2
          },
          {
            "score": 0.7934482097625732,
            "relevance": 3
          },
          {
            "score": 0.7933871746063232,
            "relevance": 5
          },
          {
            "score": 0.792614221572876,
            "relevance": 5
          },
          {
            "score": 0.79181307554245,
            "relevance": 1
          },
          {
            "score": 0.7903652191162109,
            "relevance": 4
          },
          {
            "score": 0.789715051651001,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39471190325945
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.00643789768219,
            "relevance": 2
          },
          {
            "score": 0.997072160243988,
            "relevance": 2
          },
          {
            "score": 0.994694173336029,
            "relevance": 1
          },
          {
            "score": 0.9820656776428223,
            "relevance": 3
          },
          {
            "score": 0.9711706042289734,
            "relevance": 5
          },
          {
            "score": 0.9695273637771606,
            "relevance": 4
          },
          {
            "score": 0.9558444023132324,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.0,
          "P@Full": 0.5714285714285714,
          "MRR": 0.25,
          "NDCG@3": 0.09288492328021003
        }
      }
    },
    "thresh_0.100_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7939574718475342,
            "relevance": 2
          },
          {
            "score": 0.7934482097625732,
            "relevance": 3
          },
          {
            "score": 0.7933871746063232,
            "relevance": 5
          },
          {
            "score": 0.792614221572876,
            "relevance": 5
          },
          {
            "score": 0.79181307554245,
            "relevance": 1
          },
          {
            "score": 0.7903652191162109,
            "relevance": 4
          },
          {
            "score": 0.789715051651001,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39471190325945
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6776314973831177,
            "relevance": 2
          },
          {
            "score": 0.6629151105880737,
            "relevance": 2
          },
          {
            "score": 0.659624457359314,
            "relevance": 1
          },
          {
            "score": 0.6386244297027588,
            "relevance": 3
          },
          {
            "score": 0.6264039278030396,
            "relevance": 5
          },
          {
            "score": 0.6235752105712891,
            "relevance": 4
          },
          {
            "score": 0.6095731258392334,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.0,
          "P@Full": 0.5714285714285714,
          "MRR": 0.25,
          "NDCG@3": 0.09288492328021003
        }
      }
    },
    "thresh_0.100_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7939574718475342,
            "relevance": 2
          },
          {
            "score": 0.7934482097625732,
            "relevance": 3
          },
          {
            "score": 0.7933871746063232,
            "relevance": 5
          },
          {
            "score": 0.792614221572876,
            "relevance": 5
          },
          {
            "score": 0.79181307554245,
            "relevance": 1
          },
          {
            "score": 0.7903652191162109,
            "relevance": 4
          },
          {
            "score": 0.789715051651001,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39471190325945
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8857916593551636,
            "relevance": 2
          },
          {
            "score": 0.8691407442092896,
            "relevance": 2
          },
          {
            "score": 0.865410566329956,
            "relevance": 1
          },
          {
            "score": 0.8374977111816406,
            "relevance": 3
          },
          {
            "score": 0.8227899074554443,
            "relevance": 5
          },
          {
            "score": 0.8165140151977539,
            "relevance": 4
          },
          {
            "score": 0.798638105392456,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.0,
          "P@Full": 0.5714285714285714,
          "MRR": 0.25,
          "NDCG@3": 0.09288492328021003
        }
      }
    },
    "thresh_0.100_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7939574718475342,
            "relevance": 2
          },
          {
            "score": 0.7934482097625732,
            "relevance": 3
          },
          {
            "score": 0.7933871746063232,
            "relevance": 5
          },
          {
            "score": 0.792614221572876,
            "relevance": 5
          },
          {
            "score": 0.79181307554245,
            "relevance": 1
          },
          {
            "score": 0.7903652191162109,
            "relevance": 4
          },
          {
            "score": 0.789715051651001,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39471190325945
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9589536190032959,
            "relevance": 2
          },
          {
            "score": 0.9445855617523193,
            "relevance": 2
          },
          {
            "score": 0.9412564039230347,
            "relevance": 1
          },
          {
            "score": 0.9171894788742065,
            "relevance": 3
          },
          {
            "score": 0.9032320976257324,
            "relevance": 5
          },
          {
            "score": 0.8976767063140869,
            "relevance": 4
          },
          {
            "score": 0.880271315574646,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.0,
          "P@Full": 0.5714285714285714,
          "MRR": 0.25,
          "NDCG@3": 0.09288492328021003
        }
      }
    },
    "thresh_0.100_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7939574718475342,
            "relevance": 2
          },
          {
            "score": 0.7934482097625732,
            "relevance": 3
          },
          {
            "score": 0.7933871746063232,
            "relevance": 5
          },
          {
            "score": 0.792614221572876,
            "relevance": 5
          },
          {
            "score": 0.79181307554245,
            "relevance": 1
          },
          {
            "score": 0.7903652191162109,
            "relevance": 4
          },
          {
            "score": 0.789715051651001,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39471190325945
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0151726007461548,
            "relevance": 2
          },
          {
            "score": 1.004647135734558,
            "relevance": 2
          },
          {
            "score": 1.002040147781372,
            "relevance": 1
          },
          {
            "score": 0.9861323833465576,
            "relevance": 3
          },
          {
            "score": 0.9742767810821533,
            "relevance": 5
          },
          {
            "score": 0.9712016582489014,
            "relevance": 4
          },
          {
            "score": 0.9561132192611694,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.0,
          "P@Full": 0.5714285714285714,
          "MRR": 0.25,
          "NDCG@3": 0.09288492328021003
        }
      }
    },
    "thresh_0.110_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7939574718475342,
            "relevance": 2
          },
          {
            "score": 0.7934482097625732,
            "relevance": 3
          },
          {
            "score": 0.7933871746063232,
            "relevance": 5
          },
          {
            "score": 0.792614221572876,
            "relevance": 5
          },
          {
            "score": 0.79181307554245,
            "relevance": 1
          },
          {
            "score": 0.7903652191162109,
            "relevance": 4
          },
          {
            "score": 0.789715051651001,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39471190325945
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6800228357315063,
            "relevance": 2
          },
          {
            "score": 0.6650862693786621,
            "relevance": 2
          },
          {
            "score": 0.6617621183395386,
            "relevance": 1
          },
          {
            "score": 0.6401468515396118,
            "relevance": 3
          },
          {
            "score": 0.6278562545776367,
            "relevance": 5
          },
          {
            "score": 0.6247687935829163,
            "relevance": 4
          },
          {
            "score": 0.6106716394424438,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.0,
          "P@Full": 0.5714285714285714,
          "MRR": 0.25,
          "NDCG@3": 0.09288492328021003
        }
      }
    },
    "thresh_0.110_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7939574718475342,
            "relevance": 2
          },
          {
            "score": 0.7934482097625732,
            "relevance": 3
          },
          {
            "score": 0.7933871746063232,
            "relevance": 5
          },
          {
            "score": 0.792614221572876,
            "relevance": 5
          },
          {
            "score": 0.79181307554245,
            "relevance": 1
          },
          {
            "score": 0.7903652191162109,
            "relevance": 4
          },
          {
            "score": 0.789715051651001,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39471190325945
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8859125375747681,
            "relevance": 2
          },
          {
            "score": 0.8682398796081543,
            "relevance": 2
          },
          {
            "score": 0.8643211126327515,
            "relevance": 1
          },
          {
            "score": 0.8339153528213501,
            "relevance": 3
          },
          {
            "score": 0.818602442741394,
            "relevance": 5
          },
          {
            "score": 0.811394989490509,
            "relevance": 4
          },
          {
            "score": 0.792739987373352,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.0,
          "P@Full": 0.5714285714285714,
          "MRR": 0.25,
          "NDCG@3": 0.09288492328021003
        }
      }
    },
    "thresh_0.110_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7939574718475342,
            "relevance": 2
          },
          {
            "score": 0.7934482097625732,
            "relevance": 3
          },
          {
            "score": 0.7933871746063232,
            "relevance": 5
          },
          {
            "score": 0.792614221572876,
            "relevance": 5
          },
          {
            "score": 0.79181307554245,
            "relevance": 1
          },
          {
            "score": 0.7903652191162109,
            "relevance": 4
          },
          {
            "score": 0.789715051651001,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39471190325945
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9616667032241821,
            "relevance": 2
          },
          {
            "score": 0.945976734161377,
            "relevance": 2
          },
          {
            "score": 0.9423956871032715,
            "relevance": 1
          },
          {
            "score": 0.9149338006973267,
            "relevance": 3
          },
          {
            "score": 0.9000699520111084,
            "relevance": 5
          },
          {
            "score": 0.8931769728660583,
            "relevance": 4
          },
          {
            "score": 0.8745484352111816,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.0,
          "P@Full": 0.5714285714285714,
          "MRR": 0.25,
          "NDCG@3": 0.09288492328021003
        }
      }
    },
    "thresh_0.110_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7939574718475342,
            "relevance": 2
          },
          {
            "score": 0.7934482097625732,
            "relevance": 3
          },
          {
            "score": 0.7933871746063232,
            "relevance": 5
          },
          {
            "score": 0.792614221572876,
            "relevance": 5
          },
          {
            "score": 0.79181307554245,
            "relevance": 1
          },
          {
            "score": 0.7903652191162109,
            "relevance": 4
          },
          {
            "score": 0.789715051651001,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39471190325945
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0222837924957275,
            "relevance": 2
          },
          {
            "score": 1.0104233026504517,
            "relevance": 2
          },
          {
            "score": 1.0075538158416748,
            "relevance": 1
          },
          {
            "score": 0.9879016876220703,
            "relevance": 3
          },
          {
            "score": 0.974960207939148,
            "relevance": 5
          },
          {
            "score": 0.9702677130699158,
            "relevance": 4
          },
          {
            "score": 0.9536067247390747,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.0,
          "P@Full": 0.5714285714285714,
          "MRR": 0.25,
          "NDCG@3": 0.09288492328021003
        }
      }
    },
    "thresh_0.120_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7939574718475342,
            "relevance": 2
          },
          {
            "score": 0.7934482097625732,
            "relevance": 3
          },
          {
            "score": 0.7933871746063232,
            "relevance": 5
          },
          {
            "score": 0.792614221572876,
            "relevance": 5
          },
          {
            "score": 0.79181307554245,
            "relevance": 1
          },
          {
            "score": 0.7903652191162109,
            "relevance": 4
          },
          {
            "score": 0.789715051651001,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39471190325945
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6818370819091797,
            "relevance": 2
          },
          {
            "score": 0.6666944622993469,
            "relevance": 2
          },
          {
            "score": 0.6633400917053223,
            "relevance": 1
          },
          {
            "score": 0.6411204934120178,
            "relevance": 3
          },
          {
            "score": 0.6287757158279419,
            "relevance": 5
          },
          {
            "score": 0.6254257559776306,
            "relevance": 4
          },
          {
            "score": 0.6112512350082397,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.0,
          "P@Full": 0.5714285714285714,
          "MRR": 0.25,
          "NDCG@3": 0.09288492328021003
        }
      }
    },
    "thresh_0.120_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7939574718475342,
            "relevance": 2
          },
          {
            "score": 0.7934482097625732,
            "relevance": 3
          },
          {
            "score": 0.7933871746063232,
            "relevance": 5
          },
          {
            "score": 0.792614221572876,
            "relevance": 5
          },
          {
            "score": 0.79181307554245,
            "relevance": 1
          },
          {
            "score": 0.7903652191162109,
            "relevance": 4
          },
          {
            "score": 0.789715051651001,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39471190325945
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8845354318618774,
            "relevance": 2
          },
          {
            "score": 0.8658098578453064,
            "relevance": 2
          },
          {
            "score": 0.8616981506347656,
            "relevance": 1
          },
          {
            "score": 0.8287321925163269,
            "relevance": 3
          },
          {
            "score": 0.8128139972686768,
            "relevance": 5
          },
          {
            "score": 0.8046557307243347,
            "relevance": 4
          },
          {
            "score": 0.7852275371551514,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.0,
          "P@Full": 0.5714285714285714,
          "MRR": 0.25,
          "NDCG@3": 0.09288492328021003
        }
      }
    },
    "thresh_0.120_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7939574718475342,
            "relevance": 2
          },
          {
            "score": 0.7934482097625732,
            "relevance": 3
          },
          {
            "score": 0.7933871746063232,
            "relevance": 5
          },
          {
            "score": 0.792614221572876,
            "relevance": 5
          },
          {
            "score": 0.79181307554245,
            "relevance": 1
          },
          {
            "score": 0.7903652191162109,
            "relevance": 4
          },
          {
            "score": 0.789715051651001,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39471190325945
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9625334739685059,
            "relevance": 2
          },
          {
            "score": 0.9454159140586853,
            "relevance": 2
          },
          {
            "score": 0.9415643215179443,
            "relevance": 1
          },
          {
            "score": 0.9104663729667664,
            "relevance": 3
          },
          {
            "score": 0.8946478366851807,
            "relevance": 5
          },
          {
            "score": 0.886339008808136,
            "relevance": 4
          },
          {
            "score": 0.8664364814758301,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.0,
          "P@Full": 0.5714285714285714,
          "MRR": 0.25,
          "NDCG@3": 0.09288492328021003
        }
      }
    },
    "thresh_0.120_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7939574718475342,
            "relevance": 2
          },
          {
            "score": 0.7934482097625732,
            "relevance": 3
          },
          {
            "score": 0.7933871746063232,
            "relevance": 5
          },
          {
            "score": 0.792614221572876,
            "relevance": 5
          },
          {
            "score": 0.79181307554245,
            "relevance": 1
          },
          {
            "score": 0.7903652191162109,
            "relevance": 4
          },
          {
            "score": 0.789715051651001,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39471190325945
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0275274515151978,
            "relevance": 2
          },
          {
            "score": 1.0141372680664062,
            "relevance": 2
          },
          {
            "score": 1.01096773147583,
            "relevance": 1
          },
          {
            "score": 0.9870702624320984,
            "relevance": 3
          },
          {
            "score": 0.9729102849960327,
            "relevance": 5
          },
          {
            "score": 0.9664095044136047,
            "relevance": 4
          },
          {
            "score": 0.9480041265487671,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.0,
          "P@Full": 0.5714285714285714,
          "MRR": 0.25,
          "NDCG@3": 0.09288492328021003
        }
      }
    },
    "thresh_0.130_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7939574718475342,
            "relevance": 2
          },
          {
            "score": 0.7934482097625732,
            "relevance": 3
          },
          {
            "score": 0.7933871746063232,
            "relevance": 5
          },
          {
            "score": 0.792614221572876,
            "relevance": 5
          },
          {
            "score": 0.79181307554245,
            "relevance": 1
          },
          {
            "score": 0.7903652191162109,
            "relevance": 4
          },
          {
            "score": 0.789715051651001,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39471190325945
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6830509305000305,
            "relevance": 2
          },
          {
            "score": 0.667716383934021,
            "relevance": 2
          },
          {
            "score": 0.6643357872962952,
            "relevance": 1
          },
          {
            "score": 0.6415255069732666,
            "relevance": 3
          },
          {
            "score": 0.6291419267654419,
            "relevance": 5
          },
          {
            "score": 0.6255275011062622,
            "relevance": 4
          },
          {
            "score": 0.6112930774688721,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.0,
          "P@Full": 0.5714285714285714,
          "MRR": 0.25,
          "NDCG@3": 0.09288492328021003
        }
      }
    },
    "thresh_0.130_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7939574718475342,
            "relevance": 2
          },
          {
            "score": 0.7934482097625732,
            "relevance": 3
          },
          {
            "score": 0.7933871746063232,
            "relevance": 5
          },
          {
            "score": 0.792614221572876,
            "relevance": 5
          },
          {
            "score": 0.79181307554245,
            "relevance": 1
          },
          {
            "score": 0.7903652191162109,
            "relevance": 4
          },
          {
            "score": 0.789715051651001,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39471190325945
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8815861344337463,
            "relevance": 2
          },
          {
            "score": 0.8617821931838989,
            "relevance": 2
          },
          {
            "score": 0.857474148273468,
            "relevance": 1
          },
          {
            "score": 0.8218997716903687,
            "relevance": 3
          },
          {
            "score": 0.8053812980651855,
            "relevance": 5
          },
          {
            "score": 0.796261191368103,
            "relevance": 4
          },
          {
            "score": 0.7760742902755737,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.0,
          "P@Full": 0.5714285714285714,
          "MRR": 0.25,
          "NDCG@3": 0.09288492328021003
        }
      }
    },
    "thresh_0.130_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7939574718475342,
            "relevance": 2
          },
          {
            "score": 0.7934482097625732,
            "relevance": 3
          },
          {
            "score": 0.7933871746063232,
            "relevance": 5
          },
          {
            "score": 0.792614221572876,
            "relevance": 5
          },
          {
            "score": 0.79181307554245,
            "relevance": 1
          },
          {
            "score": 0.7903652191162109,
            "relevance": 4
          },
          {
            "score": 0.789715051651001,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39471190325945
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9613935351371765,
            "relevance": 2
          },
          {
            "score": 0.9427446126937866,
            "relevance": 2
          },
          {
            "score": 0.9386036992073059,
            "relevance": 1
          },
          {
            "score": 0.903645396232605,
            "relevance": 3
          },
          {
            "score": 0.8868305683135986,
            "relevance": 5
          },
          {
            "score": 0.8770391941070557,
            "relevance": 4
          },
          {
            "score": 0.8558237552642822,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.0,
          "P@Full": 0.5714285714285714,
          "MRR": 0.25,
          "NDCG@3": 0.09288492328021003
        }
      }
    },
    "thresh_0.130_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7939574718475342,
            "relevance": 2
          },
          {
            "score": 0.7934482097625732,
            "relevance": 3
          },
          {
            "score": 0.7933871746063232,
            "relevance": 5
          },
          {
            "score": 0.792614221572876,
            "relevance": 5
          },
          {
            "score": 0.79181307554245,
            "relevance": 1
          },
          {
            "score": 0.7903652191162109,
            "relevance": 4
          },
          {
            "score": 0.789715051651001,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39471190325945
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0306401252746582,
            "relevance": 2
          },
          {
            "score": 1.0155069828033447,
            "relevance": 2
          },
          {
            "score": 1.0119967460632324,
            "relevance": 1
          },
          {
            "score": 0.9833261966705322,
            "relevance": 3
          },
          {
            "score": 0.9678101539611816,
            "relevance": 5
          },
          {
            "score": 0.9593100547790527,
            "relevance": 4
          },
          {
            "score": 0.9389915466308594,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.0,
          "P@Full": 0.5714285714285714,
          "MRR": 0.25,
          "NDCG@3": 0.09288492328021003
        }
      }
    }
  },
  "S05": {
    "thresh_0.090_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7646170854568481,
            "relevance": 4
          },
          {
            "score": 0.7635319232940674,
            "relevance": 5
          },
          {
            "score": 0.7617417573928833,
            "relevance": 5
          },
          {
            "score": 0.7615938186645508,
            "relevance": 3
          },
          {
            "score": 0.7614991068840027,
            "relevance": 1
          },
          {
            "score": 0.7614551782608032,
            "relevance": 2
          },
          {
            "score": 0.7597787976264954,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8622087104988697
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6946151256561279,
            "relevance": 5
          },
          {
            "score": 0.6874139904975891,
            "relevance": 2
          },
          {
            "score": 0.6848944425582886,
            "relevance": 4
          },
          {
            "score": 0.6773221492767334,
            "relevance": 3
          },
          {
            "score": 0.645376443862915,
            "relevance": 2
          },
          {
            "score": 0.6427633762359619,
            "relevance": 1
          },
          {
            "score": 0.6382337212562561,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6957218148476548
        }
      }
    },
    "thresh_0.090_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7646170854568481,
            "relevance": 4
          },
          {
            "score": 0.7635319232940674,
            "relevance": 5
          },
          {
            "score": 0.7617417573928833,
            "relevance": 5
          },
          {
            "score": 0.7615938186645508,
            "relevance": 3
          },
          {
            "score": 0.7614991068840027,
            "relevance": 1
          },
          {
            "score": 0.7614551782608032,
            "relevance": 2
          },
          {
            "score": 0.7597787976264954,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8622087104988697
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9043277502059937,
            "relevance": 5
          },
          {
            "score": 0.8975513577461243,
            "relevance": 2
          },
          {
            "score": 0.8950769901275635,
            "relevance": 4
          },
          {
            "score": 0.8873732089996338,
            "relevance": 3
          },
          {
            "score": 0.8528650999069214,
            "relevance": 2
          },
          {
            "score": 0.8493901491165161,
            "relevance": 1
          },
          {
            "score": 0.8428266644477844,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6957218148476548
        }
      }
    },
    "thresh_0.090_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7646170854568481,
            "relevance": 4
          },
          {
            "score": 0.7635319232940674,
            "relevance": 5
          },
          {
            "score": 0.7617417573928833,
            "relevance": 5
          },
          {
            "score": 0.7615938186645508,
            "relevance": 3
          },
          {
            "score": 0.7614991068840027,
            "relevance": 1
          },
          {
            "score": 0.7614551782608032,
            "relevance": 2
          },
          {
            "score": 0.7597787976264954,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8622087104988697
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9668350219726562,
            "relevance": 5
          },
          {
            "score": 0.9625409245491028,
            "relevance": 2
          },
          {
            "score": 0.9620378017425537,
            "relevance": 4
          },
          {
            "score": 0.9556560516357422,
            "relevance": 3
          },
          {
            "score": 0.9269418716430664,
            "relevance": 2
          },
          {
            "score": 0.9244390726089478,
            "relevance": 1
          },
          {
            "score": 0.9196224808692932,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6957218148476548
        }
      }
    },
    "thresh_0.090_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7646170854568481,
            "relevance": 4
          },
          {
            "score": 0.7635319232940674,
            "relevance": 5
          },
          {
            "score": 0.7617417573928833,
            "relevance": 5
          },
          {
            "score": 0.7615938186645508,
            "relevance": 3
          },
          {
            "score": 0.7614991068840027,
            "relevance": 1
          },
          {
            "score": 0.7614551782608032,
            "relevance": 2
          },
          {
            "score": 0.7597787976264954,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8622087104988697
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.009339451789856,
            "relevance": 4
          },
          {
            "score": 1.008622646331787,
            "relevance": 5
          },
          {
            "score": 1.0073285102844238,
            "relevance": 2
          },
          {
            "score": 1.0047186613082886,
            "relevance": 3
          },
          {
            "score": 0.9846516847610474,
            "relevance": 2
          },
          {
            "score": 0.9838035106658936,
            "relevance": 1
          },
          {
            "score": 0.9821866154670715,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6210739538718918
        }
      }
    },
    "thresh_0.100_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7646170854568481,
            "relevance": 4
          },
          {
            "score": 0.7635319232940674,
            "relevance": 5
          },
          {
            "score": 0.7617417573928833,
            "relevance": 5
          },
          {
            "score": 0.7615938186645508,
            "relevance": 3
          },
          {
            "score": 0.7614991068840027,
            "relevance": 1
          },
          {
            "score": 0.7614551782608032,
            "relevance": 2
          },
          {
            "score": 0.7597787976264954,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8622087104988697
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6984761953353882,
            "relevance": 5
          },
          {
            "score": 0.6910029649734497,
            "relevance": 2
          },
          {
            "score": 0.6882246732711792,
            "relevance": 4
          },
          {
            "score": 0.6805432438850403,
            "relevance": 3
          },
          {
            "score": 0.6480410099029541,
            "relevance": 2
          },
          {
            "score": 0.6452884078025818,
            "relevance": 1
          },
          {
            "score": 0.6404822468757629,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6957218148476548
        }
      }
    },
    "thresh_0.100_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7646170854568481,
            "relevance": 4
          },
          {
            "score": 0.7635319232940674,
            "relevance": 5
          },
          {
            "score": 0.7617417573928833,
            "relevance": 5
          },
          {
            "score": 0.7615938186645508,
            "relevance": 3
          },
          {
            "score": 0.7614991068840027,
            "relevance": 1
          },
          {
            "score": 0.7614551782608032,
            "relevance": 2
          },
          {
            "score": 0.7597787976264954,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8622087104988697
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9086631536483765,
            "relevance": 5
          },
          {
            "score": 0.9010735750198364,
            "relevance": 2
          },
          {
            "score": 0.8978757858276367,
            "relevance": 4
          },
          {
            "score": 0.8897311091423035,
            "relevance": 3
          },
          {
            "score": 0.8529525995254517,
            "relevance": 2
          },
          {
            "score": 0.8489912152290344,
            "relevance": 1
          },
          {
            "score": 0.841459333896637,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6957218148476548
        }
      }
    },
    "thresh_0.100_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7646170854568481,
            "relevance": 4
          },
          {
            "score": 0.7635319232940674,
            "relevance": 5
          },
          {
            "score": 0.7617417573928833,
            "relevance": 5
          },
          {
            "score": 0.7615938186645508,
            "relevance": 3
          },
          {
            "score": 0.7614991068840027,
            "relevance": 1
          },
          {
            "score": 0.7614551782608032,
            "relevance": 2
          },
          {
            "score": 0.7597787976264954,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8622087104988697
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9744083881378174,
            "relevance": 5
          },
          {
            "score": 0.9692243337631226,
            "relevance": 2
          },
          {
            "score": 0.9679107666015625,
            "relevance": 4
          },
          {
            "score": 0.9610151648521423,
            "relevance": 3
          },
          {
            "score": 0.9295122623443604,
            "relevance": 2
          },
          {
            "score": 0.9263913035392761,
            "relevance": 1
          },
          {
            "score": 0.9203174710273743,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6957218148476548
        }
      }
    },
    "thresh_0.100_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7646170854568481,
            "relevance": 4
          },
          {
            "score": 0.7635319232940674,
            "relevance": 5
          },
          {
            "score": 0.7617417573928833,
            "relevance": 5
          },
          {
            "score": 0.7615938186645508,
            "relevance": 3
          },
          {
            "score": 0.7614991068840027,
            "relevance": 1
          },
          {
            "score": 0.7614551782608032,
            "relevance": 2
          },
          {
            "score": 0.7597787976264954,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8622087104988697
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0201451778411865,
            "relevance": 5
          },
          {
            "score": 1.0194116830825806,
            "relevance": 4
          },
          {
            "score": 1.0181080102920532,
            "relevance": 2
          },
          {
            "score": 1.0143382549285889,
            "relevance": 3
          },
          {
            "score": 0.9916234016418457,
            "relevance": 2
          },
          {
            "score": 0.9901483654975891,
            "relevance": 1
          },
          {
            "score": 0.9872174859046936,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7227832842156693
        }
      }
    },
    "thresh_0.110_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7646170854568481,
            "relevance": 4
          },
          {
            "score": 0.7635319232940674,
            "relevance": 5
          },
          {
            "score": 0.7617417573928833,
            "relevance": 5
          },
          {
            "score": 0.7615938186645508,
            "relevance": 3
          },
          {
            "score": 0.7614991068840027,
            "relevance": 1
          },
          {
            "score": 0.7614551782608032,
            "relevance": 2
          },
          {
            "score": 0.7597787976264954,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8622087104988697
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7017938494682312,
            "relevance": 5
          },
          {
            "score": 0.6940484642982483,
            "relevance": 2
          },
          {
            "score": 0.6910043358802795,
            "relevance": 4
          },
          {
            "score": 0.6832212805747986,
            "relevance": 3
          },
          {
            "score": 0.6501907110214233,
            "relevance": 2
          },
          {
            "score": 0.647296667098999,
            "relevance": 1
          },
          {
            "score": 0.6422103643417358,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6957218148476548
        }
      }
    },
    "thresh_0.110_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7646170854568481,
            "relevance": 4
          },
          {
            "score": 0.7635319232940674,
            "relevance": 5
          },
          {
            "score": 0.7617417573928833,
            "relevance": 5
          },
          {
            "score": 0.7615938186645508,
            "relevance": 3
          },
          {
            "score": 0.7614991068840027,
            "relevance": 1
          },
          {
            "score": 0.7614551782608032,
            "relevance": 2
          },
          {
            "score": 0.7597787976264954,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8622087104988697
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9117398858070374,
            "relevance": 5
          },
          {
            "score": 0.9032896161079407,
            "relevance": 2
          },
          {
            "score": 0.8993238806724548,
            "relevance": 4
          },
          {
            "score": 0.8907204270362854,
            "relevance": 3
          },
          {
            "score": 0.8515862226486206,
            "relevance": 2
          },
          {
            "score": 0.8471176624298096,
            "relevance": 1
          },
          {
            "score": 0.8385789394378662,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6957218148476548
        }
      }
    },
    "thresh_0.110_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7646170854568481,
            "relevance": 4
          },
          {
            "score": 0.7635319232940674,
            "relevance": 5
          },
          {
            "score": 0.7617417573928833,
            "relevance": 5
          },
          {
            "score": 0.7615938186645508,
            "relevance": 3
          },
          {
            "score": 0.7614991068840027,
            "relevance": 1
          },
          {
            "score": 0.7614551782608032,
            "relevance": 2
          },
          {
            "score": 0.7597787976264954,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8622087104988697
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9806159138679504,
            "relevance": 5
          },
          {
            "score": 0.9744494557380676,
            "relevance": 2
          },
          {
            "score": 0.9722409844398499,
            "relevance": 4
          },
          {
            "score": 0.9647843241691589,
            "relevance": 3
          },
          {
            "score": 0.930251955986023,
            "relevance": 2
          },
          {
            "score": 0.926459789276123,
            "relevance": 1
          },
          {
            "score": 0.9190256595611572,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6957218148476548
        }
      }
    },
    "thresh_0.110_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7646170854568481,
            "relevance": 4
          },
          {
            "score": 0.7635319232940674,
            "relevance": 5
          },
          {
            "score": 0.7617417573928833,
            "relevance": 5
          },
          {
            "score": 0.7615938186645508,
            "relevance": 3
          },
          {
            "score": 0.7614991068840027,
            "relevance": 1
          },
          {
            "score": 0.7614551782608032,
            "relevance": 2
          },
          {
            "score": 0.7597787976264954,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8622087104988697
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0304899215698242,
            "relevance": 5
          },
          {
            "score": 1.0280704498291016,
            "relevance": 4
          },
          {
            "score": 1.027587652206421,
            "relevance": 2
          },
          {
            "score": 1.022472858428955,
            "relevance": 3
          },
          {
            "score": 0.9967104196548462,
            "relevance": 2
          },
          {
            "score": 0.9945164918899536,
            "relevance": 1
          },
          {
            "score": 0.990084171295166,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7227832842156693
        }
      }
    },
    "thresh_0.120_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7646170854568481,
            "relevance": 4
          },
          {
            "score": 0.7635319232940674,
            "relevance": 5
          },
          {
            "score": 0.7617417573928833,
            "relevance": 5
          },
          {
            "score": 0.7615938186645508,
            "relevance": 3
          },
          {
            "score": 0.7614991068840027,
            "relevance": 1
          },
          {
            "score": 0.7614551782608032,
            "relevance": 2
          },
          {
            "score": 0.7597787976264954,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8622087104988697
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7045372724533081,
            "relevance": 5
          },
          {
            "score": 0.696520209312439,
            "relevance": 2
          },
          {
            "score": 0.6932049989700317,
            "relevance": 4
          },
          {
            "score": 0.6853280663490295,
            "relevance": 3
          },
          {
            "score": 0.6517982482910156,
            "relevance": 2
          },
          {
            "score": 0.6487622261047363,
            "relevance": 1
          },
          {
            "score": 0.6433935165405273,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6957218148476548
        }
      }
    },
    "thresh_0.120_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7646170854568481,
            "relevance": 4
          },
          {
            "score": 0.7635319232940674,
            "relevance": 5
          },
          {
            "score": 0.7617417573928833,
            "relevance": 5
          },
          {
            "score": 0.7615938186645508,
            "relevance": 3
          },
          {
            "score": 0.7614991068840027,
            "relevance": 1
          },
          {
            "score": 0.7614551782608032,
            "relevance": 2
          },
          {
            "score": 0.7597787976264954,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8622087104988697
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9134653806686401,
            "relevance": 5
          },
          {
            "score": 0.9041091203689575,
            "relevance": 2
          },
          {
            "score": 0.8993332386016846,
            "relevance": 4
          },
          {
            "score": 0.8902541995048523,
            "relevance": 3
          },
          {
            "score": 0.8486896753311157,
            "relevance": 2
          },
          {
            "score": 0.8436962366104126,
            "relevance": 1
          },
          {
            "score": 0.8341186046600342,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6957218148476548
        }
      }
    },
    "thresh_0.120_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7646170854568481,
            "relevance": 4
          },
          {
            "score": 0.7635319232940674,
            "relevance": 5
          },
          {
            "score": 0.7617417573928833,
            "relevance": 5
          },
          {
            "score": 0.7615938186645508,
            "relevance": 3
          },
          {
            "score": 0.7614991068840027,
            "relevance": 1
          },
          {
            "score": 0.7614551782608032,
            "relevance": 2
          },
          {
            "score": 0.7597787976264954,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8622087104988697
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9853053092956543,
            "relevance": 5
          },
          {
            "score": 0.9780596494674683,
            "relevance": 2
          },
          {
            "score": 0.9748697280883789,
            "relevance": 4
          },
          {
            "score": 0.9668027758598328,
            "relevance": 3
          },
          {
            "score": 0.9289970397949219,
            "relevance": 2
          },
          {
            "score": 0.9244818687438965,
            "relevance": 1
          },
          {
            "score": 0.91558837890625,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6957218148476548
        }
      }
    },
    "thresh_0.120_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7646170854568481,
            "relevance": 4
          },
          {
            "score": 0.7635319232940674,
            "relevance": 5
          },
          {
            "score": 0.7617417573928833,
            "relevance": 5
          },
          {
            "score": 0.7615938186645508,
            "relevance": 3
          },
          {
            "score": 0.7614991068840027,
            "relevance": 1
          },
          {
            "score": 0.7614551782608032,
            "relevance": 2
          },
          {
            "score": 0.7597787976264954,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8622087104988697
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0394645929336548,
            "relevance": 5
          },
          {
            "score": 1.0355602502822876,
            "relevance": 2
          },
          {
            "score": 1.0350948572158813,
            "relevance": 4
          },
          {
            "score": 1.0288925170898438,
            "relevance": 3
          },
          {
            "score": 0.9996383190155029,
            "relevance": 2
          },
          {
            "score": 0.9966260194778442,
            "relevance": 1
          },
          {
            "score": 0.9904911518096924,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6957218148476548
        }
      }
    },
    "thresh_0.130_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7646170854568481,
            "relevance": 4
          },
          {
            "score": 0.7635319232940674,
            "relevance": 5
          },
          {
            "score": 0.7617417573928833,
            "relevance": 5
          },
          {
            "score": 0.7615938186645508,
            "relevance": 3
          },
          {
            "score": 0.7614991068840027,
            "relevance": 1
          },
          {
            "score": 0.7614551782608032,
            "relevance": 2
          },
          {
            "score": 0.7597787976264954,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8622087104988697
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7066789865493774,
            "relevance": 5
          },
          {
            "score": 0.6983920931816101,
            "relevance": 2
          },
          {
            "score": 0.6948018074035645,
            "relevance": 4
          },
          {
            "score": 0.6868383288383484,
            "relevance": 3
          },
          {
            "score": 0.6528403162956238,
            "relevance": 2
          },
          {
            "score": 0.6496622562408447,
            "relevance": 1
          },
          {
            "score": 0.6440104246139526,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6957218148476548
        }
      }
    },
    "thresh_0.130_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7646170854568481,
            "relevance": 4
          },
          {
            "score": 0.7635319232940674,
            "relevance": 5
          },
          {
            "score": 0.7617417573928833,
            "relevance": 5
          },
          {
            "score": 0.7615938186645508,
            "relevance": 3
          },
          {
            "score": 0.7614991068840027,
            "relevance": 1
          },
          {
            "score": 0.7614551782608032,
            "relevance": 2
          },
          {
            "score": 0.7597787976264954,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8622087104988697
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9137521982192993,
            "relevance": 5
          },
          {
            "score": 0.9034472107887268,
            "relevance": 2
          },
          {
            "score": 0.8978228569030762,
            "relevance": 4
          },
          {
            "score": 0.8882532715797424,
            "relevance": 3
          },
          {
            "score": 0.8441967368125916,
            "relevance": 2
          },
          {
            "score": 0.8386645317077637,
            "relevance": 1
          },
          {
            "score": 0.8280240297317505,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6957218148476548
        }
      }
    },
    "thresh_0.130_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7646170854568481,
            "relevance": 4
          },
          {
            "score": 0.7635319232940674,
            "relevance": 5
          },
          {
            "score": 0.7617417573928833,
            "relevance": 5
          },
          {
            "score": 0.7615938186645508,
            "relevance": 3
          },
          {
            "score": 0.7614991068840027,
            "relevance": 1
          },
          {
            "score": 0.7614551782608032,
            "relevance": 2
          },
          {
            "score": 0.7597787976264954,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8622087104988697
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9883208274841309,
            "relevance": 5
          },
          {
            "score": 0.9798963665962219,
            "relevance": 2
          },
          {
            "score": 0.9756373167037964,
            "relevance": 4
          },
          {
            "score": 0.9669098258018494,
            "relevance": 3
          },
          {
            "score": 0.9255899786949158,
            "relevance": 2
          },
          {
            "score": 0.9203029870986938,
            "relevance": 1
          },
          {
            "score": 0.9098578691482544,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6957218148476548
        }
      }
    },
    "thresh_0.130_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7646170854568481,
            "relevance": 4
          },
          {
            "score": 0.7635319232940674,
            "relevance": 5
          },
          {
            "score": 0.7617417573928833,
            "relevance": 5
          },
          {
            "score": 0.7615938186645508,
            "relevance": 3
          },
          {
            "score": 0.7614991068840027,
            "relevance": 1
          },
          {
            "score": 0.7614551782608032,
            "relevance": 2
          },
          {
            "score": 0.7597787976264954,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8622087104988697
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0468584299087524,
            "relevance": 5
          },
          {
            "score": 1.0417983531951904,
            "relevance": 2
          },
          {
            "score": 1.0402454137802124,
            "relevance": 4
          },
          {
            "score": 1.0333476066589355,
            "relevance": 3
          },
          {
            "score": 1.000115156173706,
            "relevance": 2
          },
          {
            "score": 0.9961789846420288,
            "relevance": 1
          },
          {
            "score": 0.9881309270858765,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6957218148476548
        }
      }
    }
  },
  "S06": {
    "thresh_0.090_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7808873057365417,
            "relevance": 5
          },
          {
            "score": 0.7807163000106812,
            "relevance": 1
          },
          {
            "score": 0.7803055047988892,
            "relevance": 3
          },
          {
            "score": 0.7781915664672852,
            "relevance": 5
          },
          {
            "score": 0.7780174612998962,
            "relevance": 2
          },
          {
            "score": 0.7778468132019043,
            "relevance": 4
          },
          {
            "score": 0.7775669097900391,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6050920140147794
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.459901362657547,
            "relevance": 2
          },
          {
            "score": 0.44858023524284363,
            "relevance": 1
          },
          {
            "score": 0.44292786717414856,
            "relevance": 4
          },
          {
            "score": 0.4359563887119293,
            "relevance": 3
          },
          {
            "score": 0.4257889688014984,
            "relevance": 5
          },
          {
            "score": 0.41866058111190796,
            "relevance": 2
          },
          {
            "score": 0.4066077172756195,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.19171814551138863
        }
      }
    },
    "thresh_0.090_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7808873057365417,
            "relevance": 5
          },
          {
            "score": 0.7807163000106812,
            "relevance": 1
          },
          {
            "score": 0.7803055047988892,
            "relevance": 3
          },
          {
            "score": 0.7781915664672852,
            "relevance": 5
          },
          {
            "score": 0.7780174612998962,
            "relevance": 2
          },
          {
            "score": 0.7778468132019043,
            "relevance": 4
          },
          {
            "score": 0.7775669097900391,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6050920140147794
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5861022472381592,
            "relevance": 2
          },
          {
            "score": 0.5690244436264038,
            "relevance": 1
          },
          {
            "score": 0.5580580234527588,
            "relevance": 4
          },
          {
            "score": 0.5377429723739624,
            "relevance": 3
          },
          {
            "score": 0.5215568542480469,
            "relevance": 5
          },
          {
            "score": 0.5111881494522095,
            "relevance": 2
          },
          {
            "score": 0.4892524778842926,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.19171814551138863
        }
      }
    },
    "thresh_0.090_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7808873057365417,
            "relevance": 5
          },
          {
            "score": 0.7807163000106812,
            "relevance": 1
          },
          {
            "score": 0.7803055047988892,
            "relevance": 3
          },
          {
            "score": 0.7781915664672852,
            "relevance": 5
          },
          {
            "score": 0.7780174612998962,
            "relevance": 2
          },
          {
            "score": 0.7778468132019043,
            "relevance": 4
          },
          {
            "score": 0.7775669097900391,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6050920140147794
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6538928747177124,
            "relevance": 2
          },
          {
            "score": 0.6344531774520874,
            "relevance": 1
          },
          {
            "score": 0.6212048530578613,
            "relevance": 4
          },
          {
            "score": 0.5947773456573486,
            "relevance": 3
          },
          {
            "score": 0.5756744146347046,
            "relevance": 5
          },
          {
            "score": 0.5636982917785645,
            "relevance": 2
          },
          {
            "score": 0.5367143154144287,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.19171814551138863
        }
      }
    },
    "thresh_0.090_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7808873057365417,
            "relevance": 5
          },
          {
            "score": 0.7807163000106812,
            "relevance": 1
          },
          {
            "score": 0.7803055047988892,
            "relevance": 3
          },
          {
            "score": 0.7781915664672852,
            "relevance": 5
          },
          {
            "score": 0.7780174612998962,
            "relevance": 2
          },
          {
            "score": 0.7778468132019043,
            "relevance": 4
          },
          {
            "score": 0.7775669097900391,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6050920140147794
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.733121395111084,
            "relevance": 2
          },
          {
            "score": 0.7119076251983643,
            "relevance": 1
          },
          {
            "score": 0.6967916488647461,
            "relevance": 4
          },
          {
            "score": 0.6647709608078003,
            "relevance": 3
          },
          {
            "score": 0.6427549123764038,
            "relevance": 5
          },
          {
            "score": 0.6291171312332153,
            "relevance": 2
          },
          {
            "score": 0.5966895818710327,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.19171814551138863
        }
      }
    },
    "thresh_0.100_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7808873057365417,
            "relevance": 5
          },
          {
            "score": 0.7807163000106812,
            "relevance": 1
          },
          {
            "score": 0.7803055047988892,
            "relevance": 3
          },
          {
            "score": 0.7781915664672852,
            "relevance": 5
          },
          {
            "score": 0.7780174612998962,
            "relevance": 2
          },
          {
            "score": 0.7778468132019043,
            "relevance": 4
          },
          {
            "score": 0.7775669097900391,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6050920140147794
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.46026599407196045,
            "relevance": 2
          },
          {
            "score": 0.4489126205444336,
            "relevance": 1
          },
          {
            "score": 0.4432024359703064,
            "relevance": 4
          },
          {
            "score": 0.4360533654689789,
            "relevance": 3
          },
          {
            "score": 0.4258672595024109,
            "relevance": 5
          },
          {
            "score": 0.4187418818473816,
            "relevance": 2
          },
          {
            "score": 0.4066363275051117,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.19171814551138863
        }
      }
    },
    "thresh_0.100_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7808873057365417,
            "relevance": 5
          },
          {
            "score": 0.7807163000106812,
            "relevance": 1
          },
          {
            "score": 0.7803055047988892,
            "relevance": 3
          },
          {
            "score": 0.7781915664672852,
            "relevance": 5
          },
          {
            "score": 0.7780174612998962,
            "relevance": 2
          },
          {
            "score": 0.7778468132019043,
            "relevance": 4
          },
          {
            "score": 0.7775669097900391,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6050920140147794
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5727506875991821,
            "relevance": 2
          },
          {
            "score": 0.5552510023117065,
            "relevance": 1
          },
          {
            "score": 0.5438904166221619,
            "relevance": 4
          },
          {
            "score": 0.5226435661315918,
            "relevance": 3
          },
          {
            "score": 0.506138265132904,
            "relevance": 5
          },
          {
            "score": 0.49562060832977295,
            "relevance": 2
          },
          {
            "score": 0.47320976853370667,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.19171814551138863
        }
      }
    },
    "thresh_0.100_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7808873057365417,
            "relevance": 5
          },
          {
            "score": 0.7807163000106812,
            "relevance": 1
          },
          {
            "score": 0.7803055047988892,
            "relevance": 3
          },
          {
            "score": 0.7781915664672852,
            "relevance": 5
          },
          {
            "score": 0.7780174612998962,
            "relevance": 2
          },
          {
            "score": 0.7778468132019043,
            "relevance": 4
          },
          {
            "score": 0.7775669097900391,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6050920140147794
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6347277164459229,
            "relevance": 2
          },
          {
            "score": 0.6144282817840576,
            "relevance": 1
          },
          {
            "score": 0.600399374961853,
            "relevance": 4
          },
          {
            "score": 0.572145938873291,
            "relevance": 3
          },
          {
            "score": 0.5523573160171509,
            "relevance": 5
          },
          {
            "score": 0.540044367313385,
            "relevance": 2
          },
          {
            "score": 0.5120548009872437,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.19171814551138863
        }
      }
    },
    "thresh_0.100_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7808873057365417,
            "relevance": 5
          },
          {
            "score": 0.7807163000106812,
            "relevance": 1
          },
          {
            "score": 0.7803055047988892,
            "relevance": 3
          },
          {
            "score": 0.7781915664672852,
            "relevance": 5
          },
          {
            "score": 0.7780174612998962,
            "relevance": 2
          },
          {
            "score": 0.7778468132019043,
            "relevance": 4
          },
          {
            "score": 0.7775669097900391,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6050920140147794
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7093056440353394,
            "relevance": 2
          },
          {
            "score": 0.6864687204360962,
            "relevance": 1
          },
          {
            "score": 0.6698786020278931,
            "relevance": 4
          },
          {
            "score": 0.6343599557876587,
            "relevance": 3
          },
          {
            "score": 0.6109453439712524,
            "relevance": 5
          },
          {
            "score": 0.5965996980667114,
            "relevance": 2
          },
          {
            "score": 0.5620952844619751,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.19171814551138863
        }
      }
    },
    "thresh_0.110_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7808873057365417,
            "relevance": 5
          },
          {
            "score": 0.7807163000106812,
            "relevance": 1
          },
          {
            "score": 0.7803055047988892,
            "relevance": 3
          },
          {
            "score": 0.7781915664672852,
            "relevance": 5
          },
          {
            "score": 0.7780174612998962,
            "relevance": 2
          },
          {
            "score": 0.7778468132019043,
            "relevance": 4
          },
          {
            "score": 0.7775669097900391,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6050920140147794
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.46033138036727905,
            "relevance": 2
          },
          {
            "score": 0.4489639699459076,
            "relevance": 1
          },
          {
            "score": 0.4432024657726288,
            "relevance": 4
          },
          {
            "score": 0.4358775019645691,
            "relevance": 3
          },
          {
            "score": 0.4256889224052429,
            "relevance": 5
          },
          {
            "score": 0.4185788631439209,
            "relevance": 2
          },
          {
            "score": 0.4064379036426544,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.19171814551138863
        }
      }
    },
    "thresh_0.110_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7808873057365417,
            "relevance": 5
          },
          {
            "score": 0.7807163000106812,
            "relevance": 1
          },
          {
            "score": 0.7803055047988892,
            "relevance": 3
          },
          {
            "score": 0.7781915664672852,
            "relevance": 5
          },
          {
            "score": 0.7780174612998962,
            "relevance": 2
          },
          {
            "score": 0.7778468132019043,
            "relevance": 4
          },
          {
            "score": 0.7775669097900391,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6050920140147794
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5582143664360046,
            "relevance": 2
          },
          {
            "score": 0.5403492450714111,
            "relevance": 1
          },
          {
            "score": 0.5286372900009155,
            "relevance": 4
          },
          {
            "score": 0.5065577626228333,
            "relevance": 3
          },
          {
            "score": 0.48979610204696655,
            "relevance": 5
          },
          {
            "score": 0.479167103767395,
            "relevance": 2
          },
          {
            "score": 0.45637771487236023,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.19171814551138863
        }
      }
    },
    "thresh_0.110_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7808873057365417,
            "relevance": 5
          },
          {
            "score": 0.7807163000106812,
            "relevance": 1
          },
          {
            "score": 0.7803055047988892,
            "relevance": 3
          },
          {
            "score": 0.7781915664672852,
            "relevance": 5
          },
          {
            "score": 0.7780174612998962,
            "relevance": 2
          },
          {
            "score": 0.7778468132019043,
            "relevance": 4
          },
          {
            "score": 0.7775669097900391,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6050920140147794
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6133674383163452,
            "relevance": 2
          },
          {
            "score": 0.5922870635986328,
            "relevance": 1
          },
          {
            "score": 0.5775457620620728,
            "relevance": 4
          },
          {
            "score": 0.5476475954055786,
            "relevance": 3
          },
          {
            "score": 0.5272805094718933,
            "relevance": 5
          },
          {
            "score": 0.5146943926811218,
            "relevance": 2
          },
          {
            "score": 0.4858814775943756,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.19171814551138863
        }
      }
    },
    "thresh_0.110_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7808873057365417,
            "relevance": 5
          },
          {
            "score": 0.7807163000106812,
            "relevance": 1
          },
          {
            "score": 0.7803055047988892,
            "relevance": 3
          },
          {
            "score": 0.7781915664672852,
            "relevance": 5
          },
          {
            "score": 0.7780174612998962,
            "relevance": 2
          },
          {
            "score": 0.7778468132019043,
            "relevance": 4
          },
          {
            "score": 0.7775669097900391,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6050920140147794
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6814976930618286,
            "relevance": 2
          },
          {
            "score": 0.6571052074432373,
            "relevance": 1
          },
          {
            "score": 0.6391129493713379,
            "relevance": 4
          },
          {
            "score": 0.600342869758606,
            "relevance": 3
          },
          {
            "score": 0.5756914019584656,
            "relevance": 5
          },
          {
            "score": 0.5607368350028992,
            "relevance": 2
          },
          {
            "score": 0.5244715213775635,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.19171814551138863
        }
      }
    },
    "thresh_0.120_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7808873057365417,
            "relevance": 5
          },
          {
            "score": 0.7807163000106812,
            "relevance": 1
          },
          {
            "score": 0.7803055047988892,
            "relevance": 3
          },
          {
            "score": 0.7781915664672852,
            "relevance": 5
          },
          {
            "score": 0.7780174612998962,
            "relevance": 2
          },
          {
            "score": 0.7778468132019043,
            "relevance": 4
          },
          {
            "score": 0.7775669097900391,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6050920140147794
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.4600779712200165,
            "relevance": 2
          },
          {
            "score": 0.4487146735191345,
            "relevance": 1
          },
          {
            "score": 0.44290873408317566,
            "relevance": 4
          },
          {
            "score": 0.4354104995727539,
            "relevance": 3
          },
          {
            "score": 0.4252355396747589,
            "relevance": 5
          },
          {
            "score": 0.4181530475616455,
            "relevance": 2
          },
          {
            "score": 0.40599387884140015,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.19171814551138863
        }
      }
    },
    "thresh_0.120_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7808873057365417,
            "relevance": 5
          },
          {
            "score": 0.7807163000106812,
            "relevance": 1
          },
          {
            "score": 0.7803055047988892,
            "relevance": 3
          },
          {
            "score": 0.7781915664672852,
            "relevance": 5
          },
          {
            "score": 0.7780174612998962,
            "relevance": 2
          },
          {
            "score": 0.7778468132019043,
            "relevance": 4
          },
          {
            "score": 0.7775669097900391,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6050920140147794
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5425668954849243,
            "relevance": 2
          },
          {
            "score": 0.5243992805480957,
            "relevance": 1
          },
          {
            "score": 0.5123854875564575,
            "relevance": 4
          },
          {
            "score": 0.48958659172058105,
            "relevance": 3
          },
          {
            "score": 0.472635954618454,
            "relevance": 5
          },
          {
            "score": 0.46193617582321167,
            "relevance": 2
          },
          {
            "score": 0.43887192010879517,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.19171814551138863
        }
      }
    },
    "thresh_0.120_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7808873057365417,
            "relevance": 5
          },
          {
            "score": 0.7807163000106812,
            "relevance": 1
          },
          {
            "score": 0.7803055047988892,
            "relevance": 3
          },
          {
            "score": 0.7781915664672852,
            "relevance": 5
          },
          {
            "score": 0.7780174612998962,
            "relevance": 2
          },
          {
            "score": 0.7778468132019043,
            "relevance": 4
          },
          {
            "score": 0.7775669097900391,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6050920140147794
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5899474620819092,
            "relevance": 2
          },
          {
            "score": 0.5681861042976379,
            "relevance": 1
          },
          {
            "score": 0.5528203248977661,
            "relevance": 4
          },
          {
            "score": 0.5215038061141968,
            "relevance": 3
          },
          {
            "score": 0.5006831884384155,
            "relevance": 5
          },
          {
            "score": 0.4878966212272644,
            "relevance": 2
          },
          {
            "score": 0.4584681987762451,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.19171814551138863
        }
      }
    },
    "thresh_0.120_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7808873057365417,
            "relevance": 5
          },
          {
            "score": 0.7807163000106812,
            "relevance": 1
          },
          {
            "score": 0.7803055047988892,
            "relevance": 3
          },
          {
            "score": 0.7781915664672852,
            "relevance": 5
          },
          {
            "score": 0.7780174612998962,
            "relevance": 2
          },
          {
            "score": 0.7778468132019043,
            "relevance": 4
          },
          {
            "score": 0.7775669097900391,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6050920140147794
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6498324871063232,
            "relevance": 2
          },
          {
            "score": 0.6240121126174927,
            "relevance": 1
          },
          {
            "score": 0.6047455072402954,
            "relevance": 4
          },
          {
            "score": 0.5631069540977478,
            "relevance": 3
          },
          {
            "score": 0.5374387502670288,
            "relevance": 5
          },
          {
            "score": 0.5220047235488892,
            "relevance": 2
          },
          {
            "score": 0.4843812584877014,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.19171814551138863
        }
      }
    },
    "thresh_0.130_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7808873057365417,
            "relevance": 5
          },
          {
            "score": 0.7807163000106812,
            "relevance": 1
          },
          {
            "score": 0.7803055047988892,
            "relevance": 3
          },
          {
            "score": 0.7781915664672852,
            "relevance": 5
          },
          {
            "score": 0.7780174612998962,
            "relevance": 2
          },
          {
            "score": 0.7778468132019043,
            "relevance": 4
          },
          {
            "score": 0.7775669097900391,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6050920140147794
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.45948857069015503,
            "relevance": 2
          },
          {
            "score": 0.4481472969055176,
            "relevance": 1
          },
          {
            "score": 0.4423038363456726,
            "relevance": 4
          },
          {
            "score": 0.43463650345802307,
            "relevance": 3
          },
          {
            "score": 0.4244910776615143,
            "relevance": 5
          },
          {
            "score": 0.4174480140209198,
            "relevance": 2
          },
          {
            "score": 0.4052879214286804,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.19171814551138863
        }
      }
    },
    "thresh_0.130_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7808873057365417,
            "relevance": 5
          },
          {
            "score": 0.7807163000106812,
            "relevance": 1
          },
          {
            "score": 0.7803055047988892,
            "relevance": 3
          },
          {
            "score": 0.7781915664672852,
            "relevance": 5
          },
          {
            "score": 0.7780174612998962,
            "relevance": 2
          },
          {
            "score": 0.7778468132019043,
            "relevance": 4
          },
          {
            "score": 0.7775669097900391,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6050920140147794
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5259000062942505,
            "relevance": 2
          },
          {
            "score": 0.5074985027313232,
            "relevance": 1
          },
          {
            "score": 0.4952375292778015,
            "relevance": 4
          },
          {
            "score": 0.47184547781944275,
            "relevance": 3
          },
          {
            "score": 0.4547775685787201,
            "relevance": 5
          },
          {
            "score": 0.44404879212379456,
            "relevance": 2
          },
          {
            "score": 0.4208192825317383,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.19171814551138863
        }
      }
    },
    "thresh_0.130_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7808873057365417,
            "relevance": 5
          },
          {
            "score": 0.7807163000106812,
            "relevance": 1
          },
          {
            "score": 0.7803055047988892,
            "relevance": 3
          },
          {
            "score": 0.7781915664672852,
            "relevance": 5
          },
          {
            "score": 0.7780174612998962,
            "relevance": 2
          },
          {
            "score": 0.7778468132019043,
            "relevance": 4
          },
          {
            "score": 0.7775669097900391,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6050920140147794
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5646560192108154,
            "relevance": 2
          },
          {
            "score": 0.5423336625099182,
            "relevance": 1
          },
          {
            "score": 0.5264492034912109,
            "relevance": 4
          },
          {
            "score": 0.49398139119148254,
            "relevance": 3
          },
          {
            "score": 0.47284749150276184,
            "relevance": 5
          },
          {
            "score": 0.4599403440952301,
            "relevance": 2
          },
          {
            "score": 0.4301244020462036,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.19171814551138863
        }
      }
    },
    "thresh_0.130_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7808873057365417,
            "relevance": 5
          },
          {
            "score": 0.7807163000106812,
            "relevance": 1
          },
          {
            "score": 0.7803055047988892,
            "relevance": 3
          },
          {
            "score": 0.7781915664672852,
            "relevance": 5
          },
          {
            "score": 0.7780174612998962,
            "relevance": 2
          },
          {
            "score": 0.7778468132019043,
            "relevance": 4
          },
          {
            "score": 0.7775669097900391,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6050920140147794
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6145901083946228,
            "relevance": 2
          },
          {
            "score": 0.5875318050384521,
            "relevance": 1
          },
          {
            "score": 0.5671750903129578,
            "relevance": 4
          },
          {
            "score": 0.5231844186782837,
            "relevance": 3
          },
          {
            "score": 0.49677225947380066,
            "relevance": 5
          },
          {
            "score": 0.4810146987438202,
            "relevance": 2
          },
          {
            "score": 0.4425084590911865,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.19171814551138863
        }
      }
    }
  },
  "S07": {
    "thresh_0.090_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7788088321685791,
            "relevance": 3
          },
          {
            "score": 0.7787706851959229,
            "relevance": 4
          },
          {
            "score": 0.7781739234924316,
            "relevance": 2
          },
          {
            "score": 0.7772637605667114,
            "relevance": 1
          },
          {
            "score": 0.7768105864524841,
            "relevance": 2
          },
          {
            "score": 0.7759285569190979,
            "relevance": 5
          },
          {
            "score": 0.7751592993736267,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.30940941571227865
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.48339805006980896,
            "relevance": 1
          },
          {
            "score": 0.4610486924648285,
            "relevance": 2
          },
          {
            "score": 0.4583064615726471,
            "relevance": 5
          },
          {
            "score": 0.45750293135643005,
            "relevance": 5
          },
          {
            "score": 0.4552970230579376,
            "relevance": 2
          },
          {
            "score": 0.4490760266780853,
            "relevance": 4
          },
          {
            "score": 0.4450961649417877,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.090_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7788088321685791,
            "relevance": 3
          },
          {
            "score": 0.7787706851959229,
            "relevance": 4
          },
          {
            "score": 0.7781739234924316,
            "relevance": 2
          },
          {
            "score": 0.7772637605667114,
            "relevance": 1
          },
          {
            "score": 0.7768105864524841,
            "relevance": 2
          },
          {
            "score": 0.7759285569190979,
            "relevance": 5
          },
          {
            "score": 0.7751592993736267,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.30940941571227865
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6077240705490112,
            "relevance": 1
          },
          {
            "score": 0.563524603843689,
            "relevance": 2
          },
          {
            "score": 0.558549165725708,
            "relevance": 5
          },
          {
            "score": 0.5517195463180542,
            "relevance": 5
          },
          {
            "score": 0.5474169254302979,
            "relevance": 2
          },
          {
            "score": 0.5386327505111694,
            "relevance": 4
          },
          {
            "score": 0.5291297435760498,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.090_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7788088321685791,
            "relevance": 3
          },
          {
            "score": 0.7787706851959229,
            "relevance": 4
          },
          {
            "score": 0.7781739234924316,
            "relevance": 2
          },
          {
            "score": 0.7772637605667114,
            "relevance": 1
          },
          {
            "score": 0.7768105864524841,
            "relevance": 2
          },
          {
            "score": 0.7759285569190979,
            "relevance": 5
          },
          {
            "score": 0.7751592993736267,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.30940941571227865
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6747585535049438,
            "relevance": 1
          },
          {
            "score": 0.6208871603012085,
            "relevance": 2
          },
          {
            "score": 0.6148442029953003,
            "relevance": 5
          },
          {
            "score": 0.6050707101821899,
            "relevance": 5
          },
          {
            "score": 0.5997231006622314,
            "relevance": 2
          },
          {
            "score": 0.5896478891372681,
            "relevance": 4
          },
          {
            "score": 0.5773135423660278,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.090_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7788088321685791,
            "relevance": 3
          },
          {
            "score": 0.7787706851959229,
            "relevance": 4
          },
          {
            "score": 0.7781739234924316,
            "relevance": 2
          },
          {
            "score": 0.7772637605667114,
            "relevance": 1
          },
          {
            "score": 0.7768105864524841,
            "relevance": 2
          },
          {
            "score": 0.7759285569190979,
            "relevance": 5
          },
          {
            "score": 0.7751592993736267,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.30940941571227865
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7534384727478027,
            "relevance": 1
          },
          {
            "score": 0.6911996603012085,
            "relevance": 2
          },
          {
            "score": 0.6841126680374146,
            "relevance": 5
          },
          {
            "score": 0.6713635921478271,
            "relevance": 5
          },
          {
            "score": 0.6649285554885864,
            "relevance": 2
          },
          {
            "score": 0.6534886360168457,
            "relevance": 4
          },
          {
            "score": 0.6380864381790161,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.100_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7788088321685791,
            "relevance": 3
          },
          {
            "score": 0.7787706851959229,
            "relevance": 4
          },
          {
            "score": 0.7781739234924316,
            "relevance": 2
          },
          {
            "score": 0.7772637605667114,
            "relevance": 1
          },
          {
            "score": 0.7768105864524841,
            "relevance": 2
          },
          {
            "score": 0.7759285569190979,
            "relevance": 5
          },
          {
            "score": 0.7751592993736267,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.30940941571227865
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.483511745929718,
            "relevance": 1
          },
          {
            "score": 0.4609248638153076,
            "relevance": 2
          },
          {
            "score": 0.4581679701805115,
            "relevance": 5
          },
          {
            "score": 0.45725610852241516,
            "relevance": 5
          },
          {
            "score": 0.45503512024879456,
            "relevance": 2
          },
          {
            "score": 0.448836088180542,
            "relevance": 4
          },
          {
            "score": 0.44480106234550476,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.100_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7788088321685791,
            "relevance": 3
          },
          {
            "score": 0.7787706851959229,
            "relevance": 4
          },
          {
            "score": 0.7781739234924316,
            "relevance": 2
          },
          {
            "score": 0.7772637605667114,
            "relevance": 1
          },
          {
            "score": 0.7768105864524841,
            "relevance": 2
          },
          {
            "score": 0.7759285569190979,
            "relevance": 5
          },
          {
            "score": 0.7751592993736267,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.30940941571227865
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5939916372299194,
            "relevance": 1
          },
          {
            "score": 0.5482403039932251,
            "relevance": 2
          },
          {
            "score": 0.5431349277496338,
            "relevance": 5
          },
          {
            "score": 0.5359023809432983,
            "relevance": 5
          },
          {
            "score": 0.5314875841140747,
            "relevance": 2
          },
          {
            "score": 0.5226107835769653,
            "relevance": 4
          },
          {
            "score": 0.5128190517425537,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.100_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7788088321685791,
            "relevance": 3
          },
          {
            "score": 0.7787706851959229,
            "relevance": 4
          },
          {
            "score": 0.7781739234924316,
            "relevance": 2
          },
          {
            "score": 0.7772637605667114,
            "relevance": 1
          },
          {
            "score": 0.7768105864524841,
            "relevance": 2
          },
          {
            "score": 0.7759285569190979,
            "relevance": 5
          },
          {
            "score": 0.7751592993736267,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.30940941571227865
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6550676822662354,
            "relevance": 1
          },
          {
            "score": 0.5981144309043884,
            "relevance": 2
          },
          {
            "score": 0.5918017625808716,
            "relevance": 5
          },
          {
            "score": 0.5812642574310303,
            "relevance": 5
          },
          {
            "score": 0.5756844282150269,
            "relevance": 2
          },
          {
            "score": 0.5653733611106873,
            "relevance": 4
          },
          {
            "score": 0.5524566173553467,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.100_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7788088321685791,
            "relevance": 3
          },
          {
            "score": 0.7787706851959229,
            "relevance": 4
          },
          {
            "score": 0.7781739234924316,
            "relevance": 2
          },
          {
            "score": 0.7772637605667114,
            "relevance": 1
          },
          {
            "score": 0.7768105864524841,
            "relevance": 2
          },
          {
            "score": 0.7759285569190979,
            "relevance": 5
          },
          {
            "score": 0.7751592993736267,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.30940941571227865
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7288472652435303,
            "relevance": 1
          },
          {
            "score": 0.6607306599617004,
            "relevance": 2
          },
          {
            "score": 0.6531049013137817,
            "relevance": 5
          },
          {
            "score": 0.6388857364654541,
            "relevance": 5
          },
          {
            "score": 0.6319799423217773,
            "relevance": 2
          },
          {
            "score": 0.620018482208252,
            "relevance": 4
          },
          {
            "score": 0.6034395694732666,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.110_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7788088321685791,
            "relevance": 3
          },
          {
            "score": 0.7787706851959229,
            "relevance": 4
          },
          {
            "score": 0.7781739234924316,
            "relevance": 2
          },
          {
            "score": 0.7772637605667114,
            "relevance": 1
          },
          {
            "score": 0.7768105864524841,
            "relevance": 2
          },
          {
            "score": 0.7759285569190979,
            "relevance": 5
          },
          {
            "score": 0.7751592993736267,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.30940941571227865
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.48327410221099854,
            "relevance": 1
          },
          {
            "score": 0.46047571301460266,
            "relevance": 2
          },
          {
            "score": 0.4577080011367798,
            "relevance": 5
          },
          {
            "score": 0.45668426156044006,
            "relevance": 5
          },
          {
            "score": 0.4544510543346405,
            "relevance": 2
          },
          {
            "score": 0.4482845962047577,
            "relevance": 4
          },
          {
            "score": 0.4441981613636017,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.110_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7788088321685791,
            "relevance": 3
          },
          {
            "score": 0.7787706851959229,
            "relevance": 4
          },
          {
            "score": 0.7781739234924316,
            "relevance": 2
          },
          {
            "score": 0.7772637605667114,
            "relevance": 1
          },
          {
            "score": 0.7768105864524841,
            "relevance": 2
          },
          {
            "score": 0.7759285569190979,
            "relevance": 5
          },
          {
            "score": 0.7751592993736267,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.30940941571227865
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5790346264839172,
            "relevance": 1
          },
          {
            "score": 0.5319119691848755,
            "relevance": 2
          },
          {
            "score": 0.5266973376274109,
            "relevance": 5
          },
          {
            "score": 0.519105076789856,
            "relevance": 5
          },
          {
            "score": 0.5145976543426514,
            "relevance": 2
          },
          {
            "score": 0.5056591033935547,
            "relevance": 4
          },
          {
            "score": 0.49562689661979675,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.110_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7788088321685791,
            "relevance": 3
          },
          {
            "score": 0.7787706851959229,
            "relevance": 4
          },
          {
            "score": 0.7781739234924316,
            "relevance": 2
          },
          {
            "score": 0.7772637605667114,
            "relevance": 1
          },
          {
            "score": 0.7768105864524841,
            "relevance": 2
          },
          {
            "score": 0.7759285569190979,
            "relevance": 5
          },
          {
            "score": 0.7751592993736267,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.30940941571227865
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6331485509872437,
            "relevance": 1
          },
          {
            "score": 0.5734119415283203,
            "relevance": 2
          },
          {
            "score": 0.5668663382530212,
            "relevance": 5
          },
          {
            "score": 0.5556538105010986,
            "relevance": 5
          },
          {
            "score": 0.5498780012130737,
            "relevance": 2
          },
          {
            "score": 0.5393836498260498,
            "relevance": 4
          },
          {
            "score": 0.5259813070297241,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.110_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7788088321685791,
            "relevance": 3
          },
          {
            "score": 0.7787706851959229,
            "relevance": 4
          },
          {
            "score": 0.7781739234924316,
            "relevance": 2
          },
          {
            "score": 0.7772637605667114,
            "relevance": 1
          },
          {
            "score": 0.7768105864524841,
            "relevance": 2
          },
          {
            "score": 0.7759285569190979,
            "relevance": 5
          },
          {
            "score": 0.7751592993736267,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.30940941571227865
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7002253532409668,
            "relevance": 1
          },
          {
            "score": 0.6265878677368164,
            "relevance": 2
          },
          {
            "score": 0.6184777021408081,
            "relevance": 5
          },
          {
            "score": 0.6029359102249146,
            "relevance": 5
          },
          {
            "score": 0.5956194400787354,
            "relevance": 2
          },
          {
            "score": 0.5832202434539795,
            "relevance": 4
          },
          {
            "score": 0.5656373500823975,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.120_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7788088321685791,
            "relevance": 3
          },
          {
            "score": 0.7787706851959229,
            "relevance": 4
          },
          {
            "score": 0.7781739234924316,
            "relevance": 2
          },
          {
            "score": 0.7772637605667114,
            "relevance": 1
          },
          {
            "score": 0.7768105864524841,
            "relevance": 2
          },
          {
            "score": 0.7759285569190979,
            "relevance": 5
          },
          {
            "score": 0.7751592993736267,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.30940941571227865
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.4826681613922119,
            "relevance": 1
          },
          {
            "score": 0.45968541502952576,
            "relevance": 2
          },
          {
            "score": 0.4569106996059418,
            "relevance": 5
          },
          {
            "score": 0.45577263832092285,
            "relevance": 5
          },
          {
            "score": 0.4535299241542816,
            "relevance": 2
          },
          {
            "score": 0.4474065601825714,
            "relevance": 4
          },
          {
            "score": 0.4432728588581085,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.120_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7788088321685791,
            "relevance": 3
          },
          {
            "score": 0.7787706851959229,
            "relevance": 4
          },
          {
            "score": 0.7781739234924316,
            "relevance": 2
          },
          {
            "score": 0.7772637605667114,
            "relevance": 1
          },
          {
            "score": 0.7768105864524841,
            "relevance": 2
          },
          {
            "score": 0.7759285569190979,
            "relevance": 5
          },
          {
            "score": 0.7751592993736267,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.30940941571227865
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5629315972328186,
            "relevance": 1
          },
          {
            "score": 0.5146424770355225,
            "relevance": 2
          },
          {
            "score": 0.5093414783477783,
            "relevance": 5
          },
          {
            "score": 0.5014386177062988,
            "relevance": 5
          },
          {
            "score": 0.49685946106910706,
            "relevance": 2
          },
          {
            "score": 0.48789182305336,
            "relevance": 4
          },
          {
            "score": 0.47767195105552673,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.120_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7788088321685791,
            "relevance": 3
          },
          {
            "score": 0.7787706851959229,
            "relevance": 4
          },
          {
            "score": 0.7781739234924316,
            "relevance": 2
          },
          {
            "score": 0.7772637605667114,
            "relevance": 1
          },
          {
            "score": 0.7768105864524841,
            "relevance": 2
          },
          {
            "score": 0.7759285569190979,
            "relevance": 5
          },
          {
            "score": 0.7751592993736267,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.30940941571227865
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6091464161872864,
            "relevance": 1
          },
          {
            "score": 0.5470020771026611,
            "relevance": 2
          },
          {
            "score": 0.5402668714523315,
            "relevance": 5
          },
          {
            "score": 0.5284870862960815,
            "relevance": 5
          },
          {
            "score": 0.5225573778152466,
            "relevance": 2
          },
          {
            "score": 0.5119386911392212,
            "relevance": 4
          },
          {
            "score": 0.4981618821620941,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.120_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7788088321685791,
            "relevance": 3
          },
          {
            "score": 0.7787706851959229,
            "relevance": 4
          },
          {
            "score": 0.7781739234924316,
            "relevance": 2
          },
          {
            "score": 0.7772637605667114,
            "relevance": 1
          },
          {
            "score": 0.7768105864524841,
            "relevance": 2
          },
          {
            "score": 0.7759285569190979,
            "relevance": 5
          },
          {
            "score": 0.7751592993736267,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.30940941571227865
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6677299737930298,
            "relevance": 1
          },
          {
            "score": 0.5891540050506592,
            "relevance": 2
          },
          {
            "score": 0.5806361436843872,
            "relevance": 5
          },
          {
            "score": 0.5639780163764954,
            "relevance": 5
          },
          {
            "score": 0.5563308000564575,
            "relevance": 2
          },
          {
            "score": 0.5436005592346191,
            "relevance": 4
          },
          {
            "score": 0.5252354145050049,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.130_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7788088321685791,
            "relevance": 3
          },
          {
            "score": 0.7787706851959229,
            "relevance": 4
          },
          {
            "score": 0.7781739234924316,
            "relevance": 2
          },
          {
            "score": 0.7772637605667114,
            "relevance": 1
          },
          {
            "score": 0.7768105864524841,
            "relevance": 2
          },
          {
            "score": 0.7759285569190979,
            "relevance": 5
          },
          {
            "score": 0.7751592993736267,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.30940941571227865
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.48168015480041504,
            "relevance": 1
          },
          {
            "score": 0.4585410952568054,
            "relevance": 2
          },
          {
            "score": 0.4557630717754364,
            "relevance": 5
          },
          {
            "score": 0.4545091390609741,
            "relevance": 5
          },
          {
            "score": 0.4522601366043091,
            "relevance": 2
          },
          {
            "score": 0.4461895823478699,
            "relevance": 4
          },
          {
            "score": 0.442013144493103,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.130_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7788088321685791,
            "relevance": 3
          },
          {
            "score": 0.7787706851959229,
            "relevance": 4
          },
          {
            "score": 0.7781739234924316,
            "relevance": 2
          },
          {
            "score": 0.7772637605667114,
            "relevance": 1
          },
          {
            "score": 0.7768105864524841,
            "relevance": 2
          },
          {
            "score": 0.7759285569190979,
            "relevance": 5
          },
          {
            "score": 0.7751592993736267,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.30940941571227865
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.545779287815094,
            "relevance": 1
          },
          {
            "score": 0.4965495467185974,
            "relevance": 2
          },
          {
            "score": 0.49118664860725403,
            "relevance": 5
          },
          {
            "score": 0.48302769660949707,
            "relevance": 5
          },
          {
            "score": 0.4783993363380432,
            "relevance": 2
          },
          {
            "score": 0.4694363474845886,
            "relevance": 4
          },
          {
            "score": 0.4590848684310913,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.130_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7788088321685791,
            "relevance": 3
          },
          {
            "score": 0.7787706851959229,
            "relevance": 4
          },
          {
            "score": 0.7781739234924316,
            "relevance": 2
          },
          {
            "score": 0.7772637605667114,
            "relevance": 1
          },
          {
            "score": 0.7768105864524841,
            "relevance": 2
          },
          {
            "score": 0.7759285569190979,
            "relevance": 5
          },
          {
            "score": 0.7751592993736267,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.30940941571227865
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5832592844963074,
            "relevance": 1
          },
          {
            "score": 0.5191525816917419,
            "relevance": 2
          },
          {
            "score": 0.512277364730835,
            "relevance": 5
          },
          {
            "score": 0.5000537037849426,
            "relevance": 5
          },
          {
            "score": 0.4940173029899597,
            "relevance": 2
          },
          {
            "score": 0.48333829641342163,
            "relevance": 4
          },
          {
            "score": 0.46930962800979614,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    },
    "thresh_0.130_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7788088321685791,
            "relevance": 3
          },
          {
            "score": 0.7787706851959229,
            "relevance": 4
          },
          {
            "score": 0.7781739234924316,
            "relevance": 2
          },
          {
            "score": 0.7772637605667114,
            "relevance": 1
          },
          {
            "score": 0.7768105864524841,
            "relevance": 2
          },
          {
            "score": 0.7759285569190979,
            "relevance": 5
          },
          {
            "score": 0.7751592993736267,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.30940941571227865
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6316648125648499,
            "relevance": 1
          },
          {
            "score": 0.5489581227302551,
            "relevance": 2
          },
          {
            "score": 0.5401293039321899,
            "relevance": 5
          },
          {
            "score": 0.5226143002510071,
            "relevance": 5
          },
          {
            "score": 0.5147328972816467,
            "relevance": 2
          },
          {
            "score": 0.5017979741096497,
            "relevance": 4
          },
          {
            "score": 0.48291242122650146,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3167957687195467
        }
      }
    }
  },
  "S08": {
    "thresh_0.090_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.712925374507904,
            "relevance": 4
          },
          {
            "score": 0.7116575837135315,
            "relevance": 5
          },
          {
            "score": 0.7110669612884521,
            "relevance": 1
          },
          {
            "score": 0.7107012867927551,
            "relevance": 2
          },
          {
            "score": 0.7103370428085327,
            "relevance": 2
          },
          {
            "score": 0.7090172171592712,
            "relevance": 3
          },
          {
            "score": 0.7072470188140869,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5462774038314819,
            "relevance": 3
          },
          {
            "score": 0.5344274044036865,
            "relevance": 1
          },
          {
            "score": 0.5258476734161377,
            "relevance": 4
          },
          {
            "score": 0.525736927986145,
            "relevance": 5
          },
          {
            "score": 0.5176427364349365,
            "relevance": 2
          },
          {
            "score": 0.507677435874939,
            "relevance": 5
          },
          {
            "score": 0.5057482123374939,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.26061379026195375
        }
      }
    },
    "thresh_0.090_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.712925374507904,
            "relevance": 4
          },
          {
            "score": 0.7116575837135315,
            "relevance": 5
          },
          {
            "score": 0.7110669612884521,
            "relevance": 1
          },
          {
            "score": 0.7107012867927551,
            "relevance": 2
          },
          {
            "score": 0.7103370428085327,
            "relevance": 2
          },
          {
            "score": 0.7090172171592712,
            "relevance": 3
          },
          {
            "score": 0.7072470188140869,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.717566967010498,
            "relevance": 3
          },
          {
            "score": 0.7024810314178467,
            "relevance": 1
          },
          {
            "score": 0.6848629117012024,
            "relevance": 5
          },
          {
            "score": 0.6822656393051147,
            "relevance": 4
          },
          {
            "score": 0.6686201095581055,
            "relevance": 2
          },
          {
            "score": 0.6544768810272217,
            "relevance": 5
          },
          {
            "score": 0.6504023671150208,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.398405079763084
        }
      }
    },
    "thresh_0.090_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.712925374507904,
            "relevance": 4
          },
          {
            "score": 0.7116575837135315,
            "relevance": 5
          },
          {
            "score": 0.7110669612884521,
            "relevance": 1
          },
          {
            "score": 0.7107012867927551,
            "relevance": 2
          },
          {
            "score": 0.7103370428085327,
            "relevance": 2
          },
          {
            "score": 0.7090172171592712,
            "relevance": 3
          },
          {
            "score": 0.7072470188140869,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7984256744384766,
            "relevance": 3
          },
          {
            "score": 0.7828317880630493,
            "relevance": 1
          },
          {
            "score": 0.7633853554725647,
            "relevance": 5
          },
          {
            "score": 0.7601234912872314,
            "relevance": 4
          },
          {
            "score": 0.7450063228607178,
            "relevance": 2
          },
          {
            "score": 0.7296189069747925,
            "relevance": 5
          },
          {
            "score": 0.7248697876930237,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.398405079763084
        }
      }
    },
    "thresh_0.090_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.712925374507904,
            "relevance": 4
          },
          {
            "score": 0.7116575837135315,
            "relevance": 5
          },
          {
            "score": 0.7110669612884521,
            "relevance": 1
          },
          {
            "score": 0.7107012867927551,
            "relevance": 2
          },
          {
            "score": 0.7103370428085327,
            "relevance": 2
          },
          {
            "score": 0.7090172171592712,
            "relevance": 3
          },
          {
            "score": 0.7072470188140869,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8805873394012451,
            "relevance": 3
          },
          {
            "score": 0.8655672073364258,
            "relevance": 1
          },
          {
            "score": 0.8469741940498352,
            "relevance": 5
          },
          {
            "score": 0.8437765836715698,
            "relevance": 4
          },
          {
            "score": 0.8285363912582397,
            "relevance": 2
          },
          {
            "score": 0.812838077545166,
            "relevance": 5
          },
          {
            "score": 0.807859480381012,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.398405079763084
        }
      }
    },
    "thresh_0.100_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.712925374507904,
            "relevance": 4
          },
          {
            "score": 0.7116575837135315,
            "relevance": 5
          },
          {
            "score": 0.7110669612884521,
            "relevance": 1
          },
          {
            "score": 0.7107012867927551,
            "relevance": 2
          },
          {
            "score": 0.7103370428085327,
            "relevance": 2
          },
          {
            "score": 0.7090172171592712,
            "relevance": 3
          },
          {
            "score": 0.7072470188140869,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5472011566162109,
            "relevance": 3
          },
          {
            "score": 0.5353373885154724,
            "relevance": 1
          },
          {
            "score": 0.5264224410057068,
            "relevance": 4
          },
          {
            "score": 0.526405930519104,
            "relevance": 5
          },
          {
            "score": 0.5181254744529724,
            "relevance": 2
          },
          {
            "score": 0.5081348419189453,
            "relevance": 5
          },
          {
            "score": 0.5061626434326172,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.26061379026195375
        }
      }
    },
    "thresh_0.100_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.712925374507904,
            "relevance": 4
          },
          {
            "score": 0.7116575837135315,
            "relevance": 5
          },
          {
            "score": 0.7110669612884521,
            "relevance": 1
          },
          {
            "score": 0.7107012867927551,
            "relevance": 2
          },
          {
            "score": 0.7103370428085327,
            "relevance": 2
          },
          {
            "score": 0.7090172171592712,
            "relevance": 3
          },
          {
            "score": 0.7072470188140869,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7089598178863525,
            "relevance": 3
          },
          {
            "score": 0.6934728026390076,
            "relevance": 1
          },
          {
            "score": 0.6746306419372559,
            "relevance": 5
          },
          {
            "score": 0.6716631054878235,
            "relevance": 4
          },
          {
            "score": 0.6573982834815979,
            "relevance": 2
          },
          {
            "score": 0.642848014831543,
            "relevance": 5
          },
          {
            "score": 0.6385416984558105,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.398405079763084
        }
      }
    },
    "thresh_0.100_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.712925374507904,
            "relevance": 4
          },
          {
            "score": 0.7116575837135315,
            "relevance": 5
          },
          {
            "score": 0.7110669612884521,
            "relevance": 1
          },
          {
            "score": 0.7107012867927551,
            "relevance": 2
          },
          {
            "score": 0.7103370428085327,
            "relevance": 2
          },
          {
            "score": 0.7090172171592712,
            "relevance": 3
          },
          {
            "score": 0.7072470188140869,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7880814075469971,
            "relevance": 3
          },
          {
            "score": 0.7717575430870056,
            "relevance": 1
          },
          {
            "score": 0.7502076625823975,
            "relevance": 5
          },
          {
            "score": 0.7463172078132629,
            "relevance": 4
          },
          {
            "score": 0.7300733923912048,
            "relevance": 2
          },
          {
            "score": 0.7139004468917847,
            "relevance": 5
          },
          {
            "score": 0.7087286710739136,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.398405079763084
        }
      }
    },
    "thresh_0.100_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.712925374507904,
            "relevance": 4
          },
          {
            "score": 0.7116575837135315,
            "relevance": 5
          },
          {
            "score": 0.7110669612884521,
            "relevance": 1
          },
          {
            "score": 0.7107012867927551,
            "relevance": 2
          },
          {
            "score": 0.7103370428085327,
            "relevance": 2
          },
          {
            "score": 0.7090172171592712,
            "relevance": 3
          },
          {
            "score": 0.7072470188140869,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8715239763259888,
            "relevance": 3
          },
          {
            "score": 0.8553799986839294,
            "relevance": 1
          },
          {
            "score": 0.8335531949996948,
            "relevance": 5
          },
          {
            "score": 0.8293741345405579,
            "relevance": 4
          },
          {
            "score": 0.8122885823249817,
            "relevance": 2
          },
          {
            "score": 0.7952456474304199,
            "relevance": 5
          },
          {
            "score": 0.7895559072494507,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.398405079763084
        }
      }
    },
    "thresh_0.110_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.712925374507904,
            "relevance": 4
          },
          {
            "score": 0.7116575837135315,
            "relevance": 5
          },
          {
            "score": 0.7110669612884521,
            "relevance": 1
          },
          {
            "score": 0.7107012867927551,
            "relevance": 2
          },
          {
            "score": 0.7103370428085327,
            "relevance": 2
          },
          {
            "score": 0.7090172171592712,
            "relevance": 3
          },
          {
            "score": 0.7072470188140869,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5477025508880615,
            "relevance": 3
          },
          {
            "score": 0.5358446836471558,
            "relevance": 1
          },
          {
            "score": 0.526676595211029,
            "relevance": 5
          },
          {
            "score": 0.5265949964523315,
            "relevance": 4
          },
          {
            "score": 0.5182157754898071,
            "relevance": 2
          },
          {
            "score": 0.5082154870033264,
            "relevance": 5
          },
          {
            "score": 0.5062015056610107,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.398405079763084
        }
      }
    },
    "thresh_0.110_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.712925374507904,
            "relevance": 4
          },
          {
            "score": 0.7116575837135315,
            "relevance": 5
          },
          {
            "score": 0.7110669612884521,
            "relevance": 1
          },
          {
            "score": 0.7107012867927551,
            "relevance": 2
          },
          {
            "score": 0.7103370428085327,
            "relevance": 2
          },
          {
            "score": 0.7090172171592712,
            "relevance": 3
          },
          {
            "score": 0.7072470188140869,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6988377571105957,
            "relevance": 3
          },
          {
            "score": 0.6829768419265747,
            "relevance": 1
          },
          {
            "score": 0.6629427075386047,
            "relevance": 5
          },
          {
            "score": 0.6596113443374634,
            "relevance": 4
          },
          {
            "score": 0.6447603702545166,
            "relevance": 2
          },
          {
            "score": 0.6298383474349976,
            "relevance": 5
          },
          {
            "score": 0.6253125071525574,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.398405079763084
        }
      }
    },
    "thresh_0.110_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.712925374507904,
            "relevance": 4
          },
          {
            "score": 0.7116575837135315,
            "relevance": 5
          },
          {
            "score": 0.7110669612884521,
            "relevance": 1
          },
          {
            "score": 0.7107012867927551,
            "relevance": 2
          },
          {
            "score": 0.7103370428085327,
            "relevance": 2
          },
          {
            "score": 0.7090172171592712,
            "relevance": 3
          },
          {
            "score": 0.7072470188140869,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7752690315246582,
            "relevance": 3
          },
          {
            "score": 0.7582212686538696,
            "relevance": 1
          },
          {
            "score": 0.7345582842826843,
            "relevance": 5
          },
          {
            "score": 0.7300370931625366,
            "relevance": 4
          },
          {
            "score": 0.7126880884170532,
            "relevance": 2
          },
          {
            "score": 0.6957603693008423,
            "relevance": 5
          },
          {
            "score": 0.6901775002479553,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.398405079763084
        }
      }
    },
    "thresh_0.110_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.712925374507904,
            "relevance": 4
          },
          {
            "score": 0.7116575837135315,
            "relevance": 5
          },
          {
            "score": 0.7110669612884521,
            "relevance": 1
          },
          {
            "score": 0.7107012867927551,
            "relevance": 2
          },
          {
            "score": 0.7103370428085327,
            "relevance": 2
          },
          {
            "score": 0.7090172171592712,
            "relevance": 3
          },
          {
            "score": 0.7072470188140869,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8588073253631592,
            "relevance": 3
          },
          {
            "score": 0.841471791267395,
            "relevance": 1
          },
          {
            "score": 0.8162209391593933,
            "relevance": 5
          },
          {
            "score": 0.8110103607177734,
            "relevance": 4
          },
          {
            "score": 0.7920138835906982,
            "relevance": 2
          },
          {
            "score": 0.7735996246337891,
            "relevance": 5
          },
          {
            "score": 0.7671837210655212,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.398405079763084
        }
      }
    },
    "thresh_0.120_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.712925374507904,
            "relevance": 4
          },
          {
            "score": 0.7116575837135315,
            "relevance": 5
          },
          {
            "score": 0.7110669612884521,
            "relevance": 1
          },
          {
            "score": 0.7107012867927551,
            "relevance": 2
          },
          {
            "score": 0.7103370428085327,
            "relevance": 2
          },
          {
            "score": 0.7090172171592712,
            "relevance": 3
          },
          {
            "score": 0.7072470188140869,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5477615594863892,
            "relevance": 3
          },
          {
            "score": 0.53592848777771,
            "relevance": 1
          },
          {
            "score": 0.5265295505523682,
            "relevance": 5
          },
          {
            "score": 0.5263463854789734,
            "relevance": 4
          },
          {
            "score": 0.5178952217102051,
            "relevance": 2
          },
          {
            "score": 0.5079005360603333,
            "relevance": 5
          },
          {
            "score": 0.5058465600013733,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.398405079763084
        }
      }
    },
    "thresh_0.120_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.712925374507904,
            "relevance": 4
          },
          {
            "score": 0.7116575837135315,
            "relevance": 5
          },
          {
            "score": 0.7110669612884521,
            "relevance": 1
          },
          {
            "score": 0.7107012867927551,
            "relevance": 2
          },
          {
            "score": 0.7103370428085327,
            "relevance": 2
          },
          {
            "score": 0.7090172171592712,
            "relevance": 3
          },
          {
            "score": 0.7072470188140869,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6872068643569946,
            "relevance": 3
          },
          {
            "score": 0.6710037589073181,
            "relevance": 1
          },
          {
            "score": 0.6498266458511353,
            "relevance": 5
          },
          {
            "score": 0.6461428999900818,
            "relevance": 4
          },
          {
            "score": 0.6307477355003357,
            "relevance": 2
          },
          {
            "score": 0.615495502948761,
            "relevance": 5
          },
          {
            "score": 0.6107653379440308,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.398405079763084
        }
      }
    },
    "thresh_0.120_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.712925374507904,
            "relevance": 4
          },
          {
            "score": 0.7116575837135315,
            "relevance": 5
          },
          {
            "score": 0.7110669612884521,
            "relevance": 1
          },
          {
            "score": 0.7107012867927551,
            "relevance": 2
          },
          {
            "score": 0.7103370428085327,
            "relevance": 2
          },
          {
            "score": 0.7090172171592712,
            "relevance": 3
          },
          {
            "score": 0.7072470188140869,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7599416971206665,
            "relevance": 3
          },
          {
            "score": 0.7421882748603821,
            "relevance": 1
          },
          {
            "score": 0.7164407968521118,
            "relevance": 5
          },
          {
            "score": 0.7112985253334045,
            "relevance": 4
          },
          {
            "score": 0.6928885579109192,
            "relevance": 2
          },
          {
            "score": 0.6752539277076721,
            "relevance": 5
          },
          {
            "score": 0.669280469417572,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.398405079763084
        }
      }
    },
    "thresh_0.120_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.712925374507904,
            "relevance": 4
          },
          {
            "score": 0.7116575837135315,
            "relevance": 5
          },
          {
            "score": 0.7110669612884521,
            "relevance": 1
          },
          {
            "score": 0.7107012867927551,
            "relevance": 2
          },
          {
            "score": 0.7103370428085327,
            "relevance": 2
          },
          {
            "score": 0.7090172171592712,
            "relevance": 3
          },
          {
            "score": 0.7072470188140869,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8421858549118042,
            "relevance": 3
          },
          {
            "score": 0.8236095309257507,
            "relevance": 1
          },
          {
            "score": 0.7948076725006104,
            "relevance": 5
          },
          {
            "score": 0.7885369658470154,
            "relevance": 4
          },
          {
            "score": 0.7676097750663757,
            "relevance": 2
          },
          {
            "score": 0.7478345036506653,
            "relevance": 5
          },
          {
            "score": 0.7406973242759705,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.398405079763084
        }
      }
    },
    "thresh_0.130_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.712925374507904,
            "relevance": 4
          },
          {
            "score": 0.7116575837135315,
            "relevance": 5
          },
          {
            "score": 0.7110669612884521,
            "relevance": 1
          },
          {
            "score": 0.7107012867927551,
            "relevance": 2
          },
          {
            "score": 0.7103370428085327,
            "relevance": 2
          },
          {
            "score": 0.7090172171592712,
            "relevance": 3
          },
          {
            "score": 0.7072470188140869,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5473607778549194,
            "relevance": 3
          },
          {
            "score": 0.5355709195137024,
            "relevance": 1
          },
          {
            "score": 0.5259484648704529,
            "relevance": 5
          },
          {
            "score": 0.525661289691925,
            "relevance": 4
          },
          {
            "score": 0.5171486139297485,
            "relevance": 2
          },
          {
            "score": 0.5071746110916138,
            "relevance": 5
          },
          {
            "score": 0.505082368850708,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.398405079763084
        }
      }
    },
    "thresh_0.130_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.712925374507904,
            "relevance": 4
          },
          {
            "score": 0.7116575837135315,
            "relevance": 5
          },
          {
            "score": 0.7110669612884521,
            "relevance": 1
          },
          {
            "score": 0.7107012867927551,
            "relevance": 2
          },
          {
            "score": 0.7103370428085327,
            "relevance": 2
          },
          {
            "score": 0.7090172171592712,
            "relevance": 3
          },
          {
            "score": 0.7072470188140869,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6740919351577759,
            "relevance": 3
          },
          {
            "score": 0.6575840711593628,
            "relevance": 1
          },
          {
            "score": 0.6353296041488647,
            "relevance": 5
          },
          {
            "score": 0.6313098669052124,
            "relevance": 4
          },
          {
            "score": 0.6154210567474365,
            "relevance": 2
          },
          {
            "score": 0.5998858213424683,
            "relevance": 5
          },
          {
            "score": 0.594970703125,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.398405079763084
        }
      }
    },
    "thresh_0.130_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.712925374507904,
            "relevance": 4
          },
          {
            "score": 0.7116575837135315,
            "relevance": 5
          },
          {
            "score": 0.7110669612884521,
            "relevance": 1
          },
          {
            "score": 0.7107012867927551,
            "relevance": 2
          },
          {
            "score": 0.7103370428085327,
            "relevance": 2
          },
          {
            "score": 0.7090172171592712,
            "relevance": 3
          },
          {
            "score": 0.7072470188140869,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7420939207077026,
            "relevance": 3
          },
          {
            "score": 0.7236682176589966,
            "relevance": 1
          },
          {
            "score": 0.6959067583084106,
            "relevance": 5
          },
          {
            "score": 0.6901661157608032,
            "relevance": 4
          },
          {
            "score": 0.6707636117935181,
            "relevance": 2
          },
          {
            "score": 0.6524878740310669,
            "relevance": 5
          },
          {
            "score": 0.6461535692214966,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.398405079763084
        }
      }
    },
    "thresh_0.130_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.712925374507904,
            "relevance": 4
          },
          {
            "score": 0.7116575837135315,
            "relevance": 5
          },
          {
            "score": 0.7110669612884521,
            "relevance": 1
          },
          {
            "score": 0.7107012867927551,
            "relevance": 2
          },
          {
            "score": 0.7103370428085327,
            "relevance": 2
          },
          {
            "score": 0.7090172171592712,
            "relevance": 3
          },
          {
            "score": 0.7072470188140869,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.82147216796875,
            "relevance": 3
          },
          {
            "score": 0.8016324043273926,
            "relevance": 1
          },
          {
            "score": 0.7692365646362305,
            "relevance": 5
          },
          {
            "score": 0.7619050741195679,
            "relevance": 4
          },
          {
            "score": 0.7390842437744141,
            "relevance": 2
          },
          {
            "score": 0.7180027961730957,
            "relevance": 5
          },
          {
            "score": 0.7101730108261108,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.398405079763084
        }
      }
    }
  },
  "S09": {
    "thresh_0.090_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8211473226547241,
            "relevance": 1
          },
          {
            "score": 0.8204941749572754,
            "relevance": 2
          },
          {
            "score": 0.8202166557312012,
            "relevance": 4
          },
          {
            "score": 0.8197838068008423,
            "relevance": 5
          },
          {
            "score": 0.8183861374855042,
            "relevance": 3
          },
          {
            "score": 0.8172445893287659,
            "relevance": 2
          },
          {
            "score": 0.8170267939567566,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.17900447921841645
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5389162302017212,
            "relevance": 5
          },
          {
            "score": 0.5289608240127563,
            "relevance": 4
          },
          {
            "score": 0.5273210406303406,
            "relevance": 5
          },
          {
            "score": 0.5177074074745178,
            "relevance": 2
          },
          {
            "score": 0.503334105014801,
            "relevance": 3
          },
          {
            "score": 0.4971993863582611,
            "relevance": 2
          },
          {
            "score": 0.4905608296394348,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.090_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8211473226547241,
            "relevance": 1
          },
          {
            "score": 0.8204941749572754,
            "relevance": 2
          },
          {
            "score": 0.8202166557312012,
            "relevance": 4
          },
          {
            "score": 0.8197838068008423,
            "relevance": 5
          },
          {
            "score": 0.8183861374855042,
            "relevance": 3
          },
          {
            "score": 0.8172445893287659,
            "relevance": 2
          },
          {
            "score": 0.8170267939567566,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.17900447921841645
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6944220066070557,
            "relevance": 5
          },
          {
            "score": 0.6780153512954712,
            "relevance": 4
          },
          {
            "score": 0.6737541556358337,
            "relevance": 5
          },
          {
            "score": 0.6542196869850159,
            "relevance": 2
          },
          {
            "score": 0.6315323710441589,
            "relevance": 3
          },
          {
            "score": 0.6152702569961548,
            "relevance": 2
          },
          {
            "score": 0.6060859560966492,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.090_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8211473226547241,
            "relevance": 1
          },
          {
            "score": 0.8204941749572754,
            "relevance": 2
          },
          {
            "score": 0.8202166557312012,
            "relevance": 4
          },
          {
            "score": 0.8197838068008423,
            "relevance": 5
          },
          {
            "score": 0.8183861374855042,
            "relevance": 3
          },
          {
            "score": 0.8172445893287659,
            "relevance": 2
          },
          {
            "score": 0.8170267939567566,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.17900447921841645
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7720454931259155,
            "relevance": 5
          },
          {
            "score": 0.7538406848907471,
            "relevance": 4
          },
          {
            "score": 0.7487826943397522,
            "relevance": 5
          },
          {
            "score": 0.725923478603363,
            "relevance": 2
          },
          {
            "score": 0.7001139521598816,
            "relevance": 3
          },
          {
            "score": 0.6796914339065552,
            "relevance": 2
          },
          {
            "score": 0.6694056391716003,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.090_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8211473226547241,
            "relevance": 1
          },
          {
            "score": 0.8204941749572754,
            "relevance": 2
          },
          {
            "score": 0.8202166557312012,
            "relevance": 4
          },
          {
            "score": 0.8197838068008423,
            "relevance": 5
          },
          {
            "score": 0.8183861374855042,
            "relevance": 3
          },
          {
            "score": 0.8172445893287659,
            "relevance": 2
          },
          {
            "score": 0.8170267939567566,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.17900447921841645
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8557009696960449,
            "relevance": 5
          },
          {
            "score": 0.8372502326965332,
            "relevance": 4
          },
          {
            "score": 0.8319658637046814,
            "relevance": 5
          },
          {
            "score": 0.8076345324516296,
            "relevance": 2
          },
          {
            "score": 0.7798945307731628,
            "relevance": 3
          },
          {
            "score": 0.756338357925415,
            "relevance": 2
          },
          {
            "score": 0.7451385855674744,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.100_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8211473226547241,
            "relevance": 1
          },
          {
            "score": 0.8204941749572754,
            "relevance": 2
          },
          {
            "score": 0.8202166557312012,
            "relevance": 4
          },
          {
            "score": 0.8197838068008423,
            "relevance": 5
          },
          {
            "score": 0.8183861374855042,
            "relevance": 3
          },
          {
            "score": 0.8172445893287659,
            "relevance": 2
          },
          {
            "score": 0.8170267939567566,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.17900447921841645
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5393087863922119,
            "relevance": 5
          },
          {
            "score": 0.5292521715164185,
            "relevance": 4
          },
          {
            "score": 0.5275464057922363,
            "relevance": 5
          },
          {
            "score": 0.5177453756332397,
            "relevance": 2
          },
          {
            "score": 0.5033179521560669,
            "relevance": 3
          },
          {
            "score": 0.49699631333351135,
            "relevance": 2
          },
          {
            "score": 0.49037984013557434,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.100_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8211473226547241,
            "relevance": 1
          },
          {
            "score": 0.8204941749572754,
            "relevance": 2
          },
          {
            "score": 0.8202166557312012,
            "relevance": 4
          },
          {
            "score": 0.8197838068008423,
            "relevance": 5
          },
          {
            "score": 0.8183861374855042,
            "relevance": 3
          },
          {
            "score": 0.8172445893287659,
            "relevance": 2
          },
          {
            "score": 0.8170267939567566,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.17900447921841645
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6835464835166931,
            "relevance": 5
          },
          {
            "score": 0.6664239168167114,
            "relevance": 4
          },
          {
            "score": 0.661860466003418,
            "relevance": 5
          },
          {
            "score": 0.6413081884384155,
            "relevance": 2
          },
          {
            "score": 0.61794114112854,
            "relevance": 3
          },
          {
            "score": 0.6008087396621704,
            "relevance": 2
          },
          {
            "score": 0.5914870500564575,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.100_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8211473226547241,
            "relevance": 1
          },
          {
            "score": 0.8204941749572754,
            "relevance": 2
          },
          {
            "score": 0.8202166557312012,
            "relevance": 4
          },
          {
            "score": 0.8197838068008423,
            "relevance": 5
          },
          {
            "score": 0.8183861374855042,
            "relevance": 3
          },
          {
            "score": 0.8172445893287659,
            "relevance": 2
          },
          {
            "score": 0.8170267939567566,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.17900447921841645
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7578800320625305,
            "relevance": 5
          },
          {
            "score": 0.7383627891540527,
            "relevance": 4
          },
          {
            "score": 0.7327665090560913,
            "relevance": 5
          },
          {
            "score": 0.7080310583114624,
            "relevance": 2
          },
          {
            "score": 0.6808656454086304,
            "relevance": 3
          },
          {
            "score": 0.6588037014007568,
            "relevance": 2
          },
          {
            "score": 0.648196816444397,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.100_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8211473226547241,
            "relevance": 1
          },
          {
            "score": 0.8204941749572754,
            "relevance": 2
          },
          {
            "score": 0.8202166557312012,
            "relevance": 4
          },
          {
            "score": 0.8197838068008423,
            "relevance": 5
          },
          {
            "score": 0.8183861374855042,
            "relevance": 3
          },
          {
            "score": 0.8172445893287659,
            "relevance": 2
          },
          {
            "score": 0.8170267939567566,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.17900447921841645
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8408198952674866,
            "relevance": 5
          },
          {
            "score": 0.8202006816864014,
            "relevance": 4
          },
          {
            "score": 0.8140264749526978,
            "relevance": 5
          },
          {
            "score": 0.7864793539047241,
            "relevance": 2
          },
          {
            "score": 0.756263017654419,
            "relevance": 3
          },
          {
            "score": 0.7297252416610718,
            "relevance": 2
          },
          {
            "score": 0.7178733348846436,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.110_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8211473226547241,
            "relevance": 1
          },
          {
            "score": 0.8204941749572754,
            "relevance": 2
          },
          {
            "score": 0.8202166557312012,
            "relevance": 4
          },
          {
            "score": 0.8197838068008423,
            "relevance": 5
          },
          {
            "score": 0.8183861374855042,
            "relevance": 3
          },
          {
            "score": 0.8172445893287659,
            "relevance": 2
          },
          {
            "score": 0.8170267939567566,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.17900447921841645
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5392715334892273,
            "relevance": 5
          },
          {
            "score": 0.5291255712509155,
            "relevance": 4
          },
          {
            "score": 0.5273540616035461,
            "relevance": 5
          },
          {
            "score": 0.5173746347427368,
            "relevance": 2
          },
          {
            "score": 0.5029135346412659,
            "relevance": 3
          },
          {
            "score": 0.49640849232673645,
            "relevance": 2
          },
          {
            "score": 0.4898248314857483,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.110_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8211473226547241,
            "relevance": 1
          },
          {
            "score": 0.8204941749572754,
            "relevance": 2
          },
          {
            "score": 0.8202166557312012,
            "relevance": 4
          },
          {
            "score": 0.8197838068008423,
            "relevance": 5
          },
          {
            "score": 0.8183861374855042,
            "relevance": 3
          },
          {
            "score": 0.8172445893287659,
            "relevance": 2
          },
          {
            "score": 0.8170267939567566,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.17900447921841645
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6711977124214172,
            "relevance": 5
          },
          {
            "score": 0.6534000635147095,
            "relevance": 4
          },
          {
            "score": 0.6485472321510315,
            "relevance": 5
          },
          {
            "score": 0.6270390748977661,
            "relevance": 2
          },
          {
            "score": 0.6030635833740234,
            "relevance": 3
          },
          {
            "score": 0.5851306915283203,
            "relevance": 2
          },
          {
            "score": 0.5757004618644714,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.110_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8211473226547241,
            "relevance": 1
          },
          {
            "score": 0.8204941749572754,
            "relevance": 2
          },
          {
            "score": 0.8202166557312012,
            "relevance": 4
          },
          {
            "score": 0.8197838068008423,
            "relevance": 5
          },
          {
            "score": 0.8183861374855042,
            "relevance": 3
          },
          {
            "score": 0.8172445893287659,
            "relevance": 2
          },
          {
            "score": 0.8170267939567566,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.17900447921841645
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7412143349647522,
            "relevance": 5
          },
          {
            "score": 0.7204134464263916,
            "relevance": 4
          },
          {
            "score": 0.7142898440361023,
            "relevance": 5
          },
          {
            "score": 0.6877454519271851,
            "relevance": 2
          },
          {
            "score": 0.6593140959739685,
            "relevance": 3
          },
          {
            "score": 0.635722279548645,
            "relevance": 2
          },
          {
            "score": 0.6248358488082886,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.110_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8211473226547241,
            "relevance": 1
          },
          {
            "score": 0.8204941749572754,
            "relevance": 2
          },
          {
            "score": 0.8202166557312012,
            "relevance": 4
          },
          {
            "score": 0.8197838068008423,
            "relevance": 5
          },
          {
            "score": 0.8183861374855042,
            "relevance": 3
          },
          {
            "score": 0.8172445893287659,
            "relevance": 2
          },
          {
            "score": 0.8170267939567566,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.17900447921841645
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8219353556632996,
            "relevance": 5
          },
          {
            "score": 0.7990778684616089,
            "relevance": 4
          },
          {
            "score": 0.7919902205467224,
            "relevance": 5
          },
          {
            "score": 0.7611919641494751,
            "relevance": 2
          },
          {
            "score": 0.728538453578949,
            "relevance": 3
          },
          {
            "score": 0.6991103887557983,
            "relevance": 2
          },
          {
            "score": 0.6866507530212402,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.120_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8211473226547241,
            "relevance": 1
          },
          {
            "score": 0.8204941749572754,
            "relevance": 2
          },
          {
            "score": 0.8202166557312012,
            "relevance": 4
          },
          {
            "score": 0.8197838068008423,
            "relevance": 5
          },
          {
            "score": 0.8183861374855042,
            "relevance": 3
          },
          {
            "score": 0.8172445893287659,
            "relevance": 2
          },
          {
            "score": 0.8170267939567566,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.17900447921841645
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5387872457504272,
            "relevance": 5
          },
          {
            "score": 0.5285647511482239,
            "relevance": 4
          },
          {
            "score": 0.5267282724380493,
            "relevance": 5
          },
          {
            "score": 0.5165799856185913,
            "relevance": 2
          },
          {
            "score": 0.5021058320999146,
            "relevance": 3
          },
          {
            "score": 0.4954215884208679,
            "relevance": 2
          },
          {
            "score": 0.48888152837753296,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.120_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8211473226547241,
            "relevance": 1
          },
          {
            "score": 0.8204941749572754,
            "relevance": 2
          },
          {
            "score": 0.8202166557312012,
            "relevance": 4
          },
          {
            "score": 0.8197838068008423,
            "relevance": 5
          },
          {
            "score": 0.8183861374855042,
            "relevance": 3
          },
          {
            "score": 0.8172445893287659,
            "relevance": 2
          },
          {
            "score": 0.8170267939567566,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.17900447921841645
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.657411515712738,
            "relevance": 5
          },
          {
            "score": 0.6389896273612976,
            "relevance": 4
          },
          {
            "score": 0.6338649988174438,
            "relevance": 5
          },
          {
            "score": 0.611478328704834,
            "relevance": 2
          },
          {
            "score": 0.5869753360748291,
            "relevance": 3
          },
          {
            "score": 0.5683252811431885,
            "relevance": 2
          },
          {
            "score": 0.5588173866271973,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.120_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8211473226547241,
            "relevance": 1
          },
          {
            "score": 0.8204941749572754,
            "relevance": 2
          },
          {
            "score": 0.8202166557312012,
            "relevance": 4
          },
          {
            "score": 0.8197838068008423,
            "relevance": 5
          },
          {
            "score": 0.8183861374855042,
            "relevance": 3
          },
          {
            "score": 0.8172445893287659,
            "relevance": 2
          },
          {
            "score": 0.8170267939567566,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.17900447921841645
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7220693230628967,
            "relevance": 5
          },
          {
            "score": 0.7000407576560974,
            "relevance": 4
          },
          {
            "score": 0.6934119462966919,
            "relevance": 5
          },
          {
            "score": 0.665166974067688,
            "relevance": 2
          },
          {
            "score": 0.6355918645858765,
            "relevance": 3
          },
          {
            "score": 0.6106186509132385,
            "relevance": 2
          },
          {
            "score": 0.5995023250579834,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.120_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8211473226547241,
            "relevance": 1
          },
          {
            "score": 0.8204941749572754,
            "relevance": 2
          },
          {
            "score": 0.8202166557312012,
            "relevance": 4
          },
          {
            "score": 0.8197838068008423,
            "relevance": 5
          },
          {
            "score": 0.8183861374855042,
            "relevance": 3
          },
          {
            "score": 0.8172445893287659,
            "relevance": 2
          },
          {
            "score": 0.8170267939567566,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.17900447921841645
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7989084124565125,
            "relevance": 5
          },
          {
            "score": 0.7737979292869568,
            "relevance": 4
          },
          {
            "score": 0.7657967805862427,
            "relevance": 5
          },
          {
            "score": 0.7318077087402344,
            "relevance": 2
          },
          {
            "score": 0.6968401670455933,
            "relevance": 3
          },
          {
            "score": 0.6647195816040039,
            "relevance": 2
          },
          {
            "score": 0.6517221331596375,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.130_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8211473226547241,
            "relevance": 1
          },
          {
            "score": 0.8204941749572754,
            "relevance": 2
          },
          {
            "score": 0.8202166557312012,
            "relevance": 4
          },
          {
            "score": 0.8197838068008423,
            "relevance": 5
          },
          {
            "score": 0.8183861374855042,
            "relevance": 3
          },
          {
            "score": 0.8172445893287659,
            "relevance": 2
          },
          {
            "score": 0.8170267939567566,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.17900447921841645
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5378425717353821,
            "relevance": 5
          },
          {
            "score": 0.5275564193725586,
            "relevance": 4
          },
          {
            "score": 0.52565598487854,
            "relevance": 5
          },
          {
            "score": 0.5153498649597168,
            "relevance": 2
          },
          {
            "score": 0.5008828043937683,
            "relevance": 3
          },
          {
            "score": 0.49402520060539246,
            "relevance": 2
          },
          {
            "score": 0.48753875494003296,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.130_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8211473226547241,
            "relevance": 1
          },
          {
            "score": 0.8204941749572754,
            "relevance": 2
          },
          {
            "score": 0.8202166557312012,
            "relevance": 4
          },
          {
            "score": 0.8197838068008423,
            "relevance": 5
          },
          {
            "score": 0.8183861374855042,
            "relevance": 3
          },
          {
            "score": 0.8172445893287659,
            "relevance": 2
          },
          {
            "score": 0.8170267939567566,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.17900447921841645
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6422433853149414,
            "relevance": 5
          },
          {
            "score": 0.6232585906982422,
            "relevance": 4
          },
          {
            "score": 0.6178836822509766,
            "relevance": 5
          },
          {
            "score": 0.5947099924087524,
            "relevance": 2
          },
          {
            "score": 0.569770872592926,
            "relevance": 3
          },
          {
            "score": 0.5504988431930542,
            "relevance": 2
          },
          {
            "score": 0.5409463047981262,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.130_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8211473226547241,
            "relevance": 1
          },
          {
            "score": 0.8204941749572754,
            "relevance": 2
          },
          {
            "score": 0.8202166557312012,
            "relevance": 4
          },
          {
            "score": 0.8197838068008423,
            "relevance": 5
          },
          {
            "score": 0.8183861374855042,
            "relevance": 3
          },
          {
            "score": 0.8172445893287659,
            "relevance": 2
          },
          {
            "score": 0.8170267939567566,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.17900447921841645
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7005154490470886,
            "relevance": 5
          },
          {
            "score": 0.6773439049720764,
            "relevance": 4
          },
          {
            "score": 0.6702438592910767,
            "relevance": 5
          },
          {
            "score": 0.640449047088623,
            "relevance": 2
          },
          {
            "score": 0.6098844408988953,
            "relevance": 3
          },
          {
            "score": 0.5837156772613525,
            "relevance": 2
          },
          {
            "score": 0.5724271535873413,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.130_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8211473226547241,
            "relevance": 1
          },
          {
            "score": 0.8204941749572754,
            "relevance": 2
          },
          {
            "score": 0.8202166557312012,
            "relevance": 4
          },
          {
            "score": 0.8197838068008423,
            "relevance": 5
          },
          {
            "score": 0.8183861374855042,
            "relevance": 3
          },
          {
            "score": 0.8172445893287659,
            "relevance": 2
          },
          {
            "score": 0.8170267939567566,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.17900447921841645
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7717015147209167,
            "relevance": 5
          },
          {
            "score": 0.7443912625312805,
            "relevance": 4
          },
          {
            "score": 0.7355057001113892,
            "relevance": 5
          },
          {
            "score": 0.6984968185424805,
            "relevance": 2
          },
          {
            "score": 0.6614305377006531,
            "relevance": 3
          },
          {
            "score": 0.6269270181655884,
            "relevance": 2
          },
          {
            "score": 0.6134883165359497,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    }
  },
  "S10": {
    "thresh_0.090_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8046406507492065,
            "relevance": 4
          },
          {
            "score": 0.8033640384674072,
            "relevance": 5
          },
          {
            "score": 0.8027979731559753,
            "relevance": 1
          },
          {
            "score": 0.8027118444442749,
            "relevance": 2
          },
          {
            "score": 0.8020869493484497,
            "relevance": 2
          },
          {
            "score": 0.8013826608657837,
            "relevance": 5
          },
          {
            "score": 0.8008805513381958,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.616619348526001,
            "relevance": 2
          },
          {
            "score": 0.5897190570831299,
            "relevance": 1
          },
          {
            "score": 0.5870593190193176,
            "relevance": 3
          },
          {
            "score": 0.5731087327003479,
            "relevance": 4
          },
          {
            "score": 0.5625145435333252,
            "relevance": 5
          },
          {
            "score": 0.5575436353683472,
            "relevance": 2
          },
          {
            "score": 0.5563742518424988,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.12282250076082352
        }
      }
    },
    "thresh_0.090_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8046406507492065,
            "relevance": 4
          },
          {
            "score": 0.8033640384674072,
            "relevance": 5
          },
          {
            "score": 0.8027979731559753,
            "relevance": 1
          },
          {
            "score": 0.8027118444442749,
            "relevance": 2
          },
          {
            "score": 0.8020869493484497,
            "relevance": 2
          },
          {
            "score": 0.8013826608657837,
            "relevance": 5
          },
          {
            "score": 0.8008805513381958,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8133609294891357,
            "relevance": 2
          },
          {
            "score": 0.775256872177124,
            "relevance": 1
          },
          {
            "score": 0.7716215252876282,
            "relevance": 3
          },
          {
            "score": 0.7477927803993225,
            "relevance": 4
          },
          {
            "score": 0.7323610782623291,
            "relevance": 5
          },
          {
            "score": 0.7259078025817871,
            "relevance": 2
          },
          {
            "score": 0.7244554162025452,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.12282250076082352
        }
      }
    },
    "thresh_0.090_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8046406507492065,
            "relevance": 4
          },
          {
            "score": 0.8033640384674072,
            "relevance": 5
          },
          {
            "score": 0.8027979731559753,
            "relevance": 1
          },
          {
            "score": 0.8027118444442749,
            "relevance": 2
          },
          {
            "score": 0.8020869493484497,
            "relevance": 2
          },
          {
            "score": 0.8013826608657837,
            "relevance": 5
          },
          {
            "score": 0.8008805513381958,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8937090635299683,
            "relevance": 2
          },
          {
            "score": 0.8570729494094849,
            "relevance": 1
          },
          {
            "score": 0.8534529805183411,
            "relevance": 3
          },
          {
            "score": 0.8290824294090271,
            "relevance": 4
          },
          {
            "score": 0.8130044937133789,
            "relevance": 5
          },
          {
            "score": 0.8063112497329712,
            "relevance": 2
          },
          {
            "score": 0.8048110604286194,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.12282250076082352
        }
      }
    },
    "thresh_0.090_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8046406507492065,
            "relevance": 4
          },
          {
            "score": 0.8033640384674072,
            "relevance": 5
          },
          {
            "score": 0.8027979731559753,
            "relevance": 1
          },
          {
            "score": 0.8027118444442749,
            "relevance": 2
          },
          {
            "score": 0.8020869493484497,
            "relevance": 2
          },
          {
            "score": 0.8013826608657837,
            "relevance": 5
          },
          {
            "score": 0.8008805513381958,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9644712209701538,
            "relevance": 2
          },
          {
            "score": 0.934674859046936,
            "relevance": 1
          },
          {
            "score": 0.9314902424812317,
            "relevance": 3
          },
          {
            "score": 0.9104750752449036,
            "relevance": 4
          },
          {
            "score": 0.8954404592514038,
            "relevance": 5
          },
          {
            "score": 0.8889980316162109,
            "relevance": 2
          },
          {
            "score": 0.8875420689582825,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.12282250076082352
        }
      }
    },
    "thresh_0.100_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8046406507492065,
            "relevance": 4
          },
          {
            "score": 0.8033640384674072,
            "relevance": 5
          },
          {
            "score": 0.8027979731559753,
            "relevance": 1
          },
          {
            "score": 0.8027118444442749,
            "relevance": 2
          },
          {
            "score": 0.8020869493484497,
            "relevance": 2
          },
          {
            "score": 0.8013826608657837,
            "relevance": 5
          },
          {
            "score": 0.8008805513381958,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6182591915130615,
            "relevance": 2
          },
          {
            "score": 0.590873122215271,
            "relevance": 1
          },
          {
            "score": 0.5881870985031128,
            "relevance": 3
          },
          {
            "score": 0.5738771557807922,
            "relevance": 4
          },
          {
            "score": 0.5631899833679199,
            "relevance": 5
          },
          {
            "score": 0.5582152605056763,
            "relevance": 2
          },
          {
            "score": 0.557047963142395,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.12282250076082352
        }
      }
    },
    "thresh_0.100_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8046406507492065,
            "relevance": 4
          },
          {
            "score": 0.8033640384674072,
            "relevance": 5
          },
          {
            "score": 0.8027979731559753,
            "relevance": 1
          },
          {
            "score": 0.8027118444442749,
            "relevance": 2
          },
          {
            "score": 0.8020869493484497,
            "relevance": 2
          },
          {
            "score": 0.8013826608657837,
            "relevance": 5
          },
          {
            "score": 0.8008805513381958,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8094344139099121,
            "relevance": 2
          },
          {
            "score": 0.7688426971435547,
            "relevance": 1
          },
          {
            "score": 0.7650303840637207,
            "relevance": 3
          },
          {
            "score": 0.7394568920135498,
            "relevance": 4
          },
          {
            "score": 0.7233304977416992,
            "relevance": 5
          },
          {
            "score": 0.7166975736618042,
            "relevance": 2
          },
          {
            "score": 0.7152141332626343,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.12282250076082352
        }
      }
    },
    "thresh_0.100_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8046406507492065,
            "relevance": 4
          },
          {
            "score": 0.8033640384674072,
            "relevance": 5
          },
          {
            "score": 0.8027979731559753,
            "relevance": 1
          },
          {
            "score": 0.8027118444442749,
            "relevance": 2
          },
          {
            "score": 0.8020869493484497,
            "relevance": 2
          },
          {
            "score": 0.8013826608657837,
            "relevance": 5
          },
          {
            "score": 0.8008805513381958,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8908504247665405,
            "relevance": 2
          },
          {
            "score": 0.8504394292831421,
            "relevance": 1
          },
          {
            "score": 0.8465347290039062,
            "relevance": 3
          },
          {
            "score": 0.8193608522415161,
            "relevance": 4
          },
          {
            "score": 0.8020895719528198,
            "relevance": 5
          },
          {
            "score": 0.795066237449646,
            "relevance": 2
          },
          {
            "score": 0.793506383895874,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.12282250076082352
        }
      }
    },
    "thresh_0.100_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8046406507492065,
            "relevance": 4
          },
          {
            "score": 0.8033640384674072,
            "relevance": 5
          },
          {
            "score": 0.8027979731559753,
            "relevance": 1
          },
          {
            "score": 0.8027118444442749,
            "relevance": 2
          },
          {
            "score": 0.8020869493484497,
            "relevance": 2
          },
          {
            "score": 0.8013826608657837,
            "relevance": 5
          },
          {
            "score": 0.8008805513381958,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9654852151870728,
            "relevance": 2
          },
          {
            "score": 0.9309121370315552,
            "relevance": 1
          },
          {
            "score": 0.9273432493209839,
            "relevance": 3
          },
          {
            "score": 0.902436375617981,
            "relevance": 4
          },
          {
            "score": 0.8856319189071655,
            "relevance": 5
          },
          {
            "score": 0.8786780834197998,
            "relevance": 2
          },
          {
            "score": 0.877128005027771,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.12282250076082352
        }
      }
    },
    "thresh_0.110_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8046406507492065,
            "relevance": 4
          },
          {
            "score": 0.8033640384674072,
            "relevance": 5
          },
          {
            "score": 0.8027979731559753,
            "relevance": 1
          },
          {
            "score": 0.8027118444442749,
            "relevance": 2
          },
          {
            "score": 0.8020869493484497,
            "relevance": 2
          },
          {
            "score": 0.8013826608657837,
            "relevance": 5
          },
          {
            "score": 0.8008805513381958,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6193898916244507,
            "relevance": 2
          },
          {
            "score": 0.5915433168411255,
            "relevance": 1
          },
          {
            "score": 0.588834285736084,
            "relevance": 3
          },
          {
            "score": 0.5741747617721558,
            "relevance": 4
          },
          {
            "score": 0.5634077787399292,
            "relevance": 5
          },
          {
            "score": 0.5584369897842407,
            "relevance": 2
          },
          {
            "score": 0.5572738647460938,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.12282250076082352
        }
      }
    },
    "thresh_0.110_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8046406507492065,
            "relevance": 4
          },
          {
            "score": 0.8033640384674072,
            "relevance": 5
          },
          {
            "score": 0.8027979731559753,
            "relevance": 1
          },
          {
            "score": 0.8027118444442749,
            "relevance": 2
          },
          {
            "score": 0.8020869493484497,
            "relevance": 2
          },
          {
            "score": 0.8013826608657837,
            "relevance": 5
          },
          {
            "score": 0.8008805513381958,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8039330244064331,
            "relevance": 2
          },
          {
            "score": 0.7608435153961182,
            "relevance": 1
          },
          {
            "score": 0.7568563222885132,
            "relevance": 3
          },
          {
            "score": 0.7295517921447754,
            "relevance": 4
          },
          {
            "score": 0.7127530574798584,
            "relevance": 5
          },
          {
            "score": 0.7059516906738281,
            "relevance": 2
          },
          {
            "score": 0.7044398784637451,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.12282250076082352
        }
      }
    },
    "thresh_0.110_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8046406507492065,
            "relevance": 4
          },
          {
            "score": 0.8033640384674072,
            "relevance": 5
          },
          {
            "score": 0.8027979731559753,
            "relevance": 1
          },
          {
            "score": 0.8027118444442749,
            "relevance": 2
          },
          {
            "score": 0.8020869493484497,
            "relevance": 2
          },
          {
            "score": 0.8013826608657837,
            "relevance": 5
          },
          {
            "score": 0.8008805513381958,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8857645988464355,
            "relevance": 2
          },
          {
            "score": 0.8414005041122437,
            "relevance": 1
          },
          {
            "score": 0.8372018337249756,
            "relevance": 3
          },
          {
            "score": 0.8071417808532715,
            "relevance": 4
          },
          {
            "score": 0.7886645793914795,
            "relevance": 5
          },
          {
            "score": 0.7813133001327515,
            "relevance": 2
          },
          {
            "score": 0.779694676399231,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.12282250076082352
        }
      }
    },
    "thresh_0.110_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8046406507492065,
            "relevance": 4
          },
          {
            "score": 0.8033640384674072,
            "relevance": 5
          },
          {
            "score": 0.8027979731559753,
            "relevance": 1
          },
          {
            "score": 0.8027118444442749,
            "relevance": 2
          },
          {
            "score": 0.8020869493484497,
            "relevance": 2
          },
          {
            "score": 0.8013826608657837,
            "relevance": 5
          },
          {
            "score": 0.8008805513381958,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9638102054595947,
            "relevance": 2
          },
          {
            "score": 0.923932671546936,
            "relevance": 1
          },
          {
            "score": 0.9199420213699341,
            "relevance": 3
          },
          {
            "score": 0.8907968997955322,
            "relevance": 4
          },
          {
            "score": 0.8720947504043579,
            "relevance": 5
          },
          {
            "score": 0.864598274230957,
            "relevance": 2
          },
          {
            "score": 0.8629481792449951,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.12282250076082352
        }
      }
    },
    "thresh_0.120_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8046406507492065,
            "relevance": 4
          },
          {
            "score": 0.8033640384674072,
            "relevance": 5
          },
          {
            "score": 0.8027979731559753,
            "relevance": 1
          },
          {
            "score": 0.8027118444442749,
            "relevance": 2
          },
          {
            "score": 0.8020869493484497,
            "relevance": 2
          },
          {
            "score": 0.8013826608657837,
            "relevance": 5
          },
          {
            "score": 0.8008805513381958,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6199900507926941,
            "relevance": 2
          },
          {
            "score": 0.5917097330093384,
            "relevance": 1
          },
          {
            "score": 0.588981032371521,
            "relevance": 3
          },
          {
            "score": 0.5739832520484924,
            "relevance": 4
          },
          {
            "score": 0.5631502866744995,
            "relevance": 5
          },
          {
            "score": 0.5581908226013184,
            "relevance": 2
          },
          {
            "score": 0.5570334196090698,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.12282250076082352
        }
      }
    },
    "thresh_0.120_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8046406507492065,
            "relevance": 4
          },
          {
            "score": 0.8033640384674072,
            "relevance": 5
          },
          {
            "score": 0.8027979731559753,
            "relevance": 1
          },
          {
            "score": 0.8027118444442749,
            "relevance": 2
          },
          {
            "score": 0.8020869493484497,
            "relevance": 2
          },
          {
            "score": 0.8013826608657837,
            "relevance": 5
          },
          {
            "score": 0.8008805513381958,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7968112230300903,
            "relevance": 2
          },
          {
            "score": 0.7512385845184326,
            "relevance": 1
          },
          {
            "score": 0.7470810413360596,
            "relevance": 3
          },
          {
            "score": 0.7180792689323425,
            "relevance": 4
          },
          {
            "score": 0.7006393671035767,
            "relevance": 5
          },
          {
            "score": 0.6936829090118408,
            "relevance": 2
          },
          {
            "score": 0.6921457052230835,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.12282250076082352
        }
      }
    },
    "thresh_0.120_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8046406507492065,
            "relevance": 4
          },
          {
            "score": 0.8033640384674072,
            "relevance": 5
          },
          {
            "score": 0.8027979731559753,
            "relevance": 1
          },
          {
            "score": 0.8027118444442749,
            "relevance": 2
          },
          {
            "score": 0.8020869493484497,
            "relevance": 2
          },
          {
            "score": 0.8013826608657837,
            "relevance": 5
          },
          {
            "score": 0.8008805513381958,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8783136606216431,
            "relevance": 2
          },
          {
            "score": 0.8298557996749878,
            "relevance": 1
          },
          {
            "score": 0.82535719871521,
            "relevance": 3
          },
          {
            "score": 0.7923672795295715,
            "relevance": 4
          },
          {
            "score": 0.7726906538009644,
            "relevance": 5
          },
          {
            "score": 0.7650191783905029,
            "relevance": 2
          },
          {
            "score": 0.7633438110351562,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.12282250076082352
        }
      }
    },
    "thresh_0.120_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8046406507492065,
            "relevance": 4
          },
          {
            "score": 0.8033640384674072,
            "relevance": 5
          },
          {
            "score": 0.8027979731559753,
            "relevance": 1
          },
          {
            "score": 0.8027118444442749,
            "relevance": 2
          },
          {
            "score": 0.8020869493484497,
            "relevance": 2
          },
          {
            "score": 0.8013826608657837,
            "relevance": 5
          },
          {
            "score": 0.8008805513381958,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9591283798217773,
            "relevance": 2
          },
          {
            "score": 0.9134277105331421,
            "relevance": 1
          },
          {
            "score": 0.9089804887771606,
            "relevance": 3
          },
          {
            "score": 0.8752897381782532,
            "relevance": 4
          },
          {
            "score": 0.8545881509780884,
            "relevance": 5
          },
          {
            "score": 0.8465262651443481,
            "relevance": 2
          },
          {
            "score": 0.8447725772857666,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.12282250076082352
        }
      }
    },
    "thresh_0.130_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8046406507492065,
            "relevance": 4
          },
          {
            "score": 0.8033640384674072,
            "relevance": 5
          },
          {
            "score": 0.8027979731559753,
            "relevance": 1
          },
          {
            "score": 0.8027118444442749,
            "relevance": 2
          },
          {
            "score": 0.8020869493484497,
            "relevance": 2
          },
          {
            "score": 0.8013826608657837,
            "relevance": 5
          },
          {
            "score": 0.8008805513381958,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6200408339500427,
            "relevance": 2
          },
          {
            "score": 0.5913556814193726,
            "relevance": 1
          },
          {
            "score": 0.5886105298995972,
            "relevance": 3
          },
          {
            "score": 0.5732879638671875,
            "relevance": 4
          },
          {
            "score": 0.562402606010437,
            "relevance": 5
          },
          {
            "score": 0.5574618577957153,
            "relevance": 2
          },
          {
            "score": 0.5563121438026428,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.12282250076082352
        }
      }
    },
    "thresh_0.130_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8046406507492065,
            "relevance": 4
          },
          {
            "score": 0.8033640384674072,
            "relevance": 5
          },
          {
            "score": 0.8027979731559753,
            "relevance": 1
          },
          {
            "score": 0.8027118444442749,
            "relevance": 2
          },
          {
            "score": 0.8020869493484497,
            "relevance": 2
          },
          {
            "score": 0.8013826608657837,
            "relevance": 5
          },
          {
            "score": 0.8008805513381958,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.788037896156311,
            "relevance": 2
          },
          {
            "score": 0.7400252819061279,
            "relevance": 1
          },
          {
            "score": 0.7357034683227539,
            "relevance": 3
          },
          {
            "score": 0.7050603032112122,
            "relevance": 4
          },
          {
            "score": 0.6870196461677551,
            "relevance": 5
          },
          {
            "score": 0.6799243688583374,
            "relevance": 2
          },
          {
            "score": 0.678365170955658,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.12282250076082352
        }
      }
    },
    "thresh_0.130_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8046406507492065,
            "relevance": 4
          },
          {
            "score": 0.8033640384674072,
            "relevance": 5
          },
          {
            "score": 0.8027979731559753,
            "relevance": 1
          },
          {
            "score": 0.8027118444442749,
            "relevance": 2
          },
          {
            "score": 0.8020869493484497,
            "relevance": 2
          },
          {
            "score": 0.8013826608657837,
            "relevance": 5
          },
          {
            "score": 0.8008805513381958,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8683789968490601,
            "relevance": 2
          },
          {
            "score": 0.8157358169555664,
            "relevance": 1
          },
          {
            "score": 0.8109359741210938,
            "relevance": 3
          },
          {
            "score": 0.7750188708305359,
            "relevance": 4
          },
          {
            "score": 0.7541722655296326,
            "relevance": 5
          },
          {
            "score": 0.74619460105896,
            "relevance": 2
          },
          {
            "score": 0.7444657683372498,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.12282250076082352
        }
      }
    },
    "thresh_0.130_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8046406507492065,
            "relevance": 4
          },
          {
            "score": 0.8033640384674072,
            "relevance": 5
          },
          {
            "score": 0.8027979731559753,
            "relevance": 1
          },
          {
            "score": 0.8027118444442749,
            "relevance": 2
          },
          {
            "score": 0.8020869493484497,
            "relevance": 2
          },
          {
            "score": 0.8013826608657837,
            "relevance": 5
          },
          {
            "score": 0.8008805513381958,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6038500426842506
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9511232376098633,
            "relevance": 2
          },
          {
            "score": 0.8991167545318604,
            "relevance": 1
          },
          {
            "score": 0.8941828012466431,
            "relevance": 3
          },
          {
            "score": 0.8557034134864807,
            "relevance": 4
          },
          {
            "score": 0.8329392075538635,
            "relevance": 5
          },
          {
            "score": 0.8243012428283691,
            "relevance": 2
          },
          {
            "score": 0.8224428296089172,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.12282250076082352
        }
      }
    }
  },
  "S11": {
    "thresh_0.090_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8282959461212158,
            "relevance": 5
          },
          {
            "score": 0.8280795216560364,
            "relevance": 4
          },
          {
            "score": 0.8277651071548462,
            "relevance": 3
          },
          {
            "score": 0.8273264169692993,
            "relevance": 5
          },
          {
            "score": 0.8270406126976013,
            "relevance": 1
          },
          {
            "score": 0.8268039226531982,
            "relevance": 2
          },
          {
            "score": 0.8265914916992188,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7572311065909518
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5939413905143738,
            "relevance": 3
          },
          {
            "score": 0.5871943235397339,
            "relevance": 2
          },
          {
            "score": 0.571407675743103,
            "relevance": 1
          },
          {
            "score": 0.5651848912239075,
            "relevance": 5
          },
          {
            "score": 0.5449203848838806,
            "relevance": 5
          },
          {
            "score": 0.5439797639846802,
            "relevance": 2
          },
          {
            "score": 0.5419658422470093,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.16178056803077517
        }
      }
    },
    "thresh_0.090_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8282959461212158,
            "relevance": 5
          },
          {
            "score": 0.8280795216560364,
            "relevance": 4
          },
          {
            "score": 0.8277651071548462,
            "relevance": 3
          },
          {
            "score": 0.8273264169692993,
            "relevance": 5
          },
          {
            "score": 0.8270406126976013,
            "relevance": 1
          },
          {
            "score": 0.8268039226531982,
            "relevance": 2
          },
          {
            "score": 0.8265914916992188,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7572311065909518
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7887260317802429,
            "relevance": 3
          },
          {
            "score": 0.7826770544052124,
            "relevance": 2
          },
          {
            "score": 0.760977029800415,
            "relevance": 1
          },
          {
            "score": 0.7509862780570984,
            "relevance": 5
          },
          {
            "score": 0.7215867042541504,
            "relevance": 5
          },
          {
            "score": 0.7181110382080078,
            "relevance": 4
          },
          {
            "score": 0.7124764323234558,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.16178056803077517
        }
      }
    },
    "thresh_0.090_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8282959461212158,
            "relevance": 5
          },
          {
            "score": 0.8280795216560364,
            "relevance": 4
          },
          {
            "score": 0.8277651071548462,
            "relevance": 3
          },
          {
            "score": 0.8273264169692993,
            "relevance": 5
          },
          {
            "score": 0.8270406126976013,
            "relevance": 1
          },
          {
            "score": 0.8268039226531982,
            "relevance": 2
          },
          {
            "score": 0.8265914916992188,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7572311065909518
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8695436120033264,
            "relevance": 3
          },
          {
            "score": 0.8633403778076172,
            "relevance": 2
          },
          {
            "score": 0.8425663709640503,
            "relevance": 1
          },
          {
            "score": 0.8327959179878235,
            "relevance": 5
          },
          {
            "score": 0.8030753135681152,
            "relevance": 5
          },
          {
            "score": 0.799551248550415,
            "relevance": 4
          },
          {
            "score": 0.7929020524024963,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.16178056803077517
        }
      }
    },
    "thresh_0.090_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8282959461212158,
            "relevance": 5
          },
          {
            "score": 0.8280795216560364,
            "relevance": 4
          },
          {
            "score": 0.8277651071548462,
            "relevance": 3
          },
          {
            "score": 0.8273264169692993,
            "relevance": 5
          },
          {
            "score": 0.8270406126976013,
            "relevance": 1
          },
          {
            "score": 0.8268039226531982,
            "relevance": 2
          },
          {
            "score": 0.8265914916992188,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7572311065909518
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9417961239814758,
            "relevance": 3
          },
          {
            "score": 0.9350789785385132,
            "relevance": 2
          },
          {
            "score": 0.9181309938430786,
            "relevance": 1
          },
          {
            "score": 0.910276472568512,
            "relevance": 5
          },
          {
            "score": 0.8839346170425415,
            "relevance": 5
          },
          {
            "score": 0.8805570602416992,
            "relevance": 4
          },
          {
            "score": 0.8755677342414856,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.16178056803077517
        }
      }
    },
    "thresh_0.100_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8282959461212158,
            "relevance": 5
          },
          {
            "score": 0.8280795216560364,
            "relevance": 4
          },
          {
            "score": 0.8277651071548462,
            "relevance": 3
          },
          {
            "score": 0.8273264169692993,
            "relevance": 5
          },
          {
            "score": 0.8270406126976013,
            "relevance": 1
          },
          {
            "score": 0.8268039226531982,
            "relevance": 2
          },
          {
            "score": 0.8265914916992188,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7572311065909518
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5956766605377197,
            "relevance": 3
          },
          {
            "score": 0.5890482664108276,
            "relevance": 2
          },
          {
            "score": 0.5730048418045044,
            "relevance": 1
          },
          {
            "score": 0.5666201114654541,
            "relevance": 5
          },
          {
            "score": 0.5460895299911499,
            "relevance": 5
          },
          {
            "score": 0.5448117256164551,
            "relevance": 2
          },
          {
            "score": 0.5431381464004517,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.16178056803077517
        }
      }
    },
    "thresh_0.100_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8282959461212158,
            "relevance": 5
          },
          {
            "score": 0.8280795216560364,
            "relevance": 4
          },
          {
            "score": 0.8277651071548462,
            "relevance": 3
          },
          {
            "score": 0.8273264169692993,
            "relevance": 5
          },
          {
            "score": 0.8270406126976013,
            "relevance": 1
          },
          {
            "score": 0.8268039226531982,
            "relevance": 2
          },
          {
            "score": 0.8265914916992188,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7572311065909518
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7845003604888916,
            "relevance": 3
          },
          {
            "score": 0.7787079811096191,
            "relevance": 2
          },
          {
            "score": 0.7556630373001099,
            "relevance": 1
          },
          {
            "score": 0.7448943257331848,
            "relevance": 5
          },
          {
            "score": 0.7139112949371338,
            "relevance": 5
          },
          {
            "score": 0.7103694677352905,
            "relevance": 4
          },
          {
            "score": 0.7034420967102051,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.16178056803077517
        }
      }
    },
    "thresh_0.100_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8282959461212158,
            "relevance": 5
          },
          {
            "score": 0.8280795216560364,
            "relevance": 4
          },
          {
            "score": 0.8277651071548462,
            "relevance": 3
          },
          {
            "score": 0.8273264169692993,
            "relevance": 5
          },
          {
            "score": 0.8270406126976013,
            "relevance": 1
          },
          {
            "score": 0.8268039226531982,
            "relevance": 2
          },
          {
            "score": 0.8265914916992188,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7572311065909518
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8661528825759888,
            "relevance": 3
          },
          {
            "score": 0.8602889776229858,
            "relevance": 2
          },
          {
            "score": 0.8374847173690796,
            "relevance": 1
          },
          {
            "score": 0.8265138268470764,
            "relevance": 5
          },
          {
            "score": 0.7942221164703369,
            "relevance": 5
          },
          {
            "score": 0.7905772924423218,
            "relevance": 4
          },
          {
            "score": 0.7818464040756226,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.16178056803077517
        }
      }
    },
    "thresh_0.100_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8282959461212158,
            "relevance": 5
          },
          {
            "score": 0.8280795216560364,
            "relevance": 4
          },
          {
            "score": 0.8277651071548462,
            "relevance": 3
          },
          {
            "score": 0.8273264169692993,
            "relevance": 5
          },
          {
            "score": 0.8270406126976013,
            "relevance": 1
          },
          {
            "score": 0.8268039226531982,
            "relevance": 2
          },
          {
            "score": 0.8265914916992188,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7572311065909518
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9421253204345703,
            "relevance": 3
          },
          {
            "score": 0.9358031749725342,
            "relevance": 2
          },
          {
            "score": 0.9163129329681396,
            "relevance": 1
          },
          {
            "score": 0.9068917632102966,
            "relevance": 5
          },
          {
            "score": 0.8769930601119995,
            "relevance": 5
          },
          {
            "score": 0.8734349012374878,
            "relevance": 4
          },
          {
            "score": 0.8654534816741943,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.16178056803077517
        }
      }
    },
    "thresh_0.110_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8282959461212158,
            "relevance": 5
          },
          {
            "score": 0.8280795216560364,
            "relevance": 4
          },
          {
            "score": 0.8277651071548462,
            "relevance": 3
          },
          {
            "score": 0.8273264169692993,
            "relevance": 5
          },
          {
            "score": 0.8270406126976013,
            "relevance": 1
          },
          {
            "score": 0.8268039226531982,
            "relevance": 2
          },
          {
            "score": 0.8265914916992188,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7572311065909518
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5969430804252625,
            "relevance": 3
          },
          {
            "score": 0.590449869632721,
            "relevance": 2
          },
          {
            "score": 0.574165403842926,
            "relevance": 1
          },
          {
            "score": 0.5676224231719971,
            "relevance": 5
          },
          {
            "score": 0.5468490123748779,
            "relevance": 5
          },
          {
            "score": 0.5452216267585754,
            "relevance": 2
          },
          {
            "score": 0.5439063310623169,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.16178056803077517
        }
      }
    },
    "thresh_0.110_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8282959461212158,
            "relevance": 5
          },
          {
            "score": 0.8280795216560364,
            "relevance": 4
          },
          {
            "score": 0.8277651071548462,
            "relevance": 3
          },
          {
            "score": 0.8273264169692993,
            "relevance": 5
          },
          {
            "score": 0.8270406126976013,
            "relevance": 1
          },
          {
            "score": 0.8268039226531982,
            "relevance": 2
          },
          {
            "score": 0.8265914916992188,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7572311065909518
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7787294983863831,
            "relevance": 3
          },
          {
            "score": 0.7732138633728027,
            "relevance": 2
          },
          {
            "score": 0.7488184571266174,
            "relevance": 1
          },
          {
            "score": 0.7372690439224243,
            "relevance": 5
          },
          {
            "score": 0.7047252655029297,
            "relevance": 5
          },
          {
            "score": 0.7011238932609558,
            "relevance": 4
          },
          {
            "score": 0.6928994655609131,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.16178056803077517
        }
      }
    },
    "thresh_0.110_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8282959461212158,
            "relevance": 5
          },
          {
            "score": 0.8280795216560364,
            "relevance": 4
          },
          {
            "score": 0.8277651071548462,
            "relevance": 3
          },
          {
            "score": 0.8273264169692993,
            "relevance": 5
          },
          {
            "score": 0.8270406126976013,
            "relevance": 1
          },
          {
            "score": 0.8268039226531982,
            "relevance": 2
          },
          {
            "score": 0.8265914916992188,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7572311065909518
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8605300784111023,
            "relevance": 3
          },
          {
            "score": 0.8550375699996948,
            "relevance": 2
          },
          {
            "score": 0.8301045298576355,
            "relevance": 1
          },
          {
            "score": 0.8178811073303223,
            "relevance": 5
          },
          {
            "score": 0.7829468250274658,
            "relevance": 5
          },
          {
            "score": 0.7791828513145447,
            "relevance": 4
          },
          {
            "score": 0.7683109045028687,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.16178056803077517
        }
      }
    },
    "thresh_0.110_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8282959461212158,
            "relevance": 5
          },
          {
            "score": 0.8280795216560364,
            "relevance": 4
          },
          {
            "score": 0.8277651071548462,
            "relevance": 3
          },
          {
            "score": 0.8273264169692993,
            "relevance": 5
          },
          {
            "score": 0.8270406126976013,
            "relevance": 1
          },
          {
            "score": 0.8268039226531982,
            "relevance": 2
          },
          {
            "score": 0.8265914916992188,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7572311065909518
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9396957755088806,
            "relevance": 3
          },
          {
            "score": 0.9338237047195435,
            "relevance": 2
          },
          {
            "score": 0.9115050435066223,
            "relevance": 1
          },
          {
            "score": 0.9003528356552124,
            "relevance": 5
          },
          {
            "score": 0.866576075553894,
            "relevance": 5
          },
          {
            "score": 0.8628258109092712,
            "relevance": 4
          },
          {
            "score": 0.851610541343689,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.16178056803077517
        }
      }
    },
    "thresh_0.120_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8282959461212158,
            "relevance": 5
          },
          {
            "score": 0.8280795216560364,
            "relevance": 4
          },
          {
            "score": 0.8277651071548462,
            "relevance": 3
          },
          {
            "score": 0.8273264169692993,
            "relevance": 5
          },
          {
            "score": 0.8270406126976013,
            "relevance": 1
          },
          {
            "score": 0.8268039226531982,
            "relevance": 2
          },
          {
            "score": 0.8265914916992188,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7572311065909518
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5977169871330261,
            "relevance": 3
          },
          {
            "score": 0.591374397277832,
            "relevance": 2
          },
          {
            "score": 0.5748658180236816,
            "relevance": 1
          },
          {
            "score": 0.5681692361831665,
            "relevance": 5
          },
          {
            "score": 0.5471770763397217,
            "relevance": 5
          },
          {
            "score": 0.545189619064331,
            "relevance": 2
          },
          {
            "score": 0.5442478656768799,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.16178056803077517
        }
      }
    },
    "thresh_0.120_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8282959461212158,
            "relevance": 5
          },
          {
            "score": 0.8280795216560364,
            "relevance": 4
          },
          {
            "score": 0.8277651071548462,
            "relevance": 3
          },
          {
            "score": 0.8273264169692993,
            "relevance": 5
          },
          {
            "score": 0.8270406126976013,
            "relevance": 1
          },
          {
            "score": 0.8268039226531982,
            "relevance": 2
          },
          {
            "score": 0.8265914916992188,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7572311065909518
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7713702917098999,
            "relevance": 3
          },
          {
            "score": 0.7661489248275757,
            "relevance": 2
          },
          {
            "score": 0.7404104471206665,
            "relevance": 1
          },
          {
            "score": 0.7280857563018799,
            "relevance": 5
          },
          {
            "score": 0.6940234899520874,
            "relevance": 5
          },
          {
            "score": 0.69036865234375,
            "relevance": 4
          },
          {
            "score": 0.6808598041534424,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.16178056803077517
        }
      }
    },
    "thresh_0.120_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8282959461212158,
            "relevance": 5
          },
          {
            "score": 0.8280795216560364,
            "relevance": 4
          },
          {
            "score": 0.8277651071548462,
            "relevance": 3
          },
          {
            "score": 0.8273264169692993,
            "relevance": 5
          },
          {
            "score": 0.8270406126976013,
            "relevance": 1
          },
          {
            "score": 0.8268039226531982,
            "relevance": 2
          },
          {
            "score": 0.8265914916992188,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7572311065909518
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8525407314300537,
            "relevance": 3
          },
          {
            "score": 0.8474483489990234,
            "relevance": 2
          },
          {
            "score": 0.8203076124191284,
            "relevance": 1
          },
          {
            "score": 0.806793212890625,
            "relevance": 5
          },
          {
            "score": 0.7691800594329834,
            "relevance": 5
          },
          {
            "score": 0.7652995586395264,
            "relevance": 4
          },
          {
            "score": 0.7522603273391724,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.16178056803077517
        }
      }
    },
    "thresh_0.120_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8282959461212158,
            "relevance": 5
          },
          {
            "score": 0.8280795216560364,
            "relevance": 4
          },
          {
            "score": 0.8277651071548462,
            "relevance": 3
          },
          {
            "score": 0.8273264169692993,
            "relevance": 5
          },
          {
            "score": 0.8270406126976013,
            "relevance": 1
          },
          {
            "score": 0.8268039226531982,
            "relevance": 2
          },
          {
            "score": 0.8265914916992188,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7572311065909518
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9341857433319092,
            "relevance": 3
          },
          {
            "score": 0.9288181066513062,
            "relevance": 2
          },
          {
            "score": 0.9033874273300171,
            "relevance": 1
          },
          {
            "score": 0.890346884727478,
            "relevance": 5
          },
          {
            "score": 0.8524036407470703,
            "relevance": 5
          },
          {
            "score": 0.8484511375427246,
            "relevance": 4
          },
          {
            "score": 0.8338037729263306,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.16178056803077517
        }
      }
    },
    "thresh_0.130_steep_5.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8282959461212158,
            "relevance": 5
          },
          {
            "score": 0.8280795216560364,
            "relevance": 4
          },
          {
            "score": 0.8277651071548462,
            "relevance": 3
          },
          {
            "score": 0.8273264169692993,
            "relevance": 5
          },
          {
            "score": 0.8270406126976013,
            "relevance": 1
          },
          {
            "score": 0.8268039226531982,
            "relevance": 2
          },
          {
            "score": 0.8265914916992188,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7572311065909518
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5979781150817871,
            "relevance": 3
          },
          {
            "score": 0.591800332069397,
            "relevance": 2
          },
          {
            "score": 0.5750853419303894,
            "relevance": 1
          },
          {
            "score": 0.5682401657104492,
            "relevance": 5
          },
          {
            "score": 0.5470542907714844,
            "relevance": 5
          },
          {
            "score": 0.5446991920471191,
            "relevance": 2
          },
          {
            "score": 0.544143795967102,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.16178056803077517
        }
      }
    },
    "thresh_0.130_steep_10.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8282959461212158,
            "relevance": 5
          },
          {
            "score": 0.8280795216560364,
            "relevance": 4
          },
          {
            "score": 0.8277651071548462,
            "relevance": 3
          },
          {
            "score": 0.8273264169692993,
            "relevance": 5
          },
          {
            "score": 0.8270406126976013,
            "relevance": 1
          },
          {
            "score": 0.8268039226531982,
            "relevance": 2
          },
          {
            "score": 0.8265914916992188,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7572311065909518
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7623953819274902,
            "relevance": 3
          },
          {
            "score": 0.7574819326400757,
            "relevance": 2
          },
          {
            "score": 0.7304232716560364,
            "relevance": 1
          },
          {
            "score": 0.717337965965271,
            "relevance": 5
          },
          {
            "score": 0.6818184852600098,
            "relevance": 5
          },
          {
            "score": 0.6781178712844849,
            "relevance": 4
          },
          {
            "score": 0.6673535108566284,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.16178056803077517
        }
      }
    },
    "thresh_0.130_steep_13.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8282959461212158,
            "relevance": 5
          },
          {
            "score": 0.8280795216560364,
            "relevance": 4
          },
          {
            "score": 0.8277651071548462,
            "relevance": 3
          },
          {
            "score": 0.8273264169692993,
            "relevance": 5
          },
          {
            "score": 0.8270406126976013,
            "relevance": 1
          },
          {
            "score": 0.8268039226531982,
            "relevance": 2
          },
          {
            "score": 0.8265914916992188,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7572311065909518
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8420727252960205,
            "relevance": 3
          },
          {
            "score": 0.8374052047729492,
            "relevance": 2
          },
          {
            "score": 0.8080030083656311,
            "relevance": 1
          },
          {
            "score": 0.7931761741638184,
            "relevance": 5
          },
          {
            "score": 0.7528895139694214,
            "relevance": 5
          },
          {
            "score": 0.7488986253738403,
            "relevance": 4
          },
          {
            "score": 0.7337030172348022,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.16178056803077517
        }
      }
    },
    "thresh_0.130_steep_17.0": {
      "query_type": "scope_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8282959461212158,
            "relevance": 5
          },
          {
            "score": 0.8280795216560364,
            "relevance": 4
          },
          {
            "score": 0.8277651071548462,
            "relevance": 3
          },
          {
            "score": 0.8273264169692993,
            "relevance": 5
          },
          {
            "score": 0.8270406126976013,
            "relevance": 1
          },
          {
            "score": 0.8268039226531982,
            "relevance": 2
          },
          {
            "score": 0.8265914916992188,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7572311065909518
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9252798557281494,
            "relevance": 3
          },
          {
            "score": 0.9204683303833008,
            "relevance": 2
          },
          {
            "score": 0.8916580080986023,
            "relevance": 1
          },
          {
            "score": 0.8765888214111328,
            "relevance": 5
          },
          {
            "score": 0.8342455625534058,
            "relevance": 5
          },
          {
            "score": 0.8300849199295044,
            "relevance": 4
          },
          {
            "score": 0.8118699789047241,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.16178056803077517
        }
      }
    }
  }
}