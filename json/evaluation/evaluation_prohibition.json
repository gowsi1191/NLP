{
  "P01": {
    "thresh_0.090_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.79531329870224,
            "relevance": 4
          },
          {
            "score": 0.7951686382293701,
            "relevance": 2
          },
          {
            "score": 0.7939533591270447,
            "relevance": 5
          },
          {
            "score": 0.7933061122894287,
            "relevance": 3
          },
          {
            "score": 0.7929662466049194,
            "relevance": 2
          },
          {
            "score": 0.7924280762672424,
            "relevance": 1
          },
          {
            "score": 0.7907314896583557,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5579305253465247
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.883377730846405,
            "relevance": 5
          },
          {
            "score": 0.8707621693611145,
            "relevance": 2
          },
          {
            "score": 0.8677594661712646,
            "relevance": 1
          },
          {
            "score": 0.8583427667617798,
            "relevance": 4
          },
          {
            "score": 0.858153223991394,
            "relevance": 3
          },
          {
            "score": 0.8447147607803345,
            "relevance": 2
          },
          {
            "score": 0.8292210698127747,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5751544365341659
        }
      }
    },
    "thresh_0.090_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.79531329870224,
            "relevance": 4
          },
          {
            "score": 0.7951686382293701,
            "relevance": 2
          },
          {
            "score": 0.7939533591270447,
            "relevance": 5
          },
          {
            "score": 0.7933061122894287,
            "relevance": 3
          },
          {
            "score": 0.7929662466049194,
            "relevance": 2
          },
          {
            "score": 0.7924280762672424,
            "relevance": 1
          },
          {
            "score": 0.7907314896583557,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5579305253465247
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0080273151397705,
            "relevance": 2
          },
          {
            "score": 1.0078067779541016,
            "relevance": 5
          },
          {
            "score": 1.0020411014556885,
            "relevance": 1
          },
          {
            "score": 1.0004962682724,
            "relevance": 4
          },
          {
            "score": 0.9956865310668945,
            "relevance": 3
          },
          {
            "score": 0.990593433380127,
            "relevance": 2
          },
          {
            "score": 0.9889764189720154,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39716310843255515
        }
      }
    },
    "thresh_0.090_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.79531329870224,
            "relevance": 4
          },
          {
            "score": 0.7951686382293701,
            "relevance": 2
          },
          {
            "score": 0.7939533591270447,
            "relevance": 5
          },
          {
            "score": 0.7933061122894287,
            "relevance": 3
          },
          {
            "score": 0.7929662466049194,
            "relevance": 2
          },
          {
            "score": 0.7924280762672424,
            "relevance": 1
          },
          {
            "score": 0.7907314896583557,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5579305253465247
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0242199897766113,
            "relevance": 2
          },
          {
            "score": 1.0206286907196045,
            "relevance": 5
          },
          {
            "score": 1.0181329250335693,
            "relevance": 4
          },
          {
            "score": 1.0173982381820679,
            "relevance": 1
          },
          {
            "score": 1.0127058029174805,
            "relevance": 5
          },
          {
            "score": 1.0119560956954956,
            "relevance": 3
          },
          {
            "score": 1.0093969106674194,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.5177304867460442
        }
      }
    },
    "thresh_0.090_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.79531329870224,
            "relevance": 4
          },
          {
            "score": 0.7951686382293701,
            "relevance": 2
          },
          {
            "score": 0.7939533591270447,
            "relevance": 5
          },
          {
            "score": 0.7933061122894287,
            "relevance": 3
          },
          {
            "score": 0.7929662466049194,
            "relevance": 2
          },
          {
            "score": 0.7924280762672424,
            "relevance": 1
          },
          {
            "score": 0.7907314896583557,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5579305253465247
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0297110080718994,
            "relevance": 2
          },
          {
            "score": 1.0245940685272217,
            "relevance": 5
          },
          {
            "score": 1.0243237018585205,
            "relevance": 4
          },
          {
            "score": 1.0224965810775757,
            "relevance": 1
          },
          {
            "score": 1.022141456604004,
            "relevance": 5
          },
          {
            "score": 1.0174835920333862,
            "relevance": 3
          },
          {
            "score": 1.016173005104065,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.5177304867460442
        }
      }
    },
    "thresh_0.100_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.79531329870224,
            "relevance": 4
          },
          {
            "score": 0.7951686382293701,
            "relevance": 2
          },
          {
            "score": 0.7939533591270447,
            "relevance": 5
          },
          {
            "score": 0.7933061122894287,
            "relevance": 3
          },
          {
            "score": 0.7929662466049194,
            "relevance": 2
          },
          {
            "score": 0.7924280762672424,
            "relevance": 1
          },
          {
            "score": 0.7907314896583557,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5579305253465247
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8937884569168091,
            "relevance": 5
          },
          {
            "score": 0.8804137706756592,
            "relevance": 2
          },
          {
            "score": 0.8776613473892212,
            "relevance": 1
          },
          {
            "score": 0.8679309487342834,
            "relevance": 3
          },
          {
            "score": 0.8677854537963867,
            "relevance": 4
          },
          {
            "score": 0.8540348410606384,
            "relevance": 2
          },
          {
            "score": 0.8376559615135193,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5751544365341659
        }
      }
    },
    "thresh_0.100_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.79531329870224,
            "relevance": 4
          },
          {
            "score": 0.7951686382293701,
            "relevance": 2
          },
          {
            "score": 0.7939533591270447,
            "relevance": 5
          },
          {
            "score": 0.7933061122894287,
            "relevance": 3
          },
          {
            "score": 0.7929662466049194,
            "relevance": 2
          },
          {
            "score": 0.7924280762672424,
            "relevance": 1
          },
          {
            "score": 0.7907314896583557,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5579305253465247
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0228996276855469,
            "relevance": 5
          },
          {
            "score": 1.0225365161895752,
            "relevance": 2
          },
          {
            "score": 1.0167685747146606,
            "relevance": 1
          },
          {
            "score": 1.0148366689682007,
            "relevance": 4
          },
          {
            "score": 1.010324478149414,
            "relevance": 3
          },
          {
            "score": 1.0048308372497559,
            "relevance": 2
          },
          {
            "score": 1.0022997856140137,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5751544365341659
        }
      }
    },
    "thresh_0.100_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.79531329870224,
            "relevance": 4
          },
          {
            "score": 0.7951686382293701,
            "relevance": 2
          },
          {
            "score": 0.7939533591270447,
            "relevance": 5
          },
          {
            "score": 0.7933061122894287,
            "relevance": 3
          },
          {
            "score": 0.7929662466049194,
            "relevance": 2
          },
          {
            "score": 0.7924280762672424,
            "relevance": 1
          },
          {
            "score": 0.7907314896583557,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5579305253465247
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0401642322540283,
            "relevance": 2
          },
          {
            "score": 1.0368850231170654,
            "relevance": 5
          },
          {
            "score": 1.0340200662612915,
            "relevance": 4
          },
          {
            "score": 1.0334943532943726,
            "relevance": 1
          },
          {
            "score": 1.0280349254608154,
            "relevance": 3
          },
          {
            "score": 1.0280191898345947,
            "relevance": 5
          },
          {
            "score": 1.0252695083618164,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.5177304867460442
        }
      }
    },
    "thresh_0.100_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.79531329870224,
            "relevance": 4
          },
          {
            "score": 0.7951686382293701,
            "relevance": 2
          },
          {
            "score": 0.7939533591270447,
            "relevance": 5
          },
          {
            "score": 0.7933061122894287,
            "relevance": 3
          },
          {
            "score": 0.7929662466049194,
            "relevance": 2
          },
          {
            "score": 0.7924280762672424,
            "relevance": 1
          },
          {
            "score": 0.7907314896583557,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5579305253465247
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0463502407073975,
            "relevance": 2
          },
          {
            "score": 1.0413594245910645,
            "relevance": 5
          },
          {
            "score": 1.0409904718399048,
            "relevance": 4
          },
          {
            "score": 1.0392404794692993,
            "relevance": 1
          },
          {
            "score": 1.0386137962341309,
            "relevance": 5
          },
          {
            "score": 1.03426194190979,
            "relevance": 3
          },
          {
            "score": 1.0328948497772217,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.5177304867460442
        }
      }
    },
    "thresh_0.110_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.79531329870224,
            "relevance": 4
          },
          {
            "score": 0.7951686382293701,
            "relevance": 2
          },
          {
            "score": 0.7939533591270447,
            "relevance": 5
          },
          {
            "score": 0.7933061122894287,
            "relevance": 3
          },
          {
            "score": 0.7929662466049194,
            "relevance": 2
          },
          {
            "score": 0.7924280762672424,
            "relevance": 1
          },
          {
            "score": 0.7907314896583557,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5579305253465247
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9037042856216431,
            "relevance": 5
          },
          {
            "score": 0.8895456790924072,
            "relevance": 2
          },
          {
            "score": 0.887061357498169,
            "relevance": 1
          },
          {
            "score": 0.8772135972976685,
            "relevance": 3
          },
          {
            "score": 0.8767141103744507,
            "relevance": 4
          },
          {
            "score": 0.8628541827201843,
            "relevance": 2
          },
          {
            "score": 0.8455644249916077,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5751544365341659
        }
      }
    },
    "thresh_0.110_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.79531329870224,
            "relevance": 4
          },
          {
            "score": 0.7951686382293701,
            "relevance": 2
          },
          {
            "score": 0.7939533591270447,
            "relevance": 5
          },
          {
            "score": 0.7933061122894287,
            "relevance": 3
          },
          {
            "score": 0.7929662466049194,
            "relevance": 2
          },
          {
            "score": 0.7924280762672424,
            "relevance": 1
          },
          {
            "score": 0.7907314896583557,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5579305253465247
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0375727415084839,
            "relevance": 5
          },
          {
            "score": 1.0365664958953857,
            "relevance": 2
          },
          {
            "score": 1.031043291091919,
            "relevance": 1
          },
          {
            "score": 1.0286865234375,
            "relevance": 4
          },
          {
            "score": 1.024506688117981,
            "relevance": 3
          },
          {
            "score": 1.0185763835906982,
            "relevance": 2
          },
          {
            "score": 1.0150411128997803,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5751544365341659
        }
      }
    },
    "thresh_0.110_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.79531329870224,
            "relevance": 4
          },
          {
            "score": 0.7951686382293701,
            "relevance": 2
          },
          {
            "score": 0.7939533591270447,
            "relevance": 5
          },
          {
            "score": 0.7933061122894287,
            "relevance": 3
          },
          {
            "score": 0.7929662466049194,
            "relevance": 2
          },
          {
            "score": 0.7924280762672424,
            "relevance": 1
          },
          {
            "score": 0.7907314896583557,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5579305253465247
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0557398796081543,
            "relevance": 2
          },
          {
            "score": 1.0528167486190796,
            "relevance": 5
          },
          {
            "score": 1.0495336055755615,
            "relevance": 4
          },
          {
            "score": 1.0492454767227173,
            "relevance": 1
          },
          {
            "score": 1.0437692403793335,
            "relevance": 3
          },
          {
            "score": 1.042884349822998,
            "relevance": 5
          },
          {
            "score": 1.040771484375,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.5177304867460442
        }
      }
    },
    "thresh_0.110_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.79531329870224,
            "relevance": 4
          },
          {
            "score": 0.7951686382293701,
            "relevance": 2
          },
          {
            "score": 0.7939533591270447,
            "relevance": 5
          },
          {
            "score": 0.7933061122894287,
            "relevance": 3
          },
          {
            "score": 0.7929662466049194,
            "relevance": 2
          },
          {
            "score": 0.7924280762672424,
            "relevance": 1
          },
          {
            "score": 0.7907314896583557,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5579305253465247
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0627050399780273,
            "relevance": 2
          },
          {
            "score": 1.057862639427185,
            "relevance": 5
          },
          {
            "score": 1.0573761463165283,
            "relevance": 4
          },
          {
            "score": 1.0557175874710083,
            "relevance": 1
          },
          {
            "score": 1.0547692775726318,
            "relevance": 5
          },
          {
            "score": 1.050780177116394,
            "relevance": 3
          },
          {
            "score": 1.0493462085723877,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.5177304867460442
        }
      }
    },
    "thresh_0.120_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.79531329870224,
            "relevance": 4
          },
          {
            "score": 0.7951686382293701,
            "relevance": 2
          },
          {
            "score": 0.7939533591270447,
            "relevance": 5
          },
          {
            "score": 0.7933061122894287,
            "relevance": 3
          },
          {
            "score": 0.7929662466049194,
            "relevance": 2
          },
          {
            "score": 0.7924280762672424,
            "relevance": 1
          },
          {
            "score": 0.7907314896583557,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5579305253465247
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9130830764770508,
            "relevance": 5
          },
          {
            "score": 0.8981167078018188,
            "relevance": 2
          },
          {
            "score": 0.8959171772003174,
            "relevance": 1
          },
          {
            "score": 0.8859582543373108,
            "relevance": 3
          },
          {
            "score": 0.8850867748260498,
            "relevance": 4
          },
          {
            "score": 0.8711295127868652,
            "relevance": 2
          },
          {
            "score": 0.852904736995697,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5751544365341659
        }
      }
    },
    "thresh_0.120_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.79531329870224,
            "relevance": 4
          },
          {
            "score": 0.7951686382293701,
            "relevance": 2
          },
          {
            "score": 0.7939533591270447,
            "relevance": 5
          },
          {
            "score": 0.7933061122894287,
            "relevance": 3
          },
          {
            "score": 0.7929662466049194,
            "relevance": 2
          },
          {
            "score": 0.7924280762672424,
            "relevance": 1
          },
          {
            "score": 0.7907314896583557,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5579305253465247
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.051772117614746,
            "relevance": 5
          },
          {
            "score": 1.0500584840774536,
            "relevance": 2
          },
          {
            "score": 1.0448079109191895,
            "relevance": 1
          },
          {
            "score": 1.0419849157333374,
            "relevance": 4
          },
          {
            "score": 1.0381731986999512,
            "relevance": 3
          },
          {
            "score": 1.0317670106887817,
            "relevance": 2
          },
          {
            "score": 1.0271306037902832,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5751544365341659
        }
      }
    },
    "thresh_0.120_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.79531329870224,
            "relevance": 4
          },
          {
            "score": 0.7951686382293701,
            "relevance": 2
          },
          {
            "score": 0.7939533591270447,
            "relevance": 5
          },
          {
            "score": 0.7933061122894287,
            "relevance": 3
          },
          {
            "score": 0.7929662466049194,
            "relevance": 2
          },
          {
            "score": 0.7924280762672424,
            "relevance": 1
          },
          {
            "score": 0.7907314896583557,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5579305253465247
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0708945989608765,
            "relevance": 2
          },
          {
            "score": 1.0683757066726685,
            "relevance": 5
          },
          {
            "score": 1.0646179914474487,
            "relevance": 4
          },
          {
            "score": 1.064599633216858,
            "relevance": 1
          },
          {
            "score": 1.0591051578521729,
            "relevance": 3
          },
          {
            "score": 1.057234764099121,
            "relevance": 5
          },
          {
            "score": 1.0558445453643799,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.5177304867460442
        }
      }
    },
    "thresh_0.120_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.79531329870224,
            "relevance": 4
          },
          {
            "score": 0.7951686382293701,
            "relevance": 2
          },
          {
            "score": 0.7939533591270447,
            "relevance": 5
          },
          {
            "score": 0.7933061122894287,
            "relevance": 3
          },
          {
            "score": 0.7929662466049194,
            "relevance": 2
          },
          {
            "score": 0.7924280762672424,
            "relevance": 1
          },
          {
            "score": 0.7907314896583557,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5579305253465247
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0787314176559448,
            "relevance": 2
          },
          {
            "score": 1.0740629434585571,
            "relevance": 5
          },
          {
            "score": 1.0734353065490723,
            "relevance": 4
          },
          {
            "score": 1.0718849897384644,
            "relevance": 1
          },
          {
            "score": 1.0705540180206299,
            "relevance": 5
          },
          {
            "score": 1.066993236541748,
            "relevance": 3
          },
          {
            "score": 1.0654793977737427,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.5177304867460442
        }
      }
    },
    "thresh_0.130_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.79531329870224,
            "relevance": 4
          },
          {
            "score": 0.7951686382293701,
            "relevance": 2
          },
          {
            "score": 0.7939533591270447,
            "relevance": 5
          },
          {
            "score": 0.7933061122894287,
            "relevance": 3
          },
          {
            "score": 0.7929662466049194,
            "relevance": 2
          },
          {
            "score": 0.7924280762672424,
            "relevance": 1
          },
          {
            "score": 0.7907314896583557,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5579305253465247
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9218847751617432,
            "relevance": 5
          },
          {
            "score": 0.9060876369476318,
            "relevance": 2
          },
          {
            "score": 0.9041887521743774,
            "relevance": 1
          },
          {
            "score": 0.8941243290901184,
            "relevance": 3
          },
          {
            "score": 0.8928639888763428,
            "relevance": 4
          },
          {
            "score": 0.878820538520813,
            "relevance": 2
          },
          {
            "score": 0.8596382141113281,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5751544365341659
        }
      }
    },
    "thresh_0.130_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.79531329870224,
            "relevance": 4
          },
          {
            "score": 0.7951686382293701,
            "relevance": 2
          },
          {
            "score": 0.7939533591270447,
            "relevance": 5
          },
          {
            "score": 0.7933061122894287,
            "relevance": 3
          },
          {
            "score": 0.7929662466049194,
            "relevance": 2
          },
          {
            "score": 0.7924280762672424,
            "relevance": 1
          },
          {
            "score": 0.7907314896583557,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5579305253465247
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0654449462890625,
            "relevance": 5
          },
          {
            "score": 1.0629551410675049,
            "relevance": 2
          },
          {
            "score": 1.05800461769104,
            "relevance": 1
          },
          {
            "score": 1.0546711683273315,
            "relevance": 4
          },
          {
            "score": 1.051264762878418,
            "relevance": 3
          },
          {
            "score": 1.044338345527649,
            "relevance": 2
          },
          {
            "score": 1.0384981632232666,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5751544365341659
        }
      }
    },
    "thresh_0.130_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.79531329870224,
            "relevance": 4
          },
          {
            "score": 0.7951686382293701,
            "relevance": 2
          },
          {
            "score": 0.7939533591270447,
            "relevance": 5
          },
          {
            "score": 0.7933061122894287,
            "relevance": 3
          },
          {
            "score": 0.7929662466049194,
            "relevance": 2
          },
          {
            "score": 0.7924280762672424,
            "relevance": 1
          },
          {
            "score": 0.7907314896583557,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5579305253465247
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0855765342712402,
            "relevance": 2
          },
          {
            "score": 1.0835154056549072,
            "relevance": 5
          },
          {
            "score": 1.079505205154419,
            "relevance": 1
          },
          {
            "score": 1.079217791557312,
            "relevance": 4
          },
          {
            "score": 1.073988914489746,
            "relevance": 3
          },
          {
            "score": 1.0710018873214722,
            "relevance": 5
          },
          {
            "score": 1.0704295635223389,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39716310843255515
        }
      }
    },
    "thresh_0.130_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.79531329870224,
            "relevance": 4
          },
          {
            "score": 0.7951686382293701,
            "relevance": 2
          },
          {
            "score": 0.7939533591270447,
            "relevance": 5
          },
          {
            "score": 0.7933061122894287,
            "relevance": 3
          },
          {
            "score": 0.7929662466049194,
            "relevance": 2
          },
          {
            "score": 0.7924280762672424,
            "relevance": 1
          },
          {
            "score": 0.7907314896583557,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5579305253465247
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0943875312805176,
            "relevance": 2
          },
          {
            "score": 1.0899217128753662,
            "relevance": 5
          },
          {
            "score": 1.0891233682632446,
            "relevance": 4
          },
          {
            "score": 1.0876998901367188,
            "relevance": 1
          },
          {
            "score": 1.0859122276306152,
            "relevance": 5
          },
          {
            "score": 1.0828571319580078,
            "relevance": 3
          },
          {
            "score": 1.0812461376190186,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.5177304867460442
        }
      }
    }
  },
  "P02": {
    "thresh_0.090_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8414292931556702,
            "relevance": 2
          },
          {
            "score": 0.8414196372032166,
            "relevance": 5
          },
          {
            "score": 0.8406470417976379,
            "relevance": 1
          },
          {
            "score": 0.8400040864944458,
            "relevance": 2
          },
          {
            "score": 0.8398102521896362,
            "relevance": 3
          },
          {
            "score": 0.8378170132637024,
            "relevance": 4
          },
          {
            "score": 0.8376782536506653,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39716310843255515
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5986315011978149,
            "relevance": 5
          },
          {
            "score": 0.5643240213394165,
            "relevance": 4
          },
          {
            "score": 0.5447841286659241,
            "relevance": 5
          },
          {
            "score": 0.5293140411376953,
            "relevance": 2
          },
          {
            "score": 0.5147698521614075,
            "relevance": 3
          },
          {
            "score": 0.5114119648933411,
            "relevance": 2
          },
          {
            "score": 0.5090375542640686,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.090_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8414292931556702,
            "relevance": 2
          },
          {
            "score": 0.8414196372032166,
            "relevance": 5
          },
          {
            "score": 0.8406470417976379,
            "relevance": 1
          },
          {
            "score": 0.8400040864944458,
            "relevance": 2
          },
          {
            "score": 0.8398102521896362,
            "relevance": 3
          },
          {
            "score": 0.8378170132637024,
            "relevance": 4
          },
          {
            "score": 0.8376782536506653,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39716310843255515
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8080841302871704,
            "relevance": 5
          },
          {
            "score": 0.7717803716659546,
            "relevance": 4
          },
          {
            "score": 0.750408947467804,
            "relevance": 5
          },
          {
            "score": 0.7242156267166138,
            "relevance": 2
          },
          {
            "score": 0.7130970358848572,
            "relevance": 3
          },
          {
            "score": 0.7050923705101013,
            "relevance": 2
          },
          {
            "score": 0.703359067440033,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.090_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8414292931556702,
            "relevance": 2
          },
          {
            "score": 0.8414196372032166,
            "relevance": 5
          },
          {
            "score": 0.8406470417976379,
            "relevance": 1
          },
          {
            "score": 0.8400040864944458,
            "relevance": 2
          },
          {
            "score": 0.8398102521896362,
            "relevance": 3
          },
          {
            "score": 0.8378170132637024,
            "relevance": 4
          },
          {
            "score": 0.8376782536506653,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39716310843255515
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8787081241607666,
            "relevance": 5
          },
          {
            "score": 0.8458973169326782,
            "relevance": 4
          },
          {
            "score": 0.8263946175575256,
            "relevance": 5
          },
          {
            "score": 0.8050084114074707,
            "relevance": 2
          },
          {
            "score": 0.7929731011390686,
            "relevance": 3
          },
          {
            "score": 0.7861269116401672,
            "relevance": 2
          },
          {
            "score": 0.7842715382575989,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.090_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8414292931556702,
            "relevance": 2
          },
          {
            "score": 0.8414196372032166,
            "relevance": 5
          },
          {
            "score": 0.8406470417976379,
            "relevance": 1
          },
          {
            "score": 0.8400040864944458,
            "relevance": 2
          },
          {
            "score": 0.8398102521896362,
            "relevance": 3
          },
          {
            "score": 0.8378170132637024,
            "relevance": 4
          },
          {
            "score": 0.8376782536506653,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39716310843255515
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9310590028762817,
            "relevance": 5
          },
          {
            "score": 0.9036738872528076,
            "relevance": 4
          },
          {
            "score": 0.8874331116676331,
            "relevance": 5
          },
          {
            "score": 0.87717604637146,
            "relevance": 2
          },
          {
            "score": 0.8624036908149719,
            "relevance": 3
          },
          {
            "score": 0.8591548800468445,
            "relevance": 2
          },
          {
            "score": 0.8568547368049622,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.100_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8414292931556702,
            "relevance": 2
          },
          {
            "score": 0.8414196372032166,
            "relevance": 5
          },
          {
            "score": 0.8406470417976379,
            "relevance": 1
          },
          {
            "score": 0.8400040864944458,
            "relevance": 2
          },
          {
            "score": 0.8398102521896362,
            "relevance": 3
          },
          {
            "score": 0.8378170132637024,
            "relevance": 4
          },
          {
            "score": 0.8376782536506653,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39716310843255515
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6021144390106201,
            "relevance": 5
          },
          {
            "score": 0.5674574971199036,
            "relevance": 4
          },
          {
            "score": 0.5476969480514526,
            "relevance": 5
          },
          {
            "score": 0.5314610004425049,
            "relevance": 2
          },
          {
            "score": 0.5171194076538086,
            "relevance": 3
          },
          {
            "score": 0.5135188698768616,
            "relevance": 2
          },
          {
            "score": 0.5111756920814514,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.100_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8414292931556702,
            "relevance": 2
          },
          {
            "score": 0.8414196372032166,
            "relevance": 5
          },
          {
            "score": 0.8406470417976379,
            "relevance": 1
          },
          {
            "score": 0.8400040864944458,
            "relevance": 2
          },
          {
            "score": 0.8398102521896362,
            "relevance": 3
          },
          {
            "score": 0.8378170132637024,
            "relevance": 4
          },
          {
            "score": 0.8376782536506653,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39716310843255515
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8100695610046387,
            "relevance": 5
          },
          {
            "score": 0.7723228335380554,
            "relevance": 4
          },
          {
            "score": 0.7500394582748413,
            "relevance": 5
          },
          {
            "score": 0.7204245328903198,
            "relevance": 2
          },
          {
            "score": 0.7102200984954834,
            "relevance": 3
          },
          {
            "score": 0.7010257840156555,
            "relevance": 2
          },
          {
            "score": 0.6994461417198181,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.100_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8414292931556702,
            "relevance": 2
          },
          {
            "score": 0.8414196372032166,
            "relevance": 5
          },
          {
            "score": 0.8406470417976379,
            "relevance": 1
          },
          {
            "score": 0.8400040864944458,
            "relevance": 2
          },
          {
            "score": 0.8398102521896362,
            "relevance": 3
          },
          {
            "score": 0.8378170132637024,
            "relevance": 4
          },
          {
            "score": 0.8376782536506653,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39716310843255515
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.883529543876648,
            "relevance": 5
          },
          {
            "score": 0.848917543888092,
            "relevance": 4
          },
          {
            "score": 0.8282307386398315,
            "relevance": 5
          },
          {
            "score": 0.8020662069320679,
            "relevance": 2
          },
          {
            "score": 0.7913559675216675,
            "relevance": 3
          },
          {
            "score": 0.782765805721283,
            "relevance": 2
          },
          {
            "score": 0.7811391949653625,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.100_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8414292931556702,
            "relevance": 2
          },
          {
            "score": 0.8414196372032166,
            "relevance": 5
          },
          {
            "score": 0.8406470417976379,
            "relevance": 1
          },
          {
            "score": 0.8400040864944458,
            "relevance": 2
          },
          {
            "score": 0.8398102521896362,
            "relevance": 3
          },
          {
            "score": 0.8378170132637024,
            "relevance": 4
          },
          {
            "score": 0.8376782536506653,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39716310843255515
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9402275085449219,
            "relevance": 5
          },
          {
            "score": 0.9110952019691467,
            "relevance": 4
          },
          {
            "score": 0.8936394453048706,
            "relevance": 5
          },
          {
            "score": 0.8779630661010742,
            "relevance": 2
          },
          {
            "score": 0.8647738695144653,
            "relevance": 3
          },
          {
            "score": 0.8594227433204651,
            "relevance": 2
          },
          {
            "score": 0.8574044108390808,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.110_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8414292931556702,
            "relevance": 2
          },
          {
            "score": 0.8414196372032166,
            "relevance": 5
          },
          {
            "score": 0.8406470417976379,
            "relevance": 1
          },
          {
            "score": 0.8400040864944458,
            "relevance": 2
          },
          {
            "score": 0.8398102521896362,
            "relevance": 3
          },
          {
            "score": 0.8378170132637024,
            "relevance": 4
          },
          {
            "score": 0.8376782536506653,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39716310843255515
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6052091121673584,
            "relevance": 5
          },
          {
            "score": 0.5702545642852783,
            "relevance": 4
          },
          {
            "score": 0.5503025054931641,
            "relevance": 5
          },
          {
            "score": 0.5332821607589722,
            "relevance": 2
          },
          {
            "score": 0.5191905498504639,
            "relevance": 3
          },
          {
            "score": 0.5153365135192871,
            "relevance": 2
          },
          {
            "score": 0.5130325555801392,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.110_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8414292931556702,
            "relevance": 2
          },
          {
            "score": 0.8414196372032166,
            "relevance": 5
          },
          {
            "score": 0.8406470417976379,
            "relevance": 1
          },
          {
            "score": 0.8400040864944458,
            "relevance": 2
          },
          {
            "score": 0.8398102521896362,
            "relevance": 3
          },
          {
            "score": 0.8378170132637024,
            "relevance": 4
          },
          {
            "score": 0.8376782536506653,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39716310843255515
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.810795783996582,
            "relevance": 5
          },
          {
            "score": 0.7715893983840942,
            "relevance": 4
          },
          {
            "score": 0.7483861446380615,
            "relevance": 5
          },
          {
            "score": 0.7152320146560669,
            "relevance": 2
          },
          {
            "score": 0.706008791923523,
            "relevance": 3
          },
          {
            "score": 0.6955890655517578,
            "relevance": 2
          },
          {
            "score": 0.6941738128662109,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.110_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8414292931556702,
            "relevance": 2
          },
          {
            "score": 0.8414196372032166,
            "relevance": 5
          },
          {
            "score": 0.8406470417976379,
            "relevance": 1
          },
          {
            "score": 0.8400040864944458,
            "relevance": 2
          },
          {
            "score": 0.8398102521896362,
            "relevance": 3
          },
          {
            "score": 0.8378170132637024,
            "relevance": 4
          },
          {
            "score": 0.8376782536506653,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39716310843255515
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.886813759803772,
            "relevance": 5
          },
          {
            "score": 0.8502837419509888,
            "relevance": 4
          },
          {
            "score": 0.8283407688140869,
            "relevance": 5
          },
          {
            "score": 0.7970373630523682,
            "relevance": 2
          },
          {
            "score": 0.7877824306488037,
            "relevance": 3
          },
          {
            "score": 0.7773289680480957,
            "relevance": 2
          },
          {
            "score": 0.7759525775909424,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.110_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8414292931556702,
            "relevance": 2
          },
          {
            "score": 0.8414196372032166,
            "relevance": 5
          },
          {
            "score": 0.8406470417976379,
            "relevance": 1
          },
          {
            "score": 0.8400040864944458,
            "relevance": 2
          },
          {
            "score": 0.8398102521896362,
            "relevance": 3
          },
          {
            "score": 0.8378170132637024,
            "relevance": 4
          },
          {
            "score": 0.8376782536506653,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39716310843255515
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9479119777679443,
            "relevance": 5
          },
          {
            "score": 0.9168071746826172,
            "relevance": 4
          },
          {
            "score": 0.8979837894439697,
            "relevance": 5
          },
          {
            "score": 0.876140832901001,
            "relevance": 2
          },
          {
            "score": 0.8647801876068115,
            "relevance": 3
          },
          {
            "score": 0.8570523262023926,
            "relevance": 2
          },
          {
            "score": 0.8553581237792969,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.120_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8414292931556702,
            "relevance": 2
          },
          {
            "score": 0.8414196372032166,
            "relevance": 5
          },
          {
            "score": 0.8406470417976379,
            "relevance": 1
          },
          {
            "score": 0.8400040864944458,
            "relevance": 2
          },
          {
            "score": 0.8398102521896362,
            "relevance": 3
          },
          {
            "score": 0.8378170132637024,
            "relevance": 4
          },
          {
            "score": 0.8376782536506653,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39716310843255515
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6078821420669556,
            "relevance": 5
          },
          {
            "score": 0.57268226146698,
            "relevance": 4
          },
          {
            "score": 0.5525684952735901,
            "relevance": 5
          },
          {
            "score": 0.5347484350204468,
            "relevance": 2
          },
          {
            "score": 0.5209527015686035,
            "relevance": 3
          },
          {
            "score": 0.5168359279632568,
            "relevance": 2
          },
          {
            "score": 0.514578640460968,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.120_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8414292931556702,
            "relevance": 2
          },
          {
            "score": 0.8414196372032166,
            "relevance": 5
          },
          {
            "score": 0.8406470417976379,
            "relevance": 1
          },
          {
            "score": 0.8400040864944458,
            "relevance": 2
          },
          {
            "score": 0.8398102521896362,
            "relevance": 3
          },
          {
            "score": 0.8378170132637024,
            "relevance": 4
          },
          {
            "score": 0.8376782536506653,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39716310843255515
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8101736307144165,
            "relevance": 5
          },
          {
            "score": 0.7694976329803467,
            "relevance": 4
          },
          {
            "score": 0.7453721165657043,
            "relevance": 5
          },
          {
            "score": 0.7085890769958496,
            "relevance": 2
          },
          {
            "score": 0.7004051208496094,
            "relevance": 3
          },
          {
            "score": 0.6887356042861938,
            "relevance": 2
          },
          {
            "score": 0.6874938607215881,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.120_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8414292931556702,
            "relevance": 2
          },
          {
            "score": 0.8414196372032166,
            "relevance": 5
          },
          {
            "score": 0.8406470417976379,
            "relevance": 1
          },
          {
            "score": 0.8400040864944458,
            "relevance": 2
          },
          {
            "score": 0.8398102521896362,
            "relevance": 3
          },
          {
            "score": 0.8378170132637024,
            "relevance": 4
          },
          {
            "score": 0.8376782536506653,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39716310843255515
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8883920907974243,
            "relevance": 5
          },
          {
            "score": 0.8498258590698242,
            "relevance": 4
          },
          {
            "score": 0.8265567421913147,
            "relevance": 5
          },
          {
            "score": 0.7897818088531494,
            "relevance": 2
          },
          {
            "score": 0.7821018695831299,
            "relevance": 3
          },
          {
            "score": 0.7696799039840698,
            "relevance": 2
          },
          {
            "score": 0.7685723900794983,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.120_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8414292931556702,
            "relevance": 2
          },
          {
            "score": 0.8414196372032166,
            "relevance": 5
          },
          {
            "score": 0.8406470417976379,
            "relevance": 1
          },
          {
            "score": 0.8400040864944458,
            "relevance": 2
          },
          {
            "score": 0.8398102521896362,
            "relevance": 3
          },
          {
            "score": 0.8378170132637024,
            "relevance": 4
          },
          {
            "score": 0.8376782536506653,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39716310843255515
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9538590908050537,
            "relevance": 5
          },
          {
            "score": 0.9205286502838135,
            "relevance": 4
          },
          {
            "score": 0.9001701474189758,
            "relevance": 5
          },
          {
            "score": 0.8713822364807129,
            "relevance": 2
          },
          {
            "score": 0.8620984554290771,
            "relevance": 3
          },
          {
            "score": 0.851716160774231,
            "relevance": 2
          },
          {
            "score": 0.8503878712654114,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.130_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8414292931556702,
            "relevance": 2
          },
          {
            "score": 0.8414196372032166,
            "relevance": 5
          },
          {
            "score": 0.8406470417976379,
            "relevance": 1
          },
          {
            "score": 0.8400040864944458,
            "relevance": 2
          },
          {
            "score": 0.8398102521896362,
            "relevance": 3
          },
          {
            "score": 0.8378170132637024,
            "relevance": 4
          },
          {
            "score": 0.8376782536506653,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39716310843255515
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6101020574569702,
            "relevance": 5
          },
          {
            "score": 0.5747095346450806,
            "relevance": 4
          },
          {
            "score": 0.5544641017913818,
            "relevance": 5
          },
          {
            "score": 0.5358332395553589,
            "relevance": 2
          },
          {
            "score": 0.5223770141601562,
            "relevance": 3
          },
          {
            "score": 0.5179897546768188,
            "relevance": 2
          },
          {
            "score": 0.5157862901687622,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.130_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8414292931556702,
            "relevance": 2
          },
          {
            "score": 0.8414196372032166,
            "relevance": 5
          },
          {
            "score": 0.8406470417976379,
            "relevance": 1
          },
          {
            "score": 0.8400040864944458,
            "relevance": 2
          },
          {
            "score": 0.8398102521896362,
            "relevance": 3
          },
          {
            "score": 0.8378170132637024,
            "relevance": 4
          },
          {
            "score": 0.8376782536506653,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39716310843255515
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8081213235855103,
            "relevance": 5
          },
          {
            "score": 0.7659741640090942,
            "relevance": 4
          },
          {
            "score": 0.7409301996231079,
            "relevance": 5
          },
          {
            "score": 0.7004612684249878,
            "relevance": 2
          },
          {
            "score": 0.6933642625808716,
            "relevance": 3
          },
          {
            "score": 0.6804336309432983,
            "relevance": 2
          },
          {
            "score": 0.6793719530105591,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.130_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8414292931556702,
            "relevance": 2
          },
          {
            "score": 0.8414196372032166,
            "relevance": 5
          },
          {
            "score": 0.8406470417976379,
            "relevance": 1
          },
          {
            "score": 0.8400040864944458,
            "relevance": 2
          },
          {
            "score": 0.8398102521896362,
            "relevance": 3
          },
          {
            "score": 0.8378170132637024,
            "relevance": 4
          },
          {
            "score": 0.8376782536506653,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39716310843255515
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8880963325500488,
            "relevance": 5
          },
          {
            "score": 0.8473789691925049,
            "relevance": 4
          },
          {
            "score": 0.8227185010910034,
            "relevance": 5
          },
          {
            "score": 0.7801805734634399,
            "relevance": 2
          },
          {
            "score": 0.7741794586181641,
            "relevance": 3
          },
          {
            "score": 0.759703516960144,
            "relevance": 2
          },
          {
            "score": 0.7588809728622437,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    },
    "thresh_0.130_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8414292931556702,
            "relevance": 2
          },
          {
            "score": 0.8414196372032166,
            "relevance": 5
          },
          {
            "score": 0.8406470417976379,
            "relevance": 1
          },
          {
            "score": 0.8400040864944458,
            "relevance": 2
          },
          {
            "score": 0.8398102521896362,
            "relevance": 3
          },
          {
            "score": 0.8378170132637024,
            "relevance": 4
          },
          {
            "score": 0.8376782536506653,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.39716310843255515
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9577951431274414,
            "relevance": 5
          },
          {
            "score": 0.9219598770141602,
            "relevance": 4
          },
          {
            "score": 0.8998860120773315,
            "relevance": 5
          },
          {
            "score": 0.8633650541305542,
            "relevance": 2
          },
          {
            "score": 0.8564010858535767,
            "relevance": 3
          },
          {
            "score": 0.8430936336517334,
            "relevance": 2
          },
          {
            "score": 0.8421714305877686,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9639180408426472
        }
      }
    }
  },
  "P03": {
    "thresh_0.090_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8297368288040161,
            "relevance": 2
          },
          {
            "score": 0.8292454481124878,
            "relevance": 1
          },
          {
            "score": 0.8282003998756409,
            "relevance": 5
          },
          {
            "score": 0.8281798362731934,
            "relevance": 2
          },
          {
            "score": 0.8280079364776611,
            "relevance": 5
          },
          {
            "score": 0.8279011845588684,
            "relevance": 4
          },
          {
            "score": 0.8269984722137451,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3295094350125189
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5560411810874939,
            "relevance": 3
          },
          {
            "score": 0.5526233911514282,
            "relevance": 2
          },
          {
            "score": 0.5364322662353516,
            "relevance": 5
          },
          {
            "score": 0.5339788198471069,
            "relevance": 1
          },
          {
            "score": 0.505598783493042,
            "relevance": 5
          },
          {
            "score": 0.49924013018608093,
            "relevance": 4
          },
          {
            "score": 0.4940688908100128,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.090_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8297368288040161,
            "relevance": 2
          },
          {
            "score": 0.8292454481124878,
            "relevance": 1
          },
          {
            "score": 0.8282003998756409,
            "relevance": 5
          },
          {
            "score": 0.8281798362731934,
            "relevance": 2
          },
          {
            "score": 0.8280079364776611,
            "relevance": 5
          },
          {
            "score": 0.8279011845588684,
            "relevance": 4
          },
          {
            "score": 0.8269984722137451,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3295094350125189
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7301545143127441,
            "relevance": 3
          },
          {
            "score": 0.7231134176254272,
            "relevance": 2
          },
          {
            "score": 0.7002130746841431,
            "relevance": 5
          },
          {
            "score": 0.6970421075820923,
            "relevance": 1
          },
          {
            "score": 0.6434167623519897,
            "relevance": 5
          },
          {
            "score": 0.6346437931060791,
            "relevance": 4
          },
          {
            "score": 0.6179888248443604,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.090_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8297368288040161,
            "relevance": 2
          },
          {
            "score": 0.8292454481124878,
            "relevance": 1
          },
          {
            "score": 0.8282003998756409,
            "relevance": 5
          },
          {
            "score": 0.8281798362731934,
            "relevance": 2
          },
          {
            "score": 0.8280079364776611,
            "relevance": 5
          },
          {
            "score": 0.8279011845588684,
            "relevance": 4
          },
          {
            "score": 0.8269984722137451,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3295094350125189
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8113794326782227,
            "relevance": 3
          },
          {
            "score": 0.8038550615310669,
            "relevance": 2
          },
          {
            "score": 0.7797622680664062,
            "relevance": 5
          },
          {
            "score": 0.7764430046081543,
            "relevance": 1
          },
          {
            "score": 0.7155842781066895,
            "relevance": 5
          },
          {
            "score": 0.7059478759765625,
            "relevance": 4
          },
          {
            "score": 0.684857964515686,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.090_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8297368288040161,
            "relevance": 2
          },
          {
            "score": 0.8292454481124878,
            "relevance": 1
          },
          {
            "score": 0.8282003998756409,
            "relevance": 5
          },
          {
            "score": 0.8281798362731934,
            "relevance": 2
          },
          {
            "score": 0.8280079364776611,
            "relevance": 5
          },
          {
            "score": 0.8279011845588684,
            "relevance": 4
          },
          {
            "score": 0.8269984722137451,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3295094350125189
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.892913818359375,
            "relevance": 3
          },
          {
            "score": 0.8861724138259888,
            "relevance": 2
          },
          {
            "score": 0.8630337715148926,
            "relevance": 5
          },
          {
            "score": 0.8597811460494995,
            "relevance": 1
          },
          {
            "score": 0.7975424528121948,
            "relevance": 5
          },
          {
            "score": 0.787436842918396,
            "relevance": 4
          },
          {
            "score": 0.7634153366088867,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.100_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8297368288040161,
            "relevance": 2
          },
          {
            "score": 0.8292454481124878,
            "relevance": 1
          },
          {
            "score": 0.8282003998756409,
            "relevance": 5
          },
          {
            "score": 0.8281798362731934,
            "relevance": 2
          },
          {
            "score": 0.8280079364776611,
            "relevance": 5
          },
          {
            "score": 0.8279011845588684,
            "relevance": 4
          },
          {
            "score": 0.8269984722137451,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3295094350125189
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5569852590560913,
            "relevance": 3
          },
          {
            "score": 0.5534447431564331,
            "relevance": 2
          },
          {
            "score": 0.5371590852737427,
            "relevance": 5
          },
          {
            "score": 0.5347045660018921,
            "relevance": 1
          },
          {
            "score": 0.5058203935623169,
            "relevance": 5
          },
          {
            "score": 0.49946504831314087,
            "relevance": 4
          },
          {
            "score": 0.4940531849861145,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.100_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8297368288040161,
            "relevance": 2
          },
          {
            "score": 0.8292454481124878,
            "relevance": 1
          },
          {
            "score": 0.8282003998756409,
            "relevance": 5
          },
          {
            "score": 0.8281798362731934,
            "relevance": 2
          },
          {
            "score": 0.8280079364776611,
            "relevance": 5
          },
          {
            "score": 0.8279011845588684,
            "relevance": 4
          },
          {
            "score": 0.8269984722137451,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3295094350125189
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7219207286834717,
            "relevance": 3
          },
          {
            "score": 0.7143063545227051,
            "relevance": 2
          },
          {
            "score": 0.6905364990234375,
            "relevance": 5
          },
          {
            "score": 0.6872857809066772,
            "relevance": 1
          },
          {
            "score": 0.630792498588562,
            "relevance": 5
          },
          {
            "score": 0.6218322515487671,
            "relevance": 4
          },
          {
            "score": 0.6040995717048645,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.100_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8297368288040161,
            "relevance": 2
          },
          {
            "score": 0.8292454481124878,
            "relevance": 1
          },
          {
            "score": 0.8282003998756409,
            "relevance": 5
          },
          {
            "score": 0.8281798362731934,
            "relevance": 2
          },
          {
            "score": 0.8280079364776611,
            "relevance": 5
          },
          {
            "score": 0.8279011845588684,
            "relevance": 4
          },
          {
            "score": 0.8269984722137451,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3295094350125189
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8017005920410156,
            "relevance": 3
          },
          {
            "score": 0.793229341506958,
            "relevance": 2
          },
          {
            "score": 0.7675933837890625,
            "relevance": 5
          },
          {
            "score": 0.764123797416687,
            "relevance": 1
          },
          {
            "score": 0.6980891227722168,
            "relevance": 5
          },
          {
            "score": 0.6880631446838379,
            "relevance": 4
          },
          {
            "score": 0.6649791598320007,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.100_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8297368288040161,
            "relevance": 2
          },
          {
            "score": 0.8292454481124878,
            "relevance": 1
          },
          {
            "score": 0.8282003998756409,
            "relevance": 5
          },
          {
            "score": 0.8281798362731934,
            "relevance": 2
          },
          {
            "score": 0.8280079364776611,
            "relevance": 5
          },
          {
            "score": 0.8279011845588684,
            "relevance": 4
          },
          {
            "score": 0.8269984722137451,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3295094350125189
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8848509788513184,
            "relevance": 3
          },
          {
            "score": 0.8767311573028564,
            "relevance": 2
          },
          {
            "score": 0.8512182235717773,
            "relevance": 5
          },
          {
            "score": 0.8477240800857544,
            "relevance": 1
          },
          {
            "score": 0.7769613265991211,
            "relevance": 5
          },
          {
            "score": 0.7661396265029907,
            "relevance": 4
          },
          {
            "score": 0.7385823130607605,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.110_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8297368288040161,
            "relevance": 2
          },
          {
            "score": 0.8292454481124878,
            "relevance": 1
          },
          {
            "score": 0.8282003998756409,
            "relevance": 5
          },
          {
            "score": 0.8281798362731934,
            "relevance": 2
          },
          {
            "score": 0.8280079364776611,
            "relevance": 5
          },
          {
            "score": 0.8279011845588684,
            "relevance": 4
          },
          {
            "score": 0.8269984722137451,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3295094350125189
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5574917793273926,
            "relevance": 3
          },
          {
            "score": 0.5538294315338135,
            "relevance": 2
          },
          {
            "score": 0.5374722480773926,
            "relevance": 5
          },
          {
            "score": 0.5350204110145569,
            "relevance": 1
          },
          {
            "score": 0.5056586861610413,
            "relevance": 5
          },
          {
            "score": 0.4993175268173218,
            "relevance": 4
          },
          {
            "score": 0.4936639964580536,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.110_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8297368288040161,
            "relevance": 2
          },
          {
            "score": 0.8292454481124878,
            "relevance": 1
          },
          {
            "score": 0.8282003998756409,
            "relevance": 5
          },
          {
            "score": 0.8281798362731934,
            "relevance": 2
          },
          {
            "score": 0.8280079364776611,
            "relevance": 5
          },
          {
            "score": 0.8279011845588684,
            "relevance": 4
          },
          {
            "score": 0.8269984722137451,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3295094350125189
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7121523022651672,
            "relevance": 3
          },
          {
            "score": 0.7039721012115479,
            "relevance": 2
          },
          {
            "score": 0.6793731451034546,
            "relevance": 5
          },
          {
            "score": 0.676048755645752,
            "relevance": 1
          },
          {
            "score": 0.6168293356895447,
            "relevance": 5
          },
          {
            "score": 0.6077061891555786,
            "relevance": 4
          },
          {
            "score": 0.588965892791748,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.110_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8297368288040161,
            "relevance": 2
          },
          {
            "score": 0.8292454481124878,
            "relevance": 1
          },
          {
            "score": 0.8282003998756409,
            "relevance": 5
          },
          {
            "score": 0.8281798362731934,
            "relevance": 2
          },
          {
            "score": 0.8280079364776611,
            "relevance": 5
          },
          {
            "score": 0.8279011845588684,
            "relevance": 4
          },
          {
            "score": 0.8269984722137451,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3295094350125189
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7895541787147522,
            "relevance": 3
          },
          {
            "score": 0.7801171541213989,
            "relevance": 2
          },
          {
            "score": 0.7529410123825073,
            "relevance": 5
          },
          {
            "score": 0.749323844909668,
            "relevance": 1
          },
          {
            "score": 0.6782171130180359,
            "relevance": 5
          },
          {
            "score": 0.6678295135498047,
            "relevance": 4
          },
          {
            "score": 0.642853856086731,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.110_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8297368288040161,
            "relevance": 2
          },
          {
            "score": 0.8292454481124878,
            "relevance": 1
          },
          {
            "score": 0.8282003998756409,
            "relevance": 5
          },
          {
            "score": 0.8281798362731934,
            "relevance": 2
          },
          {
            "score": 0.8280079364776611,
            "relevance": 5
          },
          {
            "score": 0.8279011845588684,
            "relevance": 4
          },
          {
            "score": 0.8269984722137451,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3295094350125189
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8732035756111145,
            "relevance": 3
          },
          {
            "score": 0.8635997772216797,
            "relevance": 2
          },
          {
            "score": 0.8355692625045776,
            "relevance": 5
          },
          {
            "score": 0.8318221569061279,
            "relevance": 1
          },
          {
            "score": 0.7522749304771423,
            "relevance": 5
          },
          {
            "score": 0.7407459020614624,
            "relevance": 4
          },
          {
            "score": 0.7096993923187256,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.120_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8297368288040161,
            "relevance": 2
          },
          {
            "score": 0.8292454481124878,
            "relevance": 1
          },
          {
            "score": 0.8282003998756409,
            "relevance": 5
          },
          {
            "score": 0.8281798362731934,
            "relevance": 2
          },
          {
            "score": 0.8280079364776611,
            "relevance": 5
          },
          {
            "score": 0.8279011845588684,
            "relevance": 4
          },
          {
            "score": 0.8269984722137451,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3295094350125189
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5575406551361084,
            "relevance": 3
          },
          {
            "score": 0.5537582635879517,
            "relevance": 2
          },
          {
            "score": 0.5373520851135254,
            "relevance": 5
          },
          {
            "score": 0.5349071621894836,
            "relevance": 1
          },
          {
            "score": 0.5050972700119019,
            "relevance": 5
          },
          {
            "score": 0.4987802505493164,
            "relevance": 4
          },
          {
            "score": 0.4928857684135437,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.120_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8297368288040161,
            "relevance": 2
          },
          {
            "score": 0.8292454481124878,
            "relevance": 1
          },
          {
            "score": 0.8282003998756409,
            "relevance": 5
          },
          {
            "score": 0.8281798362731934,
            "relevance": 2
          },
          {
            "score": 0.8280079364776611,
            "relevance": 5
          },
          {
            "score": 0.8279011845588684,
            "relevance": 4
          },
          {
            "score": 0.8269984722137451,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3295094350125189
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7008496522903442,
            "relevance": 3
          },
          {
            "score": 0.692118227481842,
            "relevance": 2
          },
          {
            "score": 0.6667424440383911,
            "relevance": 5
          },
          {
            "score": 0.6633519530296326,
            "relevance": 1
          },
          {
            "score": 0.6015887260437012,
            "relevance": 5
          },
          {
            "score": 0.5923299789428711,
            "relevance": 4
          },
          {
            "score": 0.5726686120033264,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.120_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8297368288040161,
            "relevance": 2
          },
          {
            "score": 0.8292454481124878,
            "relevance": 1
          },
          {
            "score": 0.8282003998756409,
            "relevance": 5
          },
          {
            "score": 0.8281798362731934,
            "relevance": 2
          },
          {
            "score": 0.8280079364776611,
            "relevance": 5
          },
          {
            "score": 0.8279011845588684,
            "relevance": 4
          },
          {
            "score": 0.8269984722137451,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3295094350125189
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7748821973800659,
            "relevance": 3
          },
          {
            "score": 0.7644760012626648,
            "relevance": 2
          },
          {
            "score": 0.7357889413833618,
            "relevance": 5
          },
          {
            "score": 0.7320300936698914,
            "relevance": 1
          },
          {
            "score": 0.6560616493225098,
            "relevance": 5
          },
          {
            "score": 0.6453498005867004,
            "relevance": 4
          },
          {
            "score": 0.6186304688453674,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.120_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8297368288040161,
            "relevance": 2
          },
          {
            "score": 0.8292454481124878,
            "relevance": 1
          },
          {
            "score": 0.8282003998756409,
            "relevance": 5
          },
          {
            "score": 0.8281798362731934,
            "relevance": 2
          },
          {
            "score": 0.8280079364776611,
            "relevance": 5
          },
          {
            "score": 0.8279011845588684,
            "relevance": 4
          },
          {
            "score": 0.8269984722137451,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3295094350125189
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8577045202255249,
            "relevance": 3
          },
          {
            "score": 0.8465322852134705,
            "relevance": 2
          },
          {
            "score": 0.8158832788467407,
            "relevance": 5
          },
          {
            "score": 0.8118765950202942,
            "relevance": 1
          },
          {
            "score": 0.7235043048858643,
            "relevance": 5
          },
          {
            "score": 0.7112997174263,
            "relevance": 4
          },
          {
            "score": 0.6769295334815979,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.130_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8297368288040161,
            "relevance": 2
          },
          {
            "score": 0.8292454481124878,
            "relevance": 1
          },
          {
            "score": 0.8282003998756409,
            "relevance": 5
          },
          {
            "score": 0.8281798362731934,
            "relevance": 2
          },
          {
            "score": 0.8280079364776611,
            "relevance": 5
          },
          {
            "score": 0.8279011845588684,
            "relevance": 4
          },
          {
            "score": 0.8269984722137451,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3295094350125189
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5571151971817017,
            "relevance": 3
          },
          {
            "score": 0.5532147884368896,
            "relevance": 2
          },
          {
            "score": 0.5367828011512756,
            "relevance": 5
          },
          {
            "score": 0.5343483686447144,
            "relevance": 1
          },
          {
            "score": 0.5041219592094421,
            "relevance": 5
          },
          {
            "score": 0.4978390634059906,
            "relevance": 4
          },
          {
            "score": 0.49170607328414917,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.130_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8297368288040161,
            "relevance": 2
          },
          {
            "score": 0.8292454481124878,
            "relevance": 1
          },
          {
            "score": 0.8282003998756409,
            "relevance": 5
          },
          {
            "score": 0.8281798362731934,
            "relevance": 2
          },
          {
            "score": 0.8280079364776611,
            "relevance": 5
          },
          {
            "score": 0.8279011845588684,
            "relevance": 4
          },
          {
            "score": 0.8269984722137451,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3295094350125189
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.688032865524292,
            "relevance": 3
          },
          {
            "score": 0.6787725687026978,
            "relevance": 2
          },
          {
            "score": 0.652684211730957,
            "relevance": 5
          },
          {
            "score": 0.6492358446121216,
            "relevance": 1
          },
          {
            "score": 0.5851515531539917,
            "relevance": 5
          },
          {
            "score": 0.5757871866226196,
            "relevance": 4
          },
          {
            "score": 0.5553063750267029,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.130_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8297368288040161,
            "relevance": 2
          },
          {
            "score": 0.8292454481124878,
            "relevance": 1
          },
          {
            "score": 0.8282003998756409,
            "relevance": 5
          },
          {
            "score": 0.8281798362731934,
            "relevance": 2
          },
          {
            "score": 0.8280079364776611,
            "relevance": 5
          },
          {
            "score": 0.8279011845588684,
            "relevance": 4
          },
          {
            "score": 0.8269984722137451,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3295094350125189
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7576667070388794,
            "relevance": 3
          },
          {
            "score": 0.7463052272796631,
            "relevance": 2
          },
          {
            "score": 0.7161680459976196,
            "relevance": 5
          },
          {
            "score": 0.7122764587402344,
            "relevance": 1
          },
          {
            "score": 0.6317688226699829,
            "relevance": 5
          },
          {
            "score": 0.620779275894165,
            "relevance": 4
          },
          {
            "score": 0.5925098061561584,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    },
    "thresh_0.130_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8297368288040161,
            "relevance": 2
          },
          {
            "score": 0.8292454481124878,
            "relevance": 1
          },
          {
            "score": 0.8282003998756409,
            "relevance": 5
          },
          {
            "score": 0.8281798362731934,
            "relevance": 2
          },
          {
            "score": 0.8280079364776611,
            "relevance": 5
          },
          {
            "score": 0.8279011845588684,
            "relevance": 4
          },
          {
            "score": 0.8269984722137451,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.3295094350125189
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8381451368331909,
            "relevance": 3
          },
          {
            "score": 0.8253487348556519,
            "relevance": 2
          },
          {
            "score": 0.7920392751693726,
            "relevance": 5
          },
          {
            "score": 0.7877727746963501,
            "relevance": 1
          },
          {
            "score": 0.6908031105995178,
            "relevance": 5
          },
          {
            "score": 0.6779816150665283,
            "relevance": 4
          },
          {
            "score": 0.6405827403068542,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.42013923584539437
        }
      }
    }
  },
  "P04": {
    "thresh_0.090_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.810653030872345,
            "relevance": 2
          },
          {
            "score": 0.8093363046646118,
            "relevance": 4
          },
          {
            "score": 0.8090739846229553,
            "relevance": 5
          },
          {
            "score": 0.8088799715042114,
            "relevance": 1
          },
          {
            "score": 0.8086850047111511,
            "relevance": 3
          },
          {
            "score": 0.8080177307128906,
            "relevance": 2
          },
          {
            "score": 0.8078182339668274,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.4816485275886914
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6602381467819214,
            "relevance": 4
          },
          {
            "score": 0.6541407108306885,
            "relevance": 1
          },
          {
            "score": 0.6398341059684753,
            "relevance": 5
          },
          {
            "score": 0.6190446019172668,
            "relevance": 2
          },
          {
            "score": 0.6161242723464966,
            "relevance": 3
          },
          {
            "score": 0.6117258667945862,
            "relevance": 2
          },
          {
            "score": 0.5935951471328735,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5361963692642142
        }
      }
    },
    "thresh_0.090_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.810653030872345,
            "relevance": 2
          },
          {
            "score": 0.8093363046646118,
            "relevance": 4
          },
          {
            "score": 0.8090739846229553,
            "relevance": 5
          },
          {
            "score": 0.8088799715042114,
            "relevance": 1
          },
          {
            "score": 0.8086850047111511,
            "relevance": 3
          },
          {
            "score": 0.8080177307128906,
            "relevance": 2
          },
          {
            "score": 0.8078182339668274,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.4816485275886914
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8587322235107422,
            "relevance": 4
          },
          {
            "score": 0.8539144992828369,
            "relevance": 1
          },
          {
            "score": 0.8426305651664734,
            "relevance": 5
          },
          {
            "score": 0.8269874453544617,
            "relevance": 2
          },
          {
            "score": 0.823167085647583,
            "relevance": 3
          },
          {
            "score": 0.8208158612251282,
            "relevance": 2
          },
          {
            "score": 0.8032926321029663,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5361963692642142
        }
      }
    },
    "thresh_0.090_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.810653030872345,
            "relevance": 2
          },
          {
            "score": 0.8093363046646118,
            "relevance": 4
          },
          {
            "score": 0.8090739846229553,
            "relevance": 5
          },
          {
            "score": 0.8088799715042114,
            "relevance": 1
          },
          {
            "score": 0.8086850047111511,
            "relevance": 3
          },
          {
            "score": 0.8080177307128906,
            "relevance": 2
          },
          {
            "score": 0.8078182339668274,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.4816485275886914
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9047712087631226,
            "relevance": 4
          },
          {
            "score": 0.9011610746383667,
            "relevance": 1
          },
          {
            "score": 0.8930501341819763,
            "relevance": 5
          },
          {
            "score": 0.8848353028297424,
            "relevance": 2
          },
          {
            "score": 0.8812945485115051,
            "relevance": 2
          },
          {
            "score": 0.8793735504150391,
            "relevance": 3
          },
          {
            "score": 0.8657388687133789,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5361963692642142
        }
      }
    },
    "thresh_0.090_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.810653030872345,
            "relevance": 2
          },
          {
            "score": 0.8093363046646118,
            "relevance": 4
          },
          {
            "score": 0.8090739846229553,
            "relevance": 5
          },
          {
            "score": 0.8088799715042114,
            "relevance": 1
          },
          {
            "score": 0.8086850047111511,
            "relevance": 3
          },
          {
            "score": 0.8080177307128906,
            "relevance": 2
          },
          {
            "score": 0.8078182339668274,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.4816485275886914
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9300493001937866,
            "relevance": 4
          },
          {
            "score": 0.9274882078170776,
            "relevance": 1
          },
          {
            "score": 0.9222415089607239,
            "relevance": 5
          },
          {
            "score": 0.9214120507240295,
            "relevance": 2
          },
          {
            "score": 0.9207510352134705,
            "relevance": 2
          },
          {
            "score": 0.9142287969589233,
            "relevance": 3
          },
          {
            "score": 0.9074549674987793,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5361963692642142
        }
      }
    },
    "thresh_0.100_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.810653030872345,
            "relevance": 2
          },
          {
            "score": 0.8093363046646118,
            "relevance": 4
          },
          {
            "score": 0.8090739846229553,
            "relevance": 5
          },
          {
            "score": 0.8088799715042114,
            "relevance": 1
          },
          {
            "score": 0.8086850047111511,
            "relevance": 3
          },
          {
            "score": 0.8080177307128906,
            "relevance": 2
          },
          {
            "score": 0.8078182339668274,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.4816485275886914
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6662840843200684,
            "relevance": 4
          },
          {
            "score": 0.6600548624992371,
            "relevance": 1
          },
          {
            "score": 0.6454081535339355,
            "relevance": 5
          },
          {
            "score": 0.6238611936569214,
            "relevance": 2
          },
          {
            "score": 0.6210978627204895,
            "relevance": 3
          },
          {
            "score": 0.616278886795044,
            "relevance": 2
          },
          {
            "score": 0.5979416966438293,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5361963692642142
        }
      }
    },
    "thresh_0.100_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.810653030872345,
            "relevance": 2
          },
          {
            "score": 0.8093363046646118,
            "relevance": 4
          },
          {
            "score": 0.8090739846229553,
            "relevance": 5
          },
          {
            "score": 0.8088799715042114,
            "relevance": 1
          },
          {
            "score": 0.8086850047111511,
            "relevance": 3
          },
          {
            "score": 0.8080177307128906,
            "relevance": 2
          },
          {
            "score": 0.8078182339668274,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.4816485275886914
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8679502010345459,
            "relevance": 4
          },
          {
            "score": 0.862846314907074,
            "relevance": 1
          },
          {
            "score": 0.8507862091064453,
            "relevance": 5
          },
          {
            "score": 0.8331834077835083,
            "relevance": 2
          },
          {
            "score": 0.8298093676567078,
            "relevance": 3
          },
          {
            "score": 0.8262538909912109,
            "relevance": 2
          },
          {
            "score": 0.8081261515617371,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5361963692642142
        }
      }
    },
    "thresh_0.100_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.810653030872345,
            "relevance": 2
          },
          {
            "score": 0.8093363046646118,
            "relevance": 4
          },
          {
            "score": 0.8090739846229553,
            "relevance": 5
          },
          {
            "score": 0.8088799715042114,
            "relevance": 1
          },
          {
            "score": 0.8086850047111511,
            "relevance": 3
          },
          {
            "score": 0.8080177307128906,
            "relevance": 2
          },
          {
            "score": 0.8078182339668274,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.4816485275886914
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9171218872070312,
            "relevance": 4
          },
          {
            "score": 0.9132600426673889,
            "relevance": 1
          },
          {
            "score": 0.9044475555419922,
            "relevance": 5
          },
          {
            "score": 0.8943338394165039,
            "relevance": 2
          },
          {
            "score": 0.8900101184844971,
            "relevance": 2
          },
          {
            "score": 0.8893206715583801,
            "relevance": 3
          },
          {
            "score": 0.8738119006156921,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5361963692642142
        }
      }
    },
    "thresh_0.100_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.810653030872345,
            "relevance": 2
          },
          {
            "score": 0.8093363046646118,
            "relevance": 4
          },
          {
            "score": 0.8090739846229553,
            "relevance": 5
          },
          {
            "score": 0.8088799715042114,
            "relevance": 1
          },
          {
            "score": 0.8086850047111511,
            "relevance": 3
          },
          {
            "score": 0.8080177307128906,
            "relevance": 2
          },
          {
            "score": 0.8078182339668274,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.4816485275886914
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9451674222946167,
            "relevance": 4
          },
          {
            "score": 0.9424461722373962,
            "relevance": 1
          },
          {
            "score": 0.9367374181747437,
            "relevance": 5
          },
          {
            "score": 0.9345507621765137,
            "relevance": 2
          },
          {
            "score": 0.9332857131958008,
            "relevance": 2
          },
          {
            "score": 0.9277001023292542,
            "relevance": 3
          },
          {
            "score": 0.9194733500480652,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5361963692642142
        }
      }
    },
    "thresh_0.110_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.810653030872345,
            "relevance": 2
          },
          {
            "score": 0.8093363046646118,
            "relevance": 4
          },
          {
            "score": 0.8090739846229553,
            "relevance": 5
          },
          {
            "score": 0.8088799715042114,
            "relevance": 1
          },
          {
            "score": 0.8086850047111511,
            "relevance": 3
          },
          {
            "score": 0.8080177307128906,
            "relevance": 2
          },
          {
            "score": 0.8078182339668274,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.4816485275886914
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6719772815704346,
            "relevance": 4
          },
          {
            "score": 0.6656211614608765,
            "relevance": 1
          },
          {
            "score": 0.6506433486938477,
            "relevance": 5
          },
          {
            "score": 0.6283330917358398,
            "relevance": 2
          },
          {
            "score": 0.6257455348968506,
            "relevance": 3
          },
          {
            "score": 0.6204860210418701,
            "relevance": 2
          },
          {
            "score": 0.6019701957702637,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5361963692642142
        }
      }
    },
    "thresh_0.110_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.810653030872345,
            "relevance": 2
          },
          {
            "score": 0.8093363046646118,
            "relevance": 4
          },
          {
            "score": 0.8090739846229553,
            "relevance": 5
          },
          {
            "score": 0.8088799715042114,
            "relevance": 1
          },
          {
            "score": 0.8086850047111511,
            "relevance": 3
          },
          {
            "score": 0.8080177307128906,
            "relevance": 2
          },
          {
            "score": 0.8078182339668274,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.4816485275886914
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8764017820358276,
            "relevance": 4
          },
          {
            "score": 0.8709949254989624,
            "relevance": 1
          },
          {
            "score": 0.8581115007400513,
            "relevance": 5
          },
          {
            "score": 0.8384072780609131,
            "relevance": 2
          },
          {
            "score": 0.8355284929275513,
            "relevance": 3
          },
          {
            "score": 0.830668568611145,
            "relevance": 2
          },
          {
            "score": 0.8119275569915771,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5361963692642142
        }
      }
    },
    "thresh_0.110_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.810653030872345,
            "relevance": 2
          },
          {
            "score": 0.8093363046646118,
            "relevance": 4
          },
          {
            "score": 0.8090739846229553,
            "relevance": 5
          },
          {
            "score": 0.8088799715042114,
            "relevance": 1
          },
          {
            "score": 0.8086850047111511,
            "relevance": 3
          },
          {
            "score": 0.8080177307128906,
            "relevance": 2
          },
          {
            "score": 0.8078182339668274,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.4816485275886914
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9287889003753662,
            "relevance": 4
          },
          {
            "score": 0.9246504306793213,
            "relevance": 1
          },
          {
            "score": 0.915062427520752,
            "relevance": 5
          },
          {
            "score": 0.9028241634368896,
            "relevance": 2
          },
          {
            "score": 0.8983297348022461,
            "relevance": 3
          },
          {
            "score": 0.8976284265518188,
            "relevance": 2
          },
          {
            "score": 0.8807467222213745,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5361963692642142
        }
      }
    },
    "thresh_0.110_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.810653030872345,
            "relevance": 2
          },
          {
            "score": 0.8093363046646118,
            "relevance": 4
          },
          {
            "score": 0.8090739846229553,
            "relevance": 5
          },
          {
            "score": 0.8088799715042114,
            "relevance": 1
          },
          {
            "score": 0.8086850047111511,
            "relevance": 3
          },
          {
            "score": 0.8080177307128906,
            "relevance": 2
          },
          {
            "score": 0.8078182339668274,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.4816485275886914
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9598389863967896,
            "relevance": 4
          },
          {
            "score": 0.9569344520568848,
            "relevance": 1
          },
          {
            "score": 0.9506916999816895,
            "relevance": 5
          },
          {
            "score": 0.9469043016433716,
            "relevance": 2
          },
          {
            "score": 0.9449290037155151,
            "relevance": 2
          },
          {
            "score": 0.940463662147522,
            "relevance": 3
          },
          {
            "score": 0.9305421113967896,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5361963692642142
        }
      }
    },
    "thresh_0.120_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.810653030872345,
            "relevance": 2
          },
          {
            "score": 0.8093363046646118,
            "relevance": 4
          },
          {
            "score": 0.8090739846229553,
            "relevance": 5
          },
          {
            "score": 0.8088799715042114,
            "relevance": 1
          },
          {
            "score": 0.8086850047111511,
            "relevance": 3
          },
          {
            "score": 0.8080177307128906,
            "relevance": 2
          },
          {
            "score": 0.8078182339668274,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.4816485275886914
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6772751808166504,
            "relevance": 4
          },
          {
            "score": 0.6707969307899475,
            "relevance": 1
          },
          {
            "score": 0.6554983854293823,
            "relevance": 5
          },
          {
            "score": 0.6324217319488525,
            "relevance": 2
          },
          {
            "score": 0.6300276517868042,
            "relevance": 3
          },
          {
            "score": 0.6243089437484741,
            "relevance": 2
          },
          {
            "score": 0.6056432723999023,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5361963692642142
        }
      }
    },
    "thresh_0.120_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.810653030872345,
            "relevance": 2
          },
          {
            "score": 0.8093363046646118,
            "relevance": 4
          },
          {
            "score": 0.8090739846229553,
            "relevance": 5
          },
          {
            "score": 0.8088799715042114,
            "relevance": 1
          },
          {
            "score": 0.8086850047111511,
            "relevance": 3
          },
          {
            "score": 0.8080177307128906,
            "relevance": 2
          },
          {
            "score": 0.8078182339668274,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.4816485275886914
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8839887380599976,
            "relevance": 4
          },
          {
            "score": 0.8782617449760437,
            "relevance": 1
          },
          {
            "score": 0.8645058870315552,
            "relevance": 5
          },
          {
            "score": 0.8425579071044922,
            "relevance": 2
          },
          {
            "score": 0.8402231931686401,
            "relevance": 3
          },
          {
            "score": 0.8339602947235107,
            "relevance": 2
          },
          {
            "score": 0.8145977258682251,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5361963692642142
        }
      }
    },
    "thresh_0.120_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.810653030872345,
            "relevance": 2
          },
          {
            "score": 0.8093363046646118,
            "relevance": 4
          },
          {
            "score": 0.8090739846229553,
            "relevance": 5
          },
          {
            "score": 0.8088799715042114,
            "relevance": 1
          },
          {
            "score": 0.8086850047111511,
            "relevance": 3
          },
          {
            "score": 0.8080177307128906,
            "relevance": 2
          },
          {
            "score": 0.8078182339668274,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.4816485275886914
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9396500587463379,
            "relevance": 4
          },
          {
            "score": 0.9352067112922668,
            "relevance": 1
          },
          {
            "score": 0.9247616529464722,
            "relevance": 5
          },
          {
            "score": 0.9101569652557373,
            "relevance": 2
          },
          {
            "score": 0.9062550067901611,
            "relevance": 3
          },
          {
            "score": 0.9039945602416992,
            "relevance": 2
          },
          {
            "score": 0.8863843679428101,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5361963692642142
        }
      }
    },
    "thresh_0.120_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.810653030872345,
            "relevance": 2
          },
          {
            "score": 0.8093363046646118,
            "relevance": 4
          },
          {
            "score": 0.8090739846229553,
            "relevance": 5
          },
          {
            "score": 0.8088799715042114,
            "relevance": 1
          },
          {
            "score": 0.8086850047111511,
            "relevance": 3
          },
          {
            "score": 0.8080177307128906,
            "relevance": 2
          },
          {
            "score": 0.8078182339668274,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.4816485275886914
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9739454984664917,
            "relevance": 4
          },
          {
            "score": 0.9708297848701477,
            "relevance": 1
          },
          {
            "score": 0.9639681577682495,
            "relevance": 5
          },
          {
            "score": 0.9583004713058472,
            "relevance": 2
          },
          {
            "score": 0.9554945230484009,
            "relevance": 2
          },
          {
            "score": 0.9523563385009766,
            "relevance": 3
          },
          {
            "score": 0.9404627084732056,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5361963692642142
        }
      }
    },
    "thresh_0.130_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.810653030872345,
            "relevance": 2
          },
          {
            "score": 0.8093363046646118,
            "relevance": 4
          },
          {
            "score": 0.8090739846229553,
            "relevance": 5
          },
          {
            "score": 0.8088799715042114,
            "relevance": 1
          },
          {
            "score": 0.8086850047111511,
            "relevance": 3
          },
          {
            "score": 0.8080177307128906,
            "relevance": 2
          },
          {
            "score": 0.8078182339668274,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.4816485275886914
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6821367740631104,
            "relevance": 4
          },
          {
            "score": 0.6755420565605164,
            "relevance": 1
          },
          {
            "score": 0.6599335670471191,
            "relevance": 5
          },
          {
            "score": 0.6360896825790405,
            "relevance": 2
          },
          {
            "score": 0.6339060068130493,
            "relevance": 3
          },
          {
            "score": 0.6277115345001221,
            "relevance": 2
          },
          {
            "score": 0.6089246273040771,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5361963692642142
        }
      }
    },
    "thresh_0.130_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.810653030872345,
            "relevance": 2
          },
          {
            "score": 0.8093363046646118,
            "relevance": 4
          },
          {
            "score": 0.8090739846229553,
            "relevance": 5
          },
          {
            "score": 0.8088799715042114,
            "relevance": 1
          },
          {
            "score": 0.8086850047111511,
            "relevance": 3
          },
          {
            "score": 0.8080177307128906,
            "relevance": 2
          },
          {
            "score": 0.8078182339668274,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.4816485275886914
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.890612006187439,
            "relevance": 4
          },
          {
            "score": 0.8845472931861877,
            "relevance": 1
          },
          {
            "score": 0.8698693513870239,
            "relevance": 5
          },
          {
            "score": 0.845536470413208,
            "relevance": 2
          },
          {
            "score": 0.8437932729721069,
            "relevance": 3
          },
          {
            "score": 0.8360313177108765,
            "relevance": 2
          },
          {
            "score": 0.8160402774810791,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5361963692642142
        }
      }
    },
    "thresh_0.130_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.810653030872345,
            "relevance": 2
          },
          {
            "score": 0.8093363046646118,
            "relevance": 4
          },
          {
            "score": 0.8090739846229553,
            "relevance": 5
          },
          {
            "score": 0.8088799715042114,
            "relevance": 1
          },
          {
            "score": 0.8086850047111511,
            "relevance": 3
          },
          {
            "score": 0.8080177307128906,
            "relevance": 2
          },
          {
            "score": 0.8078182339668274,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.4816485275886914
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9495766162872314,
            "relevance": 4
          },
          {
            "score": 0.9447972178459167,
            "relevance": 1
          },
          {
            "score": 0.9334059953689575,
            "relevance": 5
          },
          {
            "score": 0.9161758422851562,
            "relevance": 2
          },
          {
            "score": 0.9129434823989868,
            "relevance": 3
          },
          {
            "score": 0.9089479446411133,
            "relevance": 2
          },
          {
            "score": 0.8905608654022217,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5361963692642142
        }
      }
    },
    "thresh_0.130_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.810653030872345,
            "relevance": 2
          },
          {
            "score": 0.8093363046646118,
            "relevance": 4
          },
          {
            "score": 0.8090739846229553,
            "relevance": 5
          },
          {
            "score": 0.8088799715042114,
            "relevance": 1
          },
          {
            "score": 0.8086850047111511,
            "relevance": 3
          },
          {
            "score": 0.8080177307128906,
            "relevance": 2
          },
          {
            "score": 0.8078182339668274,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.4816485275886914
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9873571395874023,
            "relevance": 4
          },
          {
            "score": 0.9839970469474792,
            "relevance": 1
          },
          {
            "score": 0.9764169454574585,
            "relevance": 5
          },
          {
            "score": 0.968549370765686,
            "relevance": 2
          },
          {
            "score": 0.9647761583328247,
            "relevance": 2
          },
          {
            "score": 0.9631972312927246,
            "relevance": 3
          },
          {
            "score": 0.9490164518356323,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5361963692642142
        }
      }
    }
  },
  "P05": {
    "thresh_0.090_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7974185943603516,
            "relevance": 3
          },
          {
            "score": 0.7967982888221741,
            "relevance": 5
          },
          {
            "score": 0.7961910963058472,
            "relevance": 2
          },
          {
            "score": 0.7959046363830566,
            "relevance": 5
          },
          {
            "score": 0.795473575592041,
            "relevance": 2
          },
          {
            "score": 0.7952409982681274,
            "relevance": 1
          },
          {
            "score": 0.794396162033081,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5372055768966675,
            "relevance": 2
          },
          {
            "score": 0.522294819355011,
            "relevance": 3
          },
          {
            "score": 0.5222516059875488,
            "relevance": 4
          },
          {
            "score": 0.5135642886161804,
            "relevance": 5
          },
          {
            "score": 0.5058315992355347,
            "relevance": 2
          },
          {
            "score": 0.5025504231452942,
            "relevance": 5
          },
          {
            "score": 0.49593043327331543,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.2569206137583197
        }
      }
    },
    "thresh_0.090_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7974185943603516,
            "relevance": 3
          },
          {
            "score": 0.7967982888221741,
            "relevance": 5
          },
          {
            "score": 0.7961910963058472,
            "relevance": 2
          },
          {
            "score": 0.7959046363830566,
            "relevance": 5
          },
          {
            "score": 0.795473575592041,
            "relevance": 2
          },
          {
            "score": 0.7952409982681274,
            "relevance": 1
          },
          {
            "score": 0.794396162033081,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7443462610244751,
            "relevance": 2
          },
          {
            "score": 0.7281696796417236,
            "relevance": 4
          },
          {
            "score": 0.7270539402961731,
            "relevance": 3
          },
          {
            "score": 0.7099458575248718,
            "relevance": 5
          },
          {
            "score": 0.7044543623924255,
            "relevance": 5
          },
          {
            "score": 0.7038438320159912,
            "relevance": 2
          },
          {
            "score": 0.6916799545288086,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.2749615933369961
        }
      }
    },
    "thresh_0.090_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7974185943603516,
            "relevance": 3
          },
          {
            "score": 0.7967982888221741,
            "relevance": 5
          },
          {
            "score": 0.7961910963058472,
            "relevance": 2
          },
          {
            "score": 0.7959046363830566,
            "relevance": 5
          },
          {
            "score": 0.795473575592041,
            "relevance": 2
          },
          {
            "score": 0.7952409982681274,
            "relevance": 1
          },
          {
            "score": 0.794396162033081,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8188381195068359,
            "relevance": 2
          },
          {
            "score": 0.8038985729217529,
            "relevance": 4
          },
          {
            "score": 0.8037281632423401,
            "relevance": 3
          },
          {
            "score": 0.7903892397880554,
            "relevance": 5
          },
          {
            "score": 0.7838212251663208,
            "relevance": 2
          },
          {
            "score": 0.7828723788261414,
            "relevance": 5
          },
          {
            "score": 0.7722805738449097,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.2749615933369961
        }
      }
    },
    "thresh_0.090_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7974185943603516,
            "relevance": 3
          },
          {
            "score": 0.7967982888221741,
            "relevance": 5
          },
          {
            "score": 0.7961910963058472,
            "relevance": 2
          },
          {
            "score": 0.7959046363830566,
            "relevance": 5
          },
          {
            "score": 0.795473575592041,
            "relevance": 2
          },
          {
            "score": 0.7952409982681274,
            "relevance": 1
          },
          {
            "score": 0.794396162033081,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8772450685501099,
            "relevance": 2
          },
          {
            "score": 0.8660574555397034,
            "relevance": 3
          },
          {
            "score": 0.8644695281982422,
            "relevance": 4
          },
          {
            "score": 0.8614373803138733,
            "relevance": 5
          },
          {
            "score": 0.8535257577896118,
            "relevance": 2
          },
          {
            "score": 0.8487761616706848,
            "relevance": 5
          },
          {
            "score": 0.8438177108764648,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.2569206137583197
        }
      }
    },
    "thresh_0.100_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7974185943603516,
            "relevance": 3
          },
          {
            "score": 0.7967982888221741,
            "relevance": 5
          },
          {
            "score": 0.7961910963058472,
            "relevance": 2
          },
          {
            "score": 0.7959046363830566,
            "relevance": 5
          },
          {
            "score": 0.795473575592041,
            "relevance": 2
          },
          {
            "score": 0.7952409982681274,
            "relevance": 1
          },
          {
            "score": 0.794396162033081,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5402765274047852,
            "relevance": 2
          },
          {
            "score": 0.5251506567001343,
            "relevance": 4
          },
          {
            "score": 0.5250920057296753,
            "relevance": 3
          },
          {
            "score": 0.5158071517944336,
            "relevance": 5
          },
          {
            "score": 0.5081525444984436,
            "relevance": 2
          },
          {
            "score": 0.5050808191299438,
            "relevance": 5
          },
          {
            "score": 0.49812018871307373,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.2749615933369961
        }
      }
    },
    "thresh_0.100_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7974185943603516,
            "relevance": 3
          },
          {
            "score": 0.7967982888221741,
            "relevance": 5
          },
          {
            "score": 0.7961910963058472,
            "relevance": 2
          },
          {
            "score": 0.7959046363830566,
            "relevance": 5
          },
          {
            "score": 0.795473575592041,
            "relevance": 2
          },
          {
            "score": 0.7952409982681274,
            "relevance": 1
          },
          {
            "score": 0.794396162033081,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7446948289871216,
            "relevance": 2
          },
          {
            "score": 0.7278875112533569,
            "relevance": 4
          },
          {
            "score": 0.7262870073318481,
            "relevance": 3
          },
          {
            "score": 0.7065478563308716,
            "relevance": 5
          },
          {
            "score": 0.7026108503341675,
            "relevance": 5
          },
          {
            "score": 0.7008692622184753,
            "relevance": 2
          },
          {
            "score": 0.6881003379821777,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.2749615933369961
        }
      }
    },
    "thresh_0.100_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7974185943603516,
            "relevance": 3
          },
          {
            "score": 0.7967982888221741,
            "relevance": 5
          },
          {
            "score": 0.7961910963058472,
            "relevance": 2
          },
          {
            "score": 0.7959046363830566,
            "relevance": 5
          },
          {
            "score": 0.795473575592041,
            "relevance": 2
          },
          {
            "score": 0.7952409982681274,
            "relevance": 1
          },
          {
            "score": 0.794396162033081,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8216155767440796,
            "relevance": 2
          },
          {
            "score": 0.8058638572692871,
            "relevance": 4
          },
          {
            "score": 0.8050462007522583,
            "relevance": 3
          },
          {
            "score": 0.7880159616470337,
            "relevance": 5
          },
          {
            "score": 0.7827355861663818,
            "relevance": 5
          },
          {
            "score": 0.7820677161216736,
            "relevance": 2
          },
          {
            "score": 0.7696502208709717,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.2749615933369961
        }
      }
    },
    "thresh_0.100_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7974185943603516,
            "relevance": 3
          },
          {
            "score": 0.7967982888221741,
            "relevance": 5
          },
          {
            "score": 0.7961910963058472,
            "relevance": 2
          },
          {
            "score": 0.7959046363830566,
            "relevance": 5
          },
          {
            "score": 0.795473575592041,
            "relevance": 2
          },
          {
            "score": 0.7952409982681274,
            "relevance": 1
          },
          {
            "score": 0.794396162033081,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8844215869903564,
            "relevance": 2
          },
          {
            "score": 0.8717175722122192,
            "relevance": 3
          },
          {
            "score": 0.8708127737045288,
            "relevance": 4
          },
          {
            "score": 0.8629094362258911,
            "relevance": 5
          },
          {
            "score": 0.8557378649711609,
            "relevance": 2
          },
          {
            "score": 0.8528505563735962,
            "relevance": 5
          },
          {
            "score": 0.8449838161468506,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.2569206137583197
        }
      }
    },
    "thresh_0.110_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7974185943603516,
            "relevance": 3
          },
          {
            "score": 0.7967982888221741,
            "relevance": 5
          },
          {
            "score": 0.7961910963058472,
            "relevance": 2
          },
          {
            "score": 0.7959046363830566,
            "relevance": 5
          },
          {
            "score": 0.795473575592041,
            "relevance": 2
          },
          {
            "score": 0.7952409982681274,
            "relevance": 1
          },
          {
            "score": 0.794396162033081,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.543070912361145,
            "relevance": 2
          },
          {
            "score": 0.5277972221374512,
            "relevance": 4
          },
          {
            "score": 0.5276276469230652,
            "relevance": 3
          },
          {
            "score": 0.5177661776542664,
            "relevance": 5
          },
          {
            "score": 0.5102142095565796,
            "relevance": 2
          },
          {
            "score": 0.5073783993721008,
            "relevance": 5
          },
          {
            "score": 0.5000644326210022,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.2749615933369961
        }
      }
    },
    "thresh_0.110_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7974185943603516,
            "relevance": 3
          },
          {
            "score": 0.7967982888221741,
            "relevance": 5
          },
          {
            "score": 0.7961910963058472,
            "relevance": 2
          },
          {
            "score": 0.7959046363830566,
            "relevance": 5
          },
          {
            "score": 0.795473575592041,
            "relevance": 2
          },
          {
            "score": 0.7952409982681274,
            "relevance": 1
          },
          {
            "score": 0.794396162033081,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7438197135925293,
            "relevance": 2
          },
          {
            "score": 0.7263813018798828,
            "relevance": 4
          },
          {
            "score": 0.72426837682724,
            "relevance": 3
          },
          {
            "score": 0.7017982602119446,
            "relevance": 5
          },
          {
            "score": 0.6995087265968323,
            "relevance": 5
          },
          {
            "score": 0.6965773105621338,
            "relevance": 2
          },
          {
            "score": 0.6832036972045898,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.2749615933369961
        }
      }
    },
    "thresh_0.110_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7974185943603516,
            "relevance": 3
          },
          {
            "score": 0.7967982888221741,
            "relevance": 5
          },
          {
            "score": 0.7961910963058472,
            "relevance": 2
          },
          {
            "score": 0.7959046363830566,
            "relevance": 5
          },
          {
            "score": 0.795473575592041,
            "relevance": 2
          },
          {
            "score": 0.7952409982681274,
            "relevance": 1
          },
          {
            "score": 0.794396162033081,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8227789402008057,
            "relevance": 2
          },
          {
            "score": 0.806172251701355,
            "relevance": 4
          },
          {
            "score": 0.8046438097953796,
            "relevance": 3
          },
          {
            "score": 0.7836320996284485,
            "relevance": 5
          },
          {
            "score": 0.780796229839325,
            "relevance": 5
          },
          {
            "score": 0.7783690690994263,
            "relevance": 2
          },
          {
            "score": 0.7650326490402222,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.2749615933369961
        }
      }
    },
    "thresh_0.110_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7974185943603516,
            "relevance": 3
          },
          {
            "score": 0.7967982888221741,
            "relevance": 5
          },
          {
            "score": 0.7961910963058472,
            "relevance": 2
          },
          {
            "score": 0.7959046363830566,
            "relevance": 5
          },
          {
            "score": 0.795473575592041,
            "relevance": 2
          },
          {
            "score": 0.7952409982681274,
            "relevance": 1
          },
          {
            "score": 0.794396162033081,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8899142742156982,
            "relevance": 2
          },
          {
            "score": 0.8754865527153015,
            "relevance": 3
          },
          {
            "score": 0.8753752708435059,
            "relevance": 4
          },
          {
            "score": 0.8618971705436707,
            "relevance": 5
          },
          {
            "score": 0.855586051940918,
            "relevance": 2
          },
          {
            "score": 0.8548420071601868,
            "relevance": 5
          },
          {
            "score": 0.8436681032180786,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.2569206137583197
        }
      }
    },
    "thresh_0.120_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7974185943603516,
            "relevance": 3
          },
          {
            "score": 0.7967982888221741,
            "relevance": 5
          },
          {
            "score": 0.7961910963058472,
            "relevance": 2
          },
          {
            "score": 0.7959046363830566,
            "relevance": 5
          },
          {
            "score": 0.795473575592041,
            "relevance": 2
          },
          {
            "score": 0.7952409982681274,
            "relevance": 1
          },
          {
            "score": 0.794396162033081,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5455552339553833,
            "relevance": 2
          },
          {
            "score": 0.5301584005355835,
            "relevance": 4
          },
          {
            "score": 0.5298699140548706,
            "relevance": 3
          },
          {
            "score": 0.5194113254547119,
            "relevance": 5
          },
          {
            "score": 0.5119861364364624,
            "relevance": 2
          },
          {
            "score": 0.5094118714332581,
            "relevance": 5
          },
          {
            "score": 0.5017334222793579,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.2749615933369961
        }
      }
    },
    "thresh_0.120_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7974185943603516,
            "relevance": 3
          },
          {
            "score": 0.7967982888221741,
            "relevance": 5
          },
          {
            "score": 0.7961910963058472,
            "relevance": 2
          },
          {
            "score": 0.7959046363830566,
            "relevance": 5
          },
          {
            "score": 0.795473575592041,
            "relevance": 2
          },
          {
            "score": 0.7952409982681274,
            "relevance": 1
          },
          {
            "score": 0.794396162033081,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7416396141052246,
            "relevance": 2
          },
          {
            "score": 0.7235729694366455,
            "relevance": 4
          },
          {
            "score": 0.7209235429763794,
            "relevance": 3
          },
          {
            "score": 0.695643424987793,
            "relevance": 5
          },
          {
            "score": 0.695081353187561,
            "relevance": 5
          },
          {
            "score": 0.6909109354019165,
            "relevance": 2
          },
          {
            "score": 0.6769386529922485,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.2749615933369961
        }
      }
    },
    "thresh_0.120_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7974185943603516,
            "relevance": 3
          },
          {
            "score": 0.7967982888221741,
            "relevance": 5
          },
          {
            "score": 0.7961910963058472,
            "relevance": 2
          },
          {
            "score": 0.7959046363830566,
            "relevance": 5
          },
          {
            "score": 0.795473575592041,
            "relevance": 2
          },
          {
            "score": 0.7952409982681274,
            "relevance": 1
          },
          {
            "score": 0.794396162033081,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8221583366394043,
            "relevance": 2
          },
          {
            "score": 0.8046549558639526,
            "relevance": 4
          },
          {
            "score": 0.8023544549942017,
            "relevance": 3
          },
          {
            "score": 0.7770920991897583,
            "relevance": 5
          },
          {
            "score": 0.7768943309783936,
            "relevance": 5
          },
          {
            "score": 0.7725750207901001,
            "relevance": 2
          },
          {
            "score": 0.7582845687866211,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.2749615933369961
        }
      }
    },
    "thresh_0.120_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7974185943603516,
            "relevance": 3
          },
          {
            "score": 0.7967982888221741,
            "relevance": 5
          },
          {
            "score": 0.7961910963058472,
            "relevance": 2
          },
          {
            "score": 0.7959046363830566,
            "relevance": 5
          },
          {
            "score": 0.795473575592041,
            "relevance": 2
          },
          {
            "score": 0.7952409982681274,
            "relevance": 1
          },
          {
            "score": 0.794396162033081,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8934385776519775,
            "relevance": 2
          },
          {
            "score": 0.8778632879257202,
            "relevance": 4
          },
          {
            "score": 0.877062201499939,
            "relevance": 3
          },
          {
            "score": 0.8580737113952637,
            "relevance": 5
          },
          {
            "score": 0.8544358015060425,
            "relevance": 5
          },
          {
            "score": 0.8527454137802124,
            "relevance": 2
          },
          {
            "score": 0.8395431041717529,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.2749615933369961
        }
      }
    },
    "thresh_0.130_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7974185943603516,
            "relevance": 3
          },
          {
            "score": 0.7967982888221741,
            "relevance": 5
          },
          {
            "score": 0.7961910963058472,
            "relevance": 2
          },
          {
            "score": 0.7959046363830566,
            "relevance": 5
          },
          {
            "score": 0.795473575592041,
            "relevance": 2
          },
          {
            "score": 0.7952409982681274,
            "relevance": 1
          },
          {
            "score": 0.794396162033081,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.547697901725769,
            "relevance": 2
          },
          {
            "score": 0.532202959060669,
            "relevance": 4
          },
          {
            "score": 0.5317875146865845,
            "relevance": 3
          },
          {
            "score": 0.520714521408081,
            "relevance": 5
          },
          {
            "score": 0.5134395360946655,
            "relevance": 2
          },
          {
            "score": 0.5111508369445801,
            "relevance": 5
          },
          {
            "score": 0.50309818983078,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.2749615933369961
        }
      }
    },
    "thresh_0.130_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7974185943603516,
            "relevance": 3
          },
          {
            "score": 0.7967982888221741,
            "relevance": 5
          },
          {
            "score": 0.7961910963058472,
            "relevance": 2
          },
          {
            "score": 0.7959046363830566,
            "relevance": 5
          },
          {
            "score": 0.795473575592041,
            "relevance": 2
          },
          {
            "score": 0.7952409982681274,
            "relevance": 1
          },
          {
            "score": 0.794396162033081,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7380803823471069,
            "relevance": 2
          },
          {
            "score": 0.7193936109542847,
            "relevance": 4
          },
          {
            "score": 0.7161874175071716,
            "relevance": 3
          },
          {
            "score": 0.6892725229263306,
            "relevance": 5
          },
          {
            "score": 0.6880444288253784,
            "relevance": 5
          },
          {
            "score": 0.6838259100914001,
            "relevance": 2
          },
          {
            "score": 0.6692666411399841,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.2749615933369961
        }
      }
    },
    "thresh_0.130_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7974185943603516,
            "relevance": 3
          },
          {
            "score": 0.7967982888221741,
            "relevance": 5
          },
          {
            "score": 0.7961910963058472,
            "relevance": 2
          },
          {
            "score": 0.7959046363830566,
            "relevance": 5
          },
          {
            "score": 0.795473575592041,
            "relevance": 2
          },
          {
            "score": 0.7952409982681274,
            "relevance": 1
          },
          {
            "score": 0.794396162033081,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8195884227752686,
            "relevance": 2
          },
          {
            "score": 0.8011500835418701,
            "relevance": 4
          },
          {
            "score": 0.7980203032493591,
            "relevance": 3
          },
          {
            "score": 0.770880937576294,
            "relevance": 5
          },
          {
            "score": 0.7682696580886841,
            "relevance": 5
          },
          {
            "score": 0.7645520567893982,
            "relevance": 2
          },
          {
            "score": 0.7492814660072327,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.2749615933369961
        }
      }
    },
    "thresh_0.130_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7974185943603516,
            "relevance": 3
          },
          {
            "score": 0.7967982888221741,
            "relevance": 5
          },
          {
            "score": 0.7961910963058472,
            "relevance": 2
          },
          {
            "score": 0.7959046363830566,
            "relevance": 5
          },
          {
            "score": 0.795473575592041,
            "relevance": 2
          },
          {
            "score": 0.7952409982681274,
            "relevance": 1
          },
          {
            "score": 0.794396162033081,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.48328266437076156
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8946912288665771,
            "relevance": 2
          },
          {
            "score": 0.8779650926589966,
            "relevance": 4
          },
          {
            "score": 0.8761278986930847,
            "relevance": 3
          },
          {
            "score": 0.8513063192367554,
            "relevance": 5
          },
          {
            "score": 0.8511132001876831,
            "relevance": 5
          },
          {
            "score": 0.8468889594078064,
            "relevance": 2
          },
          {
            "score": 0.8322833180427551,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.2749615933369961
        }
      }
    }
  },
  "P06": {
    "thresh_0.090_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7349328398704529,
            "relevance": 5
          },
          {
            "score": 0.7342483997344971,
            "relevance": 2
          },
          {
            "score": 0.7342407703399658,
            "relevance": 3
          },
          {
            "score": 0.7341707348823547,
            "relevance": 5
          },
          {
            "score": 0.7340705990791321,
            "relevance": 2
          },
          {
            "score": 0.7335309982299805,
            "relevance": 4
          },
          {
            "score": 0.731497585773468,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6268261700970897
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9300282597541809,
            "relevance": 1
          },
          {
            "score": 0.9250679016113281,
            "relevance": 2
          },
          {
            "score": 0.9233890175819397,
            "relevance": 4
          },
          {
            "score": 0.9192595481872559,
            "relevance": 3
          },
          {
            "score": 0.9127062559127808,
            "relevance": 2
          },
          {
            "score": 0.9098571538925171,
            "relevance": 5
          },
          {
            "score": 0.8972265720367432,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.17900447921841645
        }
      }
    },
    "thresh_0.090_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7349328398704529,
            "relevance": 5
          },
          {
            "score": 0.7342483997344971,
            "relevance": 2
          },
          {
            "score": 0.7342407703399658,
            "relevance": 3
          },
          {
            "score": 0.7341707348823547,
            "relevance": 5
          },
          {
            "score": 0.7340705990791321,
            "relevance": 2
          },
          {
            "score": 0.7335309982299805,
            "relevance": 4
          },
          {
            "score": 0.731497585773468,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6268261700970897
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.051344394683838,
            "relevance": 1
          },
          {
            "score": 1.049152135848999,
            "relevance": 4
          },
          {
            "score": 1.0483149290084839,
            "relevance": 2
          },
          {
            "score": 1.0472687482833862,
            "relevance": 3
          },
          {
            "score": 1.0461875200271606,
            "relevance": 2
          },
          {
            "score": 1.0449070930480957,
            "relevance": 5
          },
          {
            "score": 1.0404531955718994,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.20606594858643096
        }
      }
    },
    "thresh_0.090_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7349328398704529,
            "relevance": 5
          },
          {
            "score": 0.7342483997344971,
            "relevance": 2
          },
          {
            "score": 0.7342407703399658,
            "relevance": 3
          },
          {
            "score": 0.7341707348823547,
            "relevance": 5
          },
          {
            "score": 0.7340705990791321,
            "relevance": 2
          },
          {
            "score": 0.7335309982299805,
            "relevance": 4
          },
          {
            "score": 0.731497585773468,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6268261700970897
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.063431739807129,
            "relevance": 1
          },
          {
            "score": 1.062298059463501,
            "relevance": 4
          },
          {
            "score": 1.0613259077072144,
            "relevance": 2
          },
          {
            "score": 1.0609735250473022,
            "relevance": 3
          },
          {
            "score": 1.0608540773391724,
            "relevance": 2
          },
          {
            "score": 1.060476303100586,
            "relevance": 5
          },
          {
            "score": 1.058420181274414,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.20606594858643096
        }
      }
    },
    "thresh_0.090_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7349328398704529,
            "relevance": 5
          },
          {
            "score": 0.7342483997344971,
            "relevance": 2
          },
          {
            "score": 0.7342407703399658,
            "relevance": 3
          },
          {
            "score": 0.7341707348823547,
            "relevance": 5
          },
          {
            "score": 0.7340705990791321,
            "relevance": 2
          },
          {
            "score": 0.7335309982299805,
            "relevance": 4
          },
          {
            "score": 0.731497585773468,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6268261700970897
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0670859813690186,
            "relevance": 1
          },
          {
            "score": 1.0664033889770508,
            "relevance": 4
          },
          {
            "score": 1.066323161125183,
            "relevance": 2
          },
          {
            "score": 1.0656732320785522,
            "relevance": 5
          },
          {
            "score": 1.0653234720230103,
            "relevance": 3
          },
          {
            "score": 1.064774751663208,
            "relevance": 5
          },
          {
            "score": 1.0646988153457642,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.20606594858643096
        }
      }
    },
    "thresh_0.100_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7349328398704529,
            "relevance": 5
          },
          {
            "score": 0.7342483997344971,
            "relevance": 2
          },
          {
            "score": 0.7342407703399658,
            "relevance": 3
          },
          {
            "score": 0.7341707348823547,
            "relevance": 5
          },
          {
            "score": 0.7340705990791321,
            "relevance": 2
          },
          {
            "score": 0.7335309982299805,
            "relevance": 4
          },
          {
            "score": 0.731497585773468,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6268261700970897
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.939984917640686,
            "relevance": 1
          },
          {
            "score": 0.9349644780158997,
            "relevance": 2
          },
          {
            "score": 0.933124840259552,
            "relevance": 4
          },
          {
            "score": 0.9288949966430664,
            "relevance": 3
          },
          {
            "score": 0.9220322370529175,
            "relevance": 2
          },
          {
            "score": 0.9191091060638428,
            "relevance": 5
          },
          {
            "score": 0.9060431718826294,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.17900447921841645
        }
      }
    },
    "thresh_0.100_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7349328398704529,
            "relevance": 5
          },
          {
            "score": 0.7342483997344971,
            "relevance": 2
          },
          {
            "score": 0.7342407703399658,
            "relevance": 3
          },
          {
            "score": 0.7341707348823547,
            "relevance": 5
          },
          {
            "score": 0.7340705990791321,
            "relevance": 2
          },
          {
            "score": 0.7335309982299805,
            "relevance": 4
          },
          {
            "score": 0.731497585773468,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6268261700970897
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.065927267074585,
            "relevance": 1
          },
          {
            "score": 1.0635926723480225,
            "relevance": 4
          },
          {
            "score": 1.0628728866577148,
            "relevance": 2
          },
          {
            "score": 1.0616445541381836,
            "relevance": 3
          },
          {
            "score": 1.0603293180465698,
            "relevance": 2
          },
          {
            "score": 1.0589933395385742,
            "relevance": 5
          },
          {
            "score": 1.0541744232177734,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.20606594858643096
        }
      }
    },
    "thresh_0.100_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7349328398704529,
            "relevance": 5
          },
          {
            "score": 0.7342483997344971,
            "relevance": 2
          },
          {
            "score": 0.7342407703399658,
            "relevance": 3
          },
          {
            "score": 0.7341707348823547,
            "relevance": 5
          },
          {
            "score": 0.7340705990791321,
            "relevance": 2
          },
          {
            "score": 0.7335309982299805,
            "relevance": 4
          },
          {
            "score": 0.731497585773468,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6268261700970897
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0791171789169312,
            "relevance": 1
          },
          {
            "score": 1.0779287815093994,
            "relevance": 4
          },
          {
            "score": 1.0768190622329712,
            "relevance": 2
          },
          {
            "score": 1.076585292816162,
            "relevance": 3
          },
          {
            "score": 1.076552391052246,
            "relevance": 2
          },
          {
            "score": 1.0759481191635132,
            "relevance": 5
          },
          {
            "score": 1.0737130641937256,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.20606594858643096
        }
      }
    },
    "thresh_0.100_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7349328398704529,
            "relevance": 5
          },
          {
            "score": 0.7342483997344971,
            "relevance": 2
          },
          {
            "score": 0.7342407703399658,
            "relevance": 3
          },
          {
            "score": 0.7341707348823547,
            "relevance": 5
          },
          {
            "score": 0.7340705990791321,
            "relevance": 2
          },
          {
            "score": 0.7335309982299805,
            "relevance": 4
          },
          {
            "score": 0.731497585773468,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6268261700970897
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0832417011260986,
            "relevance": 1
          },
          {
            "score": 1.0825603008270264,
            "relevance": 4
          },
          {
            "score": 1.0824517011642456,
            "relevance": 2
          },
          {
            "score": 1.0818047523498535,
            "relevance": 5
          },
          {
            "score": 1.0814915895462036,
            "relevance": 3
          },
          {
            "score": 1.0808908939361572,
            "relevance": 2
          },
          {
            "score": 1.0808666944503784,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.20606594858643096
        }
      }
    },
    "thresh_0.110_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7349328398704529,
            "relevance": 5
          },
          {
            "score": 0.7342483997344971,
            "relevance": 2
          },
          {
            "score": 0.7342407703399658,
            "relevance": 3
          },
          {
            "score": 0.7341707348823547,
            "relevance": 5
          },
          {
            "score": 0.7340705990791321,
            "relevance": 2
          },
          {
            "score": 0.7335309982299805,
            "relevance": 4
          },
          {
            "score": 0.731497585773468,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6268261700970897
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9493703842163086,
            "relevance": 1
          },
          {
            "score": 0.9442917108535767,
            "relevance": 2
          },
          {
            "score": 0.9422850608825684,
            "relevance": 4
          },
          {
            "score": 0.9379538893699646,
            "relevance": 3
          },
          {
            "score": 0.9307737350463867,
            "relevance": 2
          },
          {
            "score": 0.9277762174606323,
            "relevance": 5
          },
          {
            "score": 0.9142673015594482,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.17900447921841645
        }
      }
    },
    "thresh_0.110_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7349328398704529,
            "relevance": 5
          },
          {
            "score": 0.7342483997344971,
            "relevance": 2
          },
          {
            "score": 0.7342407703399658,
            "relevance": 3
          },
          {
            "score": 0.7341707348823547,
            "relevance": 5
          },
          {
            "score": 0.7340705990791321,
            "relevance": 2
          },
          {
            "score": 0.7335309982299805,
            "relevance": 4
          },
          {
            "score": 0.731497585773468,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6268261700970897
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.080020546913147,
            "relevance": 1
          },
          {
            "score": 1.0775295495986938,
            "relevance": 4
          },
          {
            "score": 1.0769389867782593,
            "relevance": 2
          },
          {
            "score": 1.0755105018615723,
            "relevance": 3
          },
          {
            "score": 1.0739384889602661,
            "relevance": 2
          },
          {
            "score": 1.07254159450531,
            "relevance": 5
          },
          {
            "score": 1.0673224925994873,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.20606594858643096
        }
      }
    },
    "thresh_0.110_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7349328398704529,
            "relevance": 5
          },
          {
            "score": 0.7342483997344971,
            "relevance": 2
          },
          {
            "score": 0.7342407703399658,
            "relevance": 3
          },
          {
            "score": 0.7341707348823547,
            "relevance": 5
          },
          {
            "score": 0.7340705990791321,
            "relevance": 2
          },
          {
            "score": 0.7335309982299805,
            "relevance": 4
          },
          {
            "score": 0.731497585773468,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6268261700970897
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0944042205810547,
            "relevance": 1
          },
          {
            "score": 1.0931525230407715,
            "relevance": 4
          },
          {
            "score": 1.0918861627578735,
            "relevance": 2
          },
          {
            "score": 1.0918521881103516,
            "relevance": 2
          },
          {
            "score": 1.0917868614196777,
            "relevance": 3
          },
          {
            "score": 1.0909903049468994,
            "relevance": 5
          },
          {
            "score": 1.0885511636734009,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.20606594858643096
        }
      }
    },
    "thresh_0.110_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7349328398704529,
            "relevance": 5
          },
          {
            "score": 0.7342483997344971,
            "relevance": 2
          },
          {
            "score": 0.7342407703399658,
            "relevance": 3
          },
          {
            "score": 0.7341707348823547,
            "relevance": 5
          },
          {
            "score": 0.7340705990791321,
            "relevance": 2
          },
          {
            "score": 0.7335309982299805,
            "relevance": 4
          },
          {
            "score": 0.731497585773468,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6268261700970897
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0990571975708008,
            "relevance": 1
          },
          {
            "score": 1.0983749628067017,
            "relevance": 4
          },
          {
            "score": 1.0982310771942139,
            "relevance": 2
          },
          {
            "score": 1.0975865125656128,
            "relevance": 5
          },
          {
            "score": 1.0973174571990967,
            "relevance": 3
          },
          {
            "score": 1.0967458486557007,
            "relevance": 2
          },
          {
            "score": 1.0965989828109741,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.20606594858643096
        }
      }
    },
    "thresh_0.120_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7349328398704529,
            "relevance": 5
          },
          {
            "score": 0.7342483997344971,
            "relevance": 2
          },
          {
            "score": 0.7342407703399658,
            "relevance": 3
          },
          {
            "score": 0.7341707348823547,
            "relevance": 5
          },
          {
            "score": 0.7340705990791321,
            "relevance": 2
          },
          {
            "score": 0.7335309982299805,
            "relevance": 4
          },
          {
            "score": 0.731497585773468,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6268261700970897
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9581484794616699,
            "relevance": 1
          },
          {
            "score": 0.9530129432678223,
            "relevance": 2
          },
          {
            "score": 0.9508336782455444,
            "relevance": 4
          },
          {
            "score": 0.9464004635810852,
            "relevance": 3
          },
          {
            "score": 0.9388947486877441,
            "relevance": 2
          },
          {
            "score": 0.9358216524124146,
            "relevance": 5
          },
          {
            "score": 0.9218626022338867,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.17900447921841645
        }
      }
    },
    "thresh_0.120_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7349328398704529,
            "relevance": 5
          },
          {
            "score": 0.7342483997344971,
            "relevance": 2
          },
          {
            "score": 0.7342407703399658,
            "relevance": 3
          },
          {
            "score": 0.7341707348823547,
            "relevance": 5
          },
          {
            "score": 0.7340705990791321,
            "relevance": 2
          },
          {
            "score": 0.7335309982299805,
            "relevance": 4
          },
          {
            "score": 0.731497585773468,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6268261700970897
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0935777425765991,
            "relevance": 1
          },
          {
            "score": 1.0909147262573242,
            "relevance": 4
          },
          {
            "score": 1.0904659032821655,
            "relevance": 2
          },
          {
            "score": 1.0888175964355469,
            "relevance": 3
          },
          {
            "score": 1.086963415145874,
            "relevance": 2
          },
          {
            "score": 1.0854997634887695,
            "relevance": 5
          },
          {
            "score": 1.0798418521881104,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.20606594858643096
        }
      }
    },
    "thresh_0.120_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7349328398704529,
            "relevance": 5
          },
          {
            "score": 0.7342483997344971,
            "relevance": 2
          },
          {
            "score": 0.7342407703399658,
            "relevance": 3
          },
          {
            "score": 0.7341707348823547,
            "relevance": 5
          },
          {
            "score": 0.7340705990791321,
            "relevance": 2
          },
          {
            "score": 0.7335309982299805,
            "relevance": 4
          },
          {
            "score": 0.731497585773468,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6268261700970897
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.1092523336410522,
            "relevance": 1
          },
          {
            "score": 1.1079275608062744,
            "relevance": 4
          },
          {
            "score": 1.1067125797271729,
            "relevance": 2
          },
          {
            "score": 1.1065349578857422,
            "relevance": 3
          },
          {
            "score": 1.1064815521240234,
            "relevance": 2
          },
          {
            "score": 1.105556845664978,
            "relevance": 5
          },
          {
            "score": 1.1028841733932495,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.20606594858643096
        }
      }
    },
    "thresh_0.120_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7349328398704529,
            "relevance": 5
          },
          {
            "score": 0.7342483997344971,
            "relevance": 2
          },
          {
            "score": 0.7342407703399658,
            "relevance": 3
          },
          {
            "score": 0.7341707348823547,
            "relevance": 5
          },
          {
            "score": 0.7340705990791321,
            "relevance": 2
          },
          {
            "score": 0.7335309982299805,
            "relevance": 4
          },
          {
            "score": 0.731497585773468,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6268261700970897
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.1144986152648926,
            "relevance": 1
          },
          {
            "score": 1.1138126850128174,
            "relevance": 4
          },
          {
            "score": 1.1136245727539062,
            "relevance": 2
          },
          {
            "score": 1.112980842590332,
            "relevance": 5
          },
          {
            "score": 1.1127657890319824,
            "relevance": 3
          },
          {
            "score": 1.1122289896011353,
            "relevance": 2
          },
          {
            "score": 1.1119306087493896,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.20606594858643096
        }
      }
    },
    "thresh_0.130_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7349328398704529,
            "relevance": 5
          },
          {
            "score": 0.7342483997344971,
            "relevance": 2
          },
          {
            "score": 0.7342407703399658,
            "relevance": 3
          },
          {
            "score": 0.7341707348823547,
            "relevance": 5
          },
          {
            "score": 0.7340705990791321,
            "relevance": 2
          },
          {
            "score": 0.7335309982299805,
            "relevance": 4
          },
          {
            "score": 0.731497585773468,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6268261700970897
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9662865996360779,
            "relevance": 1
          },
          {
            "score": 0.9610949754714966,
            "relevance": 2
          },
          {
            "score": 0.9587374329566956,
            "relevance": 4
          },
          {
            "score": 0.954200804233551,
            "relevance": 3
          },
          {
            "score": 0.946361780166626,
            "relevance": 2
          },
          {
            "score": 0.943212628364563,
            "relevance": 5
          },
          {
            "score": 0.9287960529327393,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.0,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.3333333333333333,
          "NDCG@3": 0.17900447921841645
        }
      }
    },
    "thresh_0.130_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7349328398704529,
            "relevance": 5
          },
          {
            "score": 0.7342483997344971,
            "relevance": 2
          },
          {
            "score": 0.7342407703399658,
            "relevance": 3
          },
          {
            "score": 0.7341707348823547,
            "relevance": 5
          },
          {
            "score": 0.7340705990791321,
            "relevance": 2
          },
          {
            "score": 0.7335309982299805,
            "relevance": 4
          },
          {
            "score": 0.731497585773468,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6268261700970897
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.1065540313720703,
            "relevance": 1
          },
          {
            "score": 1.1037013530731201,
            "relevance": 4
          },
          {
            "score": 1.1034072637557983,
            "relevance": 2
          },
          {
            "score": 1.1015174388885498,
            "relevance": 3
          },
          {
            "score": 1.0993542671203613,
            "relevance": 2
          },
          {
            "score": 1.097816824913025,
            "relevance": 5
          },
          {
            "score": 1.0916774272918701,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.20606594858643096
        }
      }
    },
    "thresh_0.130_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7349328398704529,
            "relevance": 5
          },
          {
            "score": 0.7342483997344971,
            "relevance": 2
          },
          {
            "score": 0.7342407703399658,
            "relevance": 3
          },
          {
            "score": 0.7341707348823547,
            "relevance": 5
          },
          {
            "score": 0.7340705990791321,
            "relevance": 2
          },
          {
            "score": 0.7335309982299805,
            "relevance": 4
          },
          {
            "score": 0.731497585773468,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6268261700970897
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.1236226558685303,
            "relevance": 1
          },
          {
            "score": 1.1222126483917236,
            "relevance": 4
          },
          {
            "score": 1.1210929155349731,
            "relevance": 2
          },
          {
            "score": 1.1207876205444336,
            "relevance": 3
          },
          {
            "score": 1.120560884475708,
            "relevance": 2
          },
          {
            "score": 1.1196022033691406,
            "relevance": 5
          },
          {
            "score": 1.1166619062423706,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.20606594858643096
        }
      }
    },
    "thresh_0.130_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7349328398704529,
            "relevance": 5
          },
          {
            "score": 0.7342483997344971,
            "relevance": 2
          },
          {
            "score": 0.7342407703399658,
            "relevance": 3
          },
          {
            "score": 0.7341707348823547,
            "relevance": 5
          },
          {
            "score": 0.7340705990791321,
            "relevance": 2
          },
          {
            "score": 0.7335309982299805,
            "relevance": 4
          },
          {
            "score": 0.731497585773468,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.6268261700970897
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.1295347213745117,
            "relevance": 1
          },
          {
            "score": 1.128840446472168,
            "relevance": 4
          },
          {
            "score": 1.1285964250564575,
            "relevance": 2
          },
          {
            "score": 1.1279520988464355,
            "relevance": 5
          },
          {
            "score": 1.127802848815918,
            "relevance": 3
          },
          {
            "score": 1.1273077726364136,
            "relevance": 2
          },
          {
            "score": 1.1268229484558105,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.20606594858643096
        }
      }
    }
  },
  "P07": {
    "thresh_0.090_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8481593132019043,
            "relevance": 5
          },
          {
            "score": 0.847968578338623,
            "relevance": 3
          },
          {
            "score": 0.8476881384849548,
            "relevance": 5
          },
          {
            "score": 0.8472248911857605,
            "relevance": 4
          },
          {
            "score": 0.8468176126480103,
            "relevance": 2
          },
          {
            "score": 0.8449920415878296,
            "relevance": 2
          },
          {
            "score": 0.8437142968177795,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8769814165134059
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.43986284732818604,
            "relevance": 3
          },
          {
            "score": 0.42860928177833557,
            "relevance": 1
          },
          {
            "score": 0.4220389425754547,
            "relevance": 2
          },
          {
            "score": 0.4180993437767029,
            "relevance": 5
          },
          {
            "score": 0.41326603293418884,
            "relevance": 2
          },
          {
            "score": 0.4108218848705292,
            "relevance": 5
          },
          {
            "score": 0.40778714418411255,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.15727032313610606
        }
      }
    },
    "thresh_0.090_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8481593132019043,
            "relevance": 5
          },
          {
            "score": 0.847968578338623,
            "relevance": 3
          },
          {
            "score": 0.8476881384849548,
            "relevance": 5
          },
          {
            "score": 0.8472248911857605,
            "relevance": 4
          },
          {
            "score": 0.8468176126480103,
            "relevance": 2
          },
          {
            "score": 0.8449920415878296,
            "relevance": 2
          },
          {
            "score": 0.8437142968177795,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8769814165134059
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5685268044471741,
            "relevance": 3
          },
          {
            "score": 0.5462316274642944,
            "relevance": 1
          },
          {
            "score": 0.5374770164489746,
            "relevance": 2
          },
          {
            "score": 0.5182112455368042,
            "relevance": 5
          },
          {
            "score": 0.5093698501586914,
            "relevance": 5
          },
          {
            "score": 0.5070938467979431,
            "relevance": 4
          },
          {
            "score": 0.504452109336853,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.15727032313610606
        }
      }
    },
    "thresh_0.090_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8481593132019043,
            "relevance": 5
          },
          {
            "score": 0.847968578338623,
            "relevance": 3
          },
          {
            "score": 0.8476881384849548,
            "relevance": 5
          },
          {
            "score": 0.8472248911857605,
            "relevance": 4
          },
          {
            "score": 0.8468176126480103,
            "relevance": 2
          },
          {
            "score": 0.8449920415878296,
            "relevance": 2
          },
          {
            "score": 0.8437142968177795,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8769814165134059
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6372906565666199,
            "relevance": 3
          },
          {
            "score": 0.6104604005813599,
            "relevance": 1
          },
          {
            "score": 0.6007587909698486,
            "relevance": 2
          },
          {
            "score": 0.5744433403015137,
            "relevance": 5
          },
          {
            "score": 0.5648462772369385,
            "relevance": 5
          },
          {
            "score": 0.5629374980926514,
            "relevance": 4
          },
          {
            "score": 0.556289553642273,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.15727032313610606
        }
      }
    },
    "thresh_0.090_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8481593132019043,
            "relevance": 5
          },
          {
            "score": 0.847968578338623,
            "relevance": 3
          },
          {
            "score": 0.8476881384849548,
            "relevance": 5
          },
          {
            "score": 0.8472248911857605,
            "relevance": 4
          },
          {
            "score": 0.8468176126480103,
            "relevance": 2
          },
          {
            "score": 0.8449920415878296,
            "relevance": 2
          },
          {
            "score": 0.8437142968177795,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8769814165134059
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7171952128410339,
            "relevance": 3
          },
          {
            "score": 0.6869498491287231,
            "relevance": 1
          },
          {
            "score": 0.676459550857544,
            "relevance": 2
          },
          {
            "score": 0.6436495780944824,
            "relevance": 5
          },
          {
            "score": 0.6333009004592896,
            "relevance": 5
          },
          {
            "score": 0.6317586898803711,
            "relevance": 4
          },
          {
            "score": 0.6210023164749146,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.15727032313610606
        }
      }
    },
    "thresh_0.100_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8481593132019043,
            "relevance": 5
          },
          {
            "score": 0.847968578338623,
            "relevance": 3
          },
          {
            "score": 0.8476881384849548,
            "relevance": 5
          },
          {
            "score": 0.8472248911857605,
            "relevance": 4
          },
          {
            "score": 0.8468176126480103,
            "relevance": 2
          },
          {
            "score": 0.8449920415878296,
            "relevance": 2
          },
          {
            "score": 0.8437142968177795,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8769814165134059
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.44039270281791687,
            "relevance": 3
          },
          {
            "score": 0.42900800704956055,
            "relevance": 1
          },
          {
            "score": 0.4224335253238678,
            "relevance": 2
          },
          {
            "score": 0.41829222440719604,
            "relevance": 5
          },
          {
            "score": 0.41336435079574585,
            "relevance": 2
          },
          {
            "score": 0.4110332131385803,
            "relevance": 5
          },
          {
            "score": 0.4080232083797455,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.15727032313610606
        }
      }
    },
    "thresh_0.100_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8481593132019043,
            "relevance": 5
          },
          {
            "score": 0.847968578338623,
            "relevance": 3
          },
          {
            "score": 0.8476881384849548,
            "relevance": 5
          },
          {
            "score": 0.8472248911857605,
            "relevance": 4
          },
          {
            "score": 0.8468176126480103,
            "relevance": 2
          },
          {
            "score": 0.8449920415878296,
            "relevance": 2
          },
          {
            "score": 0.8437142968177795,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8769814165134059
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5555151700973511,
            "relevance": 3
          },
          {
            "score": 0.5323432683944702,
            "relevance": 1
          },
          {
            "score": 0.5234484672546387,
            "relevance": 2
          },
          {
            "score": 0.5031216740608215,
            "relevance": 5
          },
          {
            "score": 0.4942200779914856,
            "relevance": 5
          },
          {
            "score": 0.49200674891471863,
            "relevance": 4
          },
          {
            "score": 0.4888406991958618,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.15727032313610606
        }
      }
    },
    "thresh_0.100_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8481593132019043,
            "relevance": 5
          },
          {
            "score": 0.847968578338623,
            "relevance": 3
          },
          {
            "score": 0.8476881384849548,
            "relevance": 5
          },
          {
            "score": 0.8472248911857605,
            "relevance": 4
          },
          {
            "score": 0.8468176126480103,
            "relevance": 2
          },
          {
            "score": 0.8449920415878296,
            "relevance": 2
          },
          {
            "score": 0.8437142968177795,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8769814165134059
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6186586618423462,
            "relevance": 3
          },
          {
            "score": 0.5901130437850952,
            "relevance": 1
          },
          {
            "score": 0.5801141262054443,
            "relevance": 2
          },
          {
            "score": 0.5517175197601318,
            "relevance": 5
          },
          {
            "score": 0.5419642925262451,
            "relevance": 5
          },
          {
            "score": 0.540164589881897,
            "relevance": 4
          },
          {
            "score": 0.5325160622596741,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.15727032313610606
        }
      }
    },
    "thresh_0.100_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8481593132019043,
            "relevance": 5
          },
          {
            "score": 0.847968578338623,
            "relevance": 3
          },
          {
            "score": 0.8476881384849548,
            "relevance": 5
          },
          {
            "score": 0.8472248911857605,
            "relevance": 4
          },
          {
            "score": 0.8468176126480103,
            "relevance": 2
          },
          {
            "score": 0.8449920415878296,
            "relevance": 2
          },
          {
            "score": 0.8437142968177795,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8769814165134059
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6942424774169922,
            "relevance": 3
          },
          {
            "score": 0.6608186960220337,
            "relevance": 1
          },
          {
            "score": 0.6497472524642944,
            "relevance": 2
          },
          {
            "score": 0.6129428148269653,
            "relevance": 5
          },
          {
            "score": 0.6022520661354065,
            "relevance": 5
          },
          {
            "score": 0.6009089946746826,
            "relevance": 4
          },
          {
            "score": 0.5882142186164856,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.15727032313610606
        }
      }
    },
    "thresh_0.110_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8481593132019043,
            "relevance": 5
          },
          {
            "score": 0.847968578338623,
            "relevance": 3
          },
          {
            "score": 0.8476881384849548,
            "relevance": 5
          },
          {
            "score": 0.8472248911857605,
            "relevance": 4
          },
          {
            "score": 0.8468176126480103,
            "relevance": 2
          },
          {
            "score": 0.8449920415878296,
            "relevance": 2
          },
          {
            "score": 0.8437142968177795,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8769814165134059
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.44067081809043884,
            "relevance": 3
          },
          {
            "score": 0.4291669726371765,
            "relevance": 1
          },
          {
            "score": 0.42260077595710754,
            "relevance": 2
          },
          {
            "score": 0.41824978590011597,
            "relevance": 5
          },
          {
            "score": 0.41322895884513855,
            "relevance": 2
          },
          {
            "score": 0.4110237658023834,
            "relevance": 5
          },
          {
            "score": 0.40804603695869446,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.15727032313610606
        }
      }
    },
    "thresh_0.110_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8481593132019043,
            "relevance": 5
          },
          {
            "score": 0.847968578338623,
            "relevance": 3
          },
          {
            "score": 0.8476881384849548,
            "relevance": 5
          },
          {
            "score": 0.8472248911857605,
            "relevance": 4
          },
          {
            "score": 0.8468176126480103,
            "relevance": 2
          },
          {
            "score": 0.8449920415878296,
            "relevance": 2
          },
          {
            "score": 0.8437142968177795,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8769814165134059
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5413504838943481,
            "relevance": 3
          },
          {
            "score": 0.5173869132995605,
            "relevance": 1
          },
          {
            "score": 0.508379340171814,
            "relevance": 2
          },
          {
            "score": 0.48709607124328613,
            "relevance": 5
          },
          {
            "score": 0.4781610071659088,
            "relevance": 5
          },
          {
            "score": 0.4760119616985321,
            "relevance": 4
          },
          {
            "score": 0.4723645746707916,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.15727032313610606
        }
      }
    },
    "thresh_0.110_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8481593132019043,
            "relevance": 5
          },
          {
            "score": 0.847968578338623,
            "relevance": 3
          },
          {
            "score": 0.8476881384849548,
            "relevance": 5
          },
          {
            "score": 0.8472248911857605,
            "relevance": 4
          },
          {
            "score": 0.8468176126480103,
            "relevance": 2
          },
          {
            "score": 0.8449920415878296,
            "relevance": 2
          },
          {
            "score": 0.8437142968177795,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8769814165134059
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5978555679321289,
            "relevance": 3
          },
          {
            "score": 0.5677227973937988,
            "relevance": 1
          },
          {
            "score": 0.5574647188186646,
            "relevance": 2
          },
          {
            "score": 0.527186930179596,
            "relevance": 5
          },
          {
            "score": 0.5173157453536987,
            "relevance": 5
          },
          {
            "score": 0.5156213045120239,
            "relevance": 4
          },
          {
            "score": 0.5070788860321045,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.15727032313610606
        }
      }
    },
    "thresh_0.110_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8481593132019043,
            "relevance": 5
          },
          {
            "score": 0.847968578338623,
            "relevance": 3
          },
          {
            "score": 0.8476881384849548,
            "relevance": 5
          },
          {
            "score": 0.8472248911857605,
            "relevance": 4
          },
          {
            "score": 0.8468176126480103,
            "relevance": 2
          },
          {
            "score": 0.8449920415878296,
            "relevance": 2
          },
          {
            "score": 0.8437142968177795,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8769814165134059
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6673308610916138,
            "relevance": 3
          },
          {
            "score": 0.6308366060256958,
            "relevance": 1
          },
          {
            "score": 0.6192251443862915,
            "relevance": 2
          },
          {
            "score": 0.578705906867981,
            "relevance": 5
          },
          {
            "score": 0.5677250623703003,
            "relevance": 5
          },
          {
            "score": 0.5665702819824219,
            "relevance": 4
          },
          {
            "score": 0.5521290302276611,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.15727032313610606
        }
      }
    },
    "thresh_0.120_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8481593132019043,
            "relevance": 5
          },
          {
            "score": 0.847968578338623,
            "relevance": 3
          },
          {
            "score": 0.8476881384849548,
            "relevance": 5
          },
          {
            "score": 0.8472248911857605,
            "relevance": 4
          },
          {
            "score": 0.8468176126480103,
            "relevance": 2
          },
          {
            "score": 0.8449920415878296,
            "relevance": 2
          },
          {
            "score": 0.8437142968177795,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8769814165134059
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.4406754970550537,
            "relevance": 3
          },
          {
            "score": 0.42906510829925537,
            "relevance": 1
          },
          {
            "score": 0.4225194454193115,
            "relevance": 2
          },
          {
            "score": 0.41795244812965393,
            "relevance": 5
          },
          {
            "score": 0.41284114122390747,
            "relevance": 2
          },
          {
            "score": 0.41077375411987305,
            "relevance": 5
          },
          {
            "score": 0.40783563256263733,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.15727032313610606
        }
      }
    },
    "thresh_0.120_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8481593132019043,
            "relevance": 5
          },
          {
            "score": 0.847968578338623,
            "relevance": 3
          },
          {
            "score": 0.8476881384849548,
            "relevance": 5
          },
          {
            "score": 0.8472248911857605,
            "relevance": 4
          },
          {
            "score": 0.8468176126480103,
            "relevance": 2
          },
          {
            "score": 0.8449920415878296,
            "relevance": 2
          },
          {
            "score": 0.8437142968177795,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8769814165134059
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5261017084121704,
            "relevance": 3
          },
          {
            "score": 0.5014447569847107,
            "relevance": 1
          },
          {
            "score": 0.4923543334007263,
            "relevance": 2
          },
          {
            "score": 0.4702356159687042,
            "relevance": 5
          },
          {
            "score": 0.4612945318222046,
            "relevance": 5
          },
          {
            "score": 0.4592107832431793,
            "relevance": 4
          },
          {
            "score": 0.45513296127319336,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.15727032313610606
        }
      }
    },
    "thresh_0.120_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8481593132019043,
            "relevance": 5
          },
          {
            "score": 0.847968578338623,
            "relevance": 3
          },
          {
            "score": 0.8476881384849548,
            "relevance": 5
          },
          {
            "score": 0.8472248911857605,
            "relevance": 4
          },
          {
            "score": 0.8468176126480103,
            "relevance": 2
          },
          {
            "score": 0.8449920415878296,
            "relevance": 2
          },
          {
            "score": 0.8437142968177795,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8769814165134059
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5750055313110352,
            "relevance": 3
          },
          {
            "score": 0.5434553027153015,
            "relevance": 1
          },
          {
            "score": 0.5329841375350952,
            "relevance": 2
          },
          {
            "score": 0.5010771751403809,
            "relevance": 5
          },
          {
            "score": 0.4911304712295532,
            "relevance": 5
          },
          {
            "score": 0.48953476548194885,
            "relevance": 4
          },
          {
            "score": 0.48022931814193726,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.15727032313610606
        }
      }
    },
    "thresh_0.120_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8481593132019043,
            "relevance": 5
          },
          {
            "score": 0.847968578338623,
            "relevance": 3
          },
          {
            "score": 0.8476881384849548,
            "relevance": 5
          },
          {
            "score": 0.8472248911857605,
            "relevance": 4
          },
          {
            "score": 0.8468176126480103,
            "relevance": 2
          },
          {
            "score": 0.8449920415878296,
            "relevance": 2
          },
          {
            "score": 0.8437142968177795,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8769814165134059
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.636568009853363,
            "relevance": 3
          },
          {
            "score": 0.5972268581390381,
            "relevance": 1
          },
          {
            "score": 0.5851390361785889,
            "relevance": 2
          },
          {
            "score": 0.5413414239883423,
            "relevance": 5
          },
          {
            "score": 0.530137300491333,
            "relevance": 5
          },
          {
            "score": 0.529152512550354,
            "relevance": 4
          },
          {
            "score": 0.5132347941398621,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.15727032313610606
        }
      }
    },
    "thresh_0.130_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8481593132019043,
            "relevance": 5
          },
          {
            "score": 0.847968578338623,
            "relevance": 3
          },
          {
            "score": 0.8476881384849548,
            "relevance": 5
          },
          {
            "score": 0.8472248911857605,
            "relevance": 4
          },
          {
            "score": 0.8468176126480103,
            "relevance": 2
          },
          {
            "score": 0.8449920415878296,
            "relevance": 2
          },
          {
            "score": 0.8437142968177795,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8769814165134059
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.4403875172138214,
            "relevance": 3
          },
          {
            "score": 0.4286838173866272,
            "relevance": 1
          },
          {
            "score": 0.4221705496311188,
            "relevance": 2
          },
          {
            "score": 0.41738277673721313,
            "relevance": 5
          },
          {
            "score": 0.41218408942222595,
            "relevance": 2
          },
          {
            "score": 0.4102650284767151,
            "relevance": 5
          },
          {
            "score": 0.4073735177516937,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.15727032313610606
        }
      }
    },
    "thresh_0.130_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8481593132019043,
            "relevance": 5
          },
          {
            "score": 0.847968578338623,
            "relevance": 3
          },
          {
            "score": 0.8476881384849548,
            "relevance": 5
          },
          {
            "score": 0.8472248911857605,
            "relevance": 4
          },
          {
            "score": 0.8468176126480103,
            "relevance": 2
          },
          {
            "score": 0.8449920415878296,
            "relevance": 2
          },
          {
            "score": 0.8437142968177795,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8769814165134059
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5098552703857422,
            "relevance": 3
          },
          {
            "score": 0.4846157431602478,
            "relevance": 1
          },
          {
            "score": 0.4754737317562103,
            "relevance": 2
          },
          {
            "score": 0.4526553750038147,
            "relevance": 5
          },
          {
            "score": 0.4437364339828491,
            "relevance": 5
          },
          {
            "score": 0.4417180120944977,
            "relevance": 4
          },
          {
            "score": 0.4372674524784088,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.15727032313610606
        }
      }
    },
    "thresh_0.130_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8481593132019043,
            "relevance": 5
          },
          {
            "score": 0.847968578338623,
            "relevance": 3
          },
          {
            "score": 0.8476881384849548,
            "relevance": 5
          },
          {
            "score": 0.8472248911857605,
            "relevance": 4
          },
          {
            "score": 0.8468176126480103,
            "relevance": 2
          },
          {
            "score": 0.8449920415878296,
            "relevance": 2
          },
          {
            "score": 0.8437142968177795,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8769814165134059
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.5502851009368896,
            "relevance": 3
          },
          {
            "score": 0.5175267457962036,
            "relevance": 1
          },
          {
            "score": 0.5068953037261963,
            "relevance": 2
          },
          {
            "score": 0.47365760803222656,
            "relevance": 5
          },
          {
            "score": 0.4636814594268799,
            "relevance": 5
          },
          {
            "score": 0.46217575669288635,
            "relevance": 4
          },
          {
            "score": 0.45225951075553894,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.15727032313610606
        }
      }
    },
    "thresh_0.130_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8481593132019043,
            "relevance": 5
          },
          {
            "score": 0.847968578338623,
            "relevance": 3
          },
          {
            "score": 0.8476881384849548,
            "relevance": 5
          },
          {
            "score": 0.8472248911857605,
            "relevance": 4
          },
          {
            "score": 0.8468176126480103,
            "relevance": 2
          },
          {
            "score": 0.8449920415878296,
            "relevance": 2
          },
          {
            "score": 0.8437142968177795,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.8769814165134059
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6022045612335205,
            "relevance": 3
          },
          {
            "score": 0.5603605508804321,
            "relevance": 1
          },
          {
            "score": 0.5478826761245728,
            "relevance": 2
          },
          {
            "score": 0.501395046710968,
            "relevance": 5
          },
          {
            "score": 0.4900479316711426,
            "relevance": 5
          },
          {
            "score": 0.48920753598213196,
            "relevance": 4
          },
          {
            "score": 0.4721531569957733,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.15727032313610606
        }
      }
    }
  },
  "P08": {
    "thresh_0.090_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8015514612197876,
            "relevance": 1
          },
          {
            "score": 0.8014587163925171,
            "relevance": 3
          },
          {
            "score": 0.8011890649795532,
            "relevance": 2
          },
          {
            "score": 0.8004627227783203,
            "relevance": 5
          },
          {
            "score": 0.8004512190818787,
            "relevance": 2
          },
          {
            "score": 0.7998021841049194,
            "relevance": 5
          },
          {
            "score": 0.7977893352508545,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.11912932425718949
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7877397537231445,
            "relevance": 4
          },
          {
            "score": 0.7758725881576538,
            "relevance": 2
          },
          {
            "score": 0.7615773677825928,
            "relevance": 5
          },
          {
            "score": 0.7584031224250793,
            "relevance": 3
          },
          {
            "score": 0.74229896068573,
            "relevance": 2
          },
          {
            "score": 0.7373737692832947,
            "relevance": 1
          },
          {
            "score": 0.7335821390151978,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5579305253465247
        }
      }
    },
    "thresh_0.090_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8015514612197876,
            "relevance": 1
          },
          {
            "score": 0.8014587163925171,
            "relevance": 3
          },
          {
            "score": 0.8011890649795532,
            "relevance": 2
          },
          {
            "score": 0.8004627227783203,
            "relevance": 5
          },
          {
            "score": 0.8004512190818787,
            "relevance": 2
          },
          {
            "score": 0.7998021841049194,
            "relevance": 5
          },
          {
            "score": 0.7977893352508545,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.11912932425718949
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.953323245048523,
            "relevance": 4
          },
          {
            "score": 0.9509702920913696,
            "relevance": 2
          },
          {
            "score": 0.9407865405082703,
            "relevance": 3
          },
          {
            "score": 0.9379234313964844,
            "relevance": 5
          },
          {
            "score": 0.9286929965019226,
            "relevance": 1
          },
          {
            "score": 0.9275599718093872,
            "relevance": 2
          },
          {
            "score": 0.9204883575439453,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.3512435910948293
        }
      }
    },
    "thresh_0.090_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8015514612197876,
            "relevance": 1
          },
          {
            "score": 0.8014587163925171,
            "relevance": 3
          },
          {
            "score": 0.8011890649795532,
            "relevance": 2
          },
          {
            "score": 0.8004627227783203,
            "relevance": 5
          },
          {
            "score": 0.8004512190818787,
            "relevance": 2
          },
          {
            "score": 0.7998021841049194,
            "relevance": 5
          },
          {
            "score": 0.7977893352508545,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.11912932425718949
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9815101623535156,
            "relevance": 2
          },
          {
            "score": 0.9794425964355469,
            "relevance": 4
          },
          {
            "score": 0.9752646088600159,
            "relevance": 3
          },
          {
            "score": 0.969099760055542,
            "relevance": 5
          },
          {
            "score": 0.9689318537712097,
            "relevance": 1
          },
          {
            "score": 0.9637622833251953,
            "relevance": 2
          },
          {
            "score": 0.9577279090881348,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.2749615933369961
        }
      }
    },
    "thresh_0.090_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8015514612197876,
            "relevance": 1
          },
          {
            "score": 0.8014587163925171,
            "relevance": 3
          },
          {
            "score": 0.8011890649795532,
            "relevance": 2
          },
          {
            "score": 0.8004627227783203,
            "relevance": 5
          },
          {
            "score": 0.8004512190818787,
            "relevance": 2
          },
          {
            "score": 0.7998021841049194,
            "relevance": 5
          },
          {
            "score": 0.7977893352508545,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.11912932425718949
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9951131343841553,
            "relevance": 2
          },
          {
            "score": 0.9915375113487244,
            "relevance": 3
          },
          {
            "score": 0.9902760982513428,
            "relevance": 4
          },
          {
            "score": 0.9894657731056213,
            "relevance": 1
          },
          {
            "score": 0.9831210374832153,
            "relevance": 5
          },
          {
            "score": 0.9812654256820679,
            "relevance": 2
          },
          {
            "score": 0.9759894609451294,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.2569206137583197
        }
      }
    },
    "thresh_0.100_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8015514612197876,
            "relevance": 1
          },
          {
            "score": 0.8014587163925171,
            "relevance": 3
          },
          {
            "score": 0.8011890649795532,
            "relevance": 2
          },
          {
            "score": 0.8004627227783203,
            "relevance": 5
          },
          {
            "score": 0.8004512190818787,
            "relevance": 2
          },
          {
            "score": 0.7998021841049194,
            "relevance": 5
          },
          {
            "score": 0.7977893352508545,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.11912932425718949
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7960970997810364,
            "relevance": 4
          },
          {
            "score": 0.7835661172866821,
            "relevance": 2
          },
          {
            "score": 0.7692660689353943,
            "relevance": 5
          },
          {
            "score": 0.7656035423278809,
            "relevance": 3
          },
          {
            "score": 0.749348521232605,
            "relevance": 2
          },
          {
            "score": 0.7438820600509644,
            "relevance": 1
          },
          {
            "score": 0.7405328154563904,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5579305253465247
        }
      }
    },
    "thresh_0.100_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8015514612197876,
            "relevance": 1
          },
          {
            "score": 0.8014587163925171,
            "relevance": 3
          },
          {
            "score": 0.8011890649795532,
            "relevance": 2
          },
          {
            "score": 0.8004627227783203,
            "relevance": 5
          },
          {
            "score": 0.8004512190818787,
            "relevance": 2
          },
          {
            "score": 0.7998021841049194,
            "relevance": 5
          },
          {
            "score": 0.7977893352508545,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.11912932425718949
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9664996266365051,
            "relevance": 4
          },
          {
            "score": 0.9632729291915894,
            "relevance": 2
          },
          {
            "score": 0.9523295164108276,
            "relevance": 3
          },
          {
            "score": 0.9501829743385315,
            "relevance": 5
          },
          {
            "score": 0.9390305280685425,
            "relevance": 1
          },
          {
            "score": 0.9388132095336914,
            "relevance": 2
          },
          {
            "score": 0.9315529465675354,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.3512435910948293
        }
      }
    },
    "thresh_0.100_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8015514612197876,
            "relevance": 1
          },
          {
            "score": 0.8014587163925171,
            "relevance": 3
          },
          {
            "score": 0.8011890649795532,
            "relevance": 2
          },
          {
            "score": 0.8004627227783203,
            "relevance": 5
          },
          {
            "score": 0.8004512190818787,
            "relevance": 2
          },
          {
            "score": 0.7998021841049194,
            "relevance": 5
          },
          {
            "score": 0.7977893352508545,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.11912932425718949
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9962384700775146,
            "relevance": 2
          },
          {
            "score": 0.9947691559791565,
            "relevance": 4
          },
          {
            "score": 0.9894534349441528,
            "relevance": 3
          },
          {
            "score": 0.9838220477104187,
            "relevance": 5
          },
          {
            "score": 0.9821898937225342,
            "relevance": 1
          },
          {
            "score": 0.9777498245239258,
            "relevance": 2
          },
          {
            "score": 0.9715773463249207,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.2749615933369961
        }
      }
    },
    "thresh_0.100_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8015514612197876,
            "relevance": 1
          },
          {
            "score": 0.8014587163925171,
            "relevance": 3
          },
          {
            "score": 0.8011890649795532,
            "relevance": 2
          },
          {
            "score": 0.8004627227783203,
            "relevance": 5
          },
          {
            "score": 0.8004512190818787,
            "relevance": 2
          },
          {
            "score": 0.7998021841049194,
            "relevance": 5
          },
          {
            "score": 0.7977893352508545,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.11912932425718949
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0114628076553345,
            "relevance": 2
          },
          {
            "score": 1.0076297521591187,
            "relevance": 3
          },
          {
            "score": 1.0069198608398438,
            "relevance": 4
          },
          {
            "score": 1.0050536394119263,
            "relevance": 1
          },
          {
            "score": 0.9995099902153015,
            "relevance": 5
          },
          {
            "score": 0.9972825050354004,
            "relevance": 2
          },
          {
            "score": 0.9919450879096985,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.2569206137583197
        }
      }
    },
    "thresh_0.110_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8015514612197876,
            "relevance": 1
          },
          {
            "score": 0.8014587163925171,
            "relevance": 3
          },
          {
            "score": 0.8011890649795532,
            "relevance": 2
          },
          {
            "score": 0.8004627227783203,
            "relevance": 5
          },
          {
            "score": 0.8004512190818787,
            "relevance": 2
          },
          {
            "score": 0.7998021841049194,
            "relevance": 5
          },
          {
            "score": 0.7977893352508545,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.11912932425718949
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8039904236793518,
            "relevance": 4
          },
          {
            "score": 0.790777325630188,
            "relevance": 2
          },
          {
            "score": 0.776497483253479,
            "relevance": 5
          },
          {
            "score": 0.7723240852355957,
            "relevance": 3
          },
          {
            "score": 0.7559385299682617,
            "relevance": 2
          },
          {
            "score": 0.7499083280563354,
            "relevance": 1
          },
          {
            "score": 0.7470343112945557,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5579305253465247
        }
      }
    },
    "thresh_0.110_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8015514612197876,
            "relevance": 1
          },
          {
            "score": 0.8014587163925171,
            "relevance": 3
          },
          {
            "score": 0.8011890649795532,
            "relevance": 2
          },
          {
            "score": 0.8004627227783203,
            "relevance": 5
          },
          {
            "score": 0.8004512190818787,
            "relevance": 2
          },
          {
            "score": 0.7998021841049194,
            "relevance": 5
          },
          {
            "score": 0.7977893352508545,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.11912932425718949
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9791223406791687,
            "relevance": 4
          },
          {
            "score": 0.9749372005462646,
            "relevance": 2
          },
          {
            "score": 0.9631743431091309,
            "relevance": 3
          },
          {
            "score": 0.9618196487426758,
            "relevance": 5
          },
          {
            "score": 0.949360728263855,
            "relevance": 2
          },
          {
            "score": 0.9485725164413452,
            "relevance": 1
          },
          {
            "score": 0.9419052600860596,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.3512435910948293
        }
      }
    },
    "thresh_0.110_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8015514612197876,
            "relevance": 1
          },
          {
            "score": 0.8014587163925171,
            "relevance": 3
          },
          {
            "score": 0.8011890649795532,
            "relevance": 2
          },
          {
            "score": 0.8004627227783203,
            "relevance": 5
          },
          {
            "score": 0.8004512190818787,
            "relevance": 2
          },
          {
            "score": 0.7998021841049194,
            "relevance": 5
          },
          {
            "score": 0.7977893352508545,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.11912932425718949
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0104668140411377,
            "relevance": 2
          },
          {
            "score": 1.0096797943115234,
            "relevance": 4
          },
          {
            "score": 1.003077507019043,
            "relevance": 3
          },
          {
            "score": 0.9980597496032715,
            "relevance": 5
          },
          {
            "score": 0.9947682619094849,
            "relevance": 1
          },
          {
            "score": 0.9911611080169678,
            "relevance": 2
          },
          {
            "score": 0.9848413467407227,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.2749615933369961
        }
      }
    },
    "thresh_0.110_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8015514612197876,
            "relevance": 1
          },
          {
            "score": 0.8014587163925171,
            "relevance": 3
          },
          {
            "score": 0.8011890649795532,
            "relevance": 2
          },
          {
            "score": 0.8004627227783203,
            "relevance": 5
          },
          {
            "score": 0.8004512190818787,
            "relevance": 2
          },
          {
            "score": 0.7998021841049194,
            "relevance": 5
          },
          {
            "score": 0.7977893352508545,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.11912932425718949
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0274856090545654,
            "relevance": 2
          },
          {
            "score": 1.0233513116836548,
            "relevance": 3
          },
          {
            "score": 1.0232937335968018,
            "relevance": 4
          },
          {
            "score": 1.0201812982559204,
            "relevance": 1
          },
          {
            "score": 1.0155903100967407,
            "relevance": 5
          },
          {
            "score": 1.0129261016845703,
            "relevance": 2
          },
          {
            "score": 1.0075223445892334,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.2569206137583197
        }
      }
    },
    "thresh_0.120_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8015514612197876,
            "relevance": 1
          },
          {
            "score": 0.8014587163925171,
            "relevance": 3
          },
          {
            "score": 0.8011890649795532,
            "relevance": 2
          },
          {
            "score": 0.8004627227783203,
            "relevance": 5
          },
          {
            "score": 0.8004512190818787,
            "relevance": 2
          },
          {
            "score": 0.7998021841049194,
            "relevance": 5
          },
          {
            "score": 0.7977893352508545,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.11912932425718949
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.811375617980957,
            "relevance": 4
          },
          {
            "score": 0.7974632978439331,
            "relevance": 2
          },
          {
            "score": 0.7832286357879639,
            "relevance": 5
          },
          {
            "score": 0.778522253036499,
            "relevance": 3
          },
          {
            "score": 0.7620264291763306,
            "relevance": 2
          },
          {
            "score": 0.7554115056991577,
            "relevance": 1
          },
          {
            "score": 0.7530440092086792,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5579305253465247
        }
      }
    },
    "thresh_0.120_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8015514612197876,
            "relevance": 1
          },
          {
            "score": 0.8014587163925171,
            "relevance": 3
          },
          {
            "score": 0.8011890649795532,
            "relevance": 2
          },
          {
            "score": 0.8004627227783203,
            "relevance": 5
          },
          {
            "score": 0.8004512190818787,
            "relevance": 2
          },
          {
            "score": 0.7998021841049194,
            "relevance": 5
          },
          {
            "score": 0.7977893352508545,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.11912932425718949
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9911154508590698,
            "relevance": 4
          },
          {
            "score": 0.9858825206756592,
            "relevance": 2
          },
          {
            "score": 0.9732352495193481,
            "relevance": 3
          },
          {
            "score": 0.9727510213851929,
            "relevance": 5
          },
          {
            "score": 0.9591145515441895,
            "relevance": 2
          },
          {
            "score": 0.9572279453277588,
            "relevance": 1
          },
          {
            "score": 0.9514561891555786,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.3512435910948293
        }
      }
    },
    "thresh_0.120_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8015514612197876,
            "relevance": 1
          },
          {
            "score": 0.8014587163925171,
            "relevance": 3
          },
          {
            "score": 0.8011890649795532,
            "relevance": 2
          },
          {
            "score": 0.8004627227783203,
            "relevance": 5
          },
          {
            "score": 0.8004512190818787,
            "relevance": 2
          },
          {
            "score": 0.7998021841049194,
            "relevance": 5
          },
          {
            "score": 0.7977893352508545,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.11912932425718949
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0241124629974365,
            "relevance": 2
          },
          {
            "score": 1.024099349975586,
            "relevance": 4
          },
          {
            "score": 1.0160448551177979,
            "relevance": 3
          },
          {
            "score": 1.0117274522781372,
            "relevance": 5
          },
          {
            "score": 1.006561040878296,
            "relevance": 1
          },
          {
            "score": 1.0038996934890747,
            "relevance": 2
          },
          {
            "score": 0.997420072555542,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.2749615933369961
        }
      }
    },
    "thresh_0.120_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8015514612197876,
            "relevance": 1
          },
          {
            "score": 0.8014587163925171,
            "relevance": 3
          },
          {
            "score": 0.8011890649795532,
            "relevance": 2
          },
          {
            "score": 0.8004627227783203,
            "relevance": 5
          },
          {
            "score": 0.8004512190818787,
            "relevance": 2
          },
          {
            "score": 0.7998021841049194,
            "relevance": 5
          },
          {
            "score": 0.7977893352508545,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.11912932425718949
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0431114435195923,
            "relevance": 2
          },
          {
            "score": 1.0393364429473877,
            "relevance": 4
          },
          {
            "score": 1.0386230945587158,
            "relevance": 3
          },
          {
            "score": 1.034753441810608,
            "relevance": 1
          },
          {
            "score": 1.0312902927398682,
            "relevance": 5
          },
          {
            "score": 1.0281113386154175,
            "relevance": 2
          },
          {
            "score": 1.0226337909698486,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.2749615933369961
        }
      }
    },
    "thresh_0.130_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8015514612197876,
            "relevance": 1
          },
          {
            "score": 0.8014587163925171,
            "relevance": 3
          },
          {
            "score": 0.8011890649795532,
            "relevance": 2
          },
          {
            "score": 0.8004627227783203,
            "relevance": 5
          },
          {
            "score": 0.8004512190818787,
            "relevance": 2
          },
          {
            "score": 0.7998021841049194,
            "relevance": 5
          },
          {
            "score": 0.7977893352508545,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.11912932425718949
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8182103633880615,
            "relevance": 4
          },
          {
            "score": 0.8035835027694702,
            "relevance": 2
          },
          {
            "score": 0.7894173860549927,
            "relevance": 5
          },
          {
            "score": 0.7841582298278809,
            "relevance": 3
          },
          {
            "score": 0.7675715684890747,
            "relevance": 2
          },
          {
            "score": 0.7603533267974854,
            "relevance": 1
          },
          {
            "score": 0.7585214972496033,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5579305253465247
        }
      }
    },
    "thresh_0.130_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8015514612197876,
            "relevance": 1
          },
          {
            "score": 0.8014587163925171,
            "relevance": 3
          },
          {
            "score": 0.8011890649795532,
            "relevance": 2
          },
          {
            "score": 0.8004627227783203,
            "relevance": 5
          },
          {
            "score": 0.8004512190818787,
            "relevance": 2
          },
          {
            "score": 0.7998021841049194,
            "relevance": 5
          },
          {
            "score": 0.7977893352508545,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.11912932425718949
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.002402424812317,
            "relevance": 4
          },
          {
            "score": 0.9960269927978516,
            "relevance": 2
          },
          {
            "score": 0.9828938245773315,
            "relevance": 5
          },
          {
            "score": 0.9824265241622925,
            "relevance": 3
          },
          {
            "score": 0.9679858684539795,
            "relevance": 2
          },
          {
            "score": 0.9649057388305664,
            "relevance": 1
          },
          {
            "score": 0.9601152539253235,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5579305253465247
        }
      }
    },
    "thresh_0.130_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8015514612197876,
            "relevance": 1
          },
          {
            "score": 0.8014587163925171,
            "relevance": 3
          },
          {
            "score": 0.8011890649795532,
            "relevance": 2
          },
          {
            "score": 0.8004627227783203,
            "relevance": 5
          },
          {
            "score": 0.8004512190818787,
            "relevance": 2
          },
          {
            "score": 0.7998021841049194,
            "relevance": 5
          },
          {
            "score": 0.7977893352508545,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.11912932425718949
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0379513502120972,
            "relevance": 4
          },
          {
            "score": 1.0370885133743286,
            "relevance": 2
          },
          {
            "score": 1.0282593965530396,
            "relevance": 3
          },
          {
            "score": 1.024735450744629,
            "relevance": 5
          },
          {
            "score": 1.0174578428268433,
            "relevance": 1
          },
          {
            "score": 1.0158637762069702,
            "relevance": 2
          },
          {
            "score": 1.009209394454956,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.3512435910948293
        }
      }
    },
    "thresh_0.130_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8015514612197876,
            "relevance": 1
          },
          {
            "score": 0.8014587163925171,
            "relevance": 3
          },
          {
            "score": 0.8011890649795532,
            "relevance": 2
          },
          {
            "score": 0.8004627227783203,
            "relevance": 5
          },
          {
            "score": 0.8004512190818787,
            "relevance": 2
          },
          {
            "score": 0.7998021841049194,
            "relevance": 5
          },
          {
            "score": 0.7977893352508545,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.11912932425718949
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0582669973373413,
            "relevance": 2
          },
          {
            "score": 1.0549839735031128,
            "relevance": 4
          },
          {
            "score": 1.0533607006072998,
            "relevance": 3
          },
          {
            "score": 1.048667073249817,
            "relevance": 1
          },
          {
            "score": 1.0465335845947266,
            "relevance": 5
          },
          {
            "score": 1.042747974395752,
            "relevance": 2
          },
          {
            "score": 1.037184715270996,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.2749615933369961
        }
      }
    }
  },
  "P09": {
    "thresh_0.090_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8487545251846313,
            "relevance": 3
          },
          {
            "score": 0.8475731611251831,
            "relevance": 5
          },
          {
            "score": 0.8468641042709351,
            "relevance": 5
          },
          {
            "score": 0.8465965986251831,
            "relevance": 4
          },
          {
            "score": 0.8457452058792114,
            "relevance": 1
          },
          {
            "score": 0.8455476760864258,
            "relevance": 2
          },
          {
            "score": 0.84315025806427,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7244174209977395
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.48249849677085876,
            "relevance": 5
          },
          {
            "score": 0.47614431381225586,
            "relevance": 1
          },
          {
            "score": 0.4682559370994568,
            "relevance": 2
          },
          {
            "score": 0.459420770406723,
            "relevance": 3
          },
          {
            "score": 0.4521707594394684,
            "relevance": 5
          },
          {
            "score": 0.4508460760116577,
            "relevance": 2
          },
          {
            "score": 0.4455215036869049,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5706441916394969
        }
      }
    },
    "thresh_0.090_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8487545251846313,
            "relevance": 3
          },
          {
            "score": 0.8475731611251831,
            "relevance": 5
          },
          {
            "score": 0.8468641042709351,
            "relevance": 5
          },
          {
            "score": 0.8465965986251831,
            "relevance": 4
          },
          {
            "score": 0.8457452058792114,
            "relevance": 1
          },
          {
            "score": 0.8455476760864258,
            "relevance": 2
          },
          {
            "score": 0.84315025806427,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7244174209977395
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6491177082061768,
            "relevance": 5
          },
          {
            "score": 0.638572633266449,
            "relevance": 1
          },
          {
            "score": 0.627648651599884,
            "relevance": 2
          },
          {
            "score": 0.6040695905685425,
            "relevance": 3
          },
          {
            "score": 0.6005793809890747,
            "relevance": 5
          },
          {
            "score": 0.583855152130127,
            "relevance": 4
          },
          {
            "score": 0.5822364687919617,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5706441916394969
        }
      }
    },
    "thresh_0.090_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8487545251846313,
            "relevance": 3
          },
          {
            "score": 0.8475731611251831,
            "relevance": 5
          },
          {
            "score": 0.8468641042709351,
            "relevance": 5
          },
          {
            "score": 0.8465965986251831,
            "relevance": 4
          },
          {
            "score": 0.8457452058792114,
            "relevance": 1
          },
          {
            "score": 0.8455476760864258,
            "relevance": 2
          },
          {
            "score": 0.84315025806427,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7244174209977395
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7292153835296631,
            "relevance": 5
          },
          {
            "score": 0.7178390622138977,
            "relevance": 1
          },
          {
            "score": 0.70623379945755,
            "relevance": 2
          },
          {
            "score": 0.6785352230072021,
            "relevance": 3
          },
          {
            "score": 0.6762117147445679,
            "relevance": 5
          },
          {
            "score": 0.6562038660049438,
            "relevance": 4
          },
          {
            "score": 0.6520503163337708,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5706441916394969
        }
      }
    },
    "thresh_0.090_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8487545251846313,
            "relevance": 3
          },
          {
            "score": 0.8475731611251831,
            "relevance": 5
          },
          {
            "score": 0.8468641042709351,
            "relevance": 5
          },
          {
            "score": 0.8465965986251831,
            "relevance": 4
          },
          {
            "score": 0.8457452058792114,
            "relevance": 1
          },
          {
            "score": 0.8455476760864258,
            "relevance": 2
          },
          {
            "score": 0.84315025806427,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7244174209977395
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8121579885482788,
            "relevance": 5
          },
          {
            "score": 0.8012307286262512,
            "relevance": 1
          },
          {
            "score": 0.7898116707801819,
            "relevance": 2
          },
          {
            "score": 0.7615242004394531,
            "relevance": 3
          },
          {
            "score": 0.7595721483230591,
            "relevance": 5
          },
          {
            "score": 0.7382553815841675,
            "relevance": 4
          },
          {
            "score": 0.7326435446739197,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5706441916394969
        }
      }
    },
    "thresh_0.100_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8487545251846313,
            "relevance": 3
          },
          {
            "score": 0.8475731611251831,
            "relevance": 5
          },
          {
            "score": 0.8468641042709351,
            "relevance": 5
          },
          {
            "score": 0.8465965986251831,
            "relevance": 4
          },
          {
            "score": 0.8457452058792114,
            "relevance": 1
          },
          {
            "score": 0.8455476760864258,
            "relevance": 2
          },
          {
            "score": 0.84315025806427,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7244174209977395
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.4836936891078949,
            "relevance": 5
          },
          {
            "score": 0.47724756598472595,
            "relevance": 1
          },
          {
            "score": 0.4693080484867096,
            "relevance": 2
          },
          {
            "score": 0.4601718485355377,
            "relevance": 3
          },
          {
            "score": 0.45302653312683105,
            "relevance": 5
          },
          {
            "score": 0.45137152075767517,
            "relevance": 2
          },
          {
            "score": 0.4462028741836548,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5706441916394969
        }
      }
    },
    "thresh_0.100_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8487545251846313,
            "relevance": 3
          },
          {
            "score": 0.8475731611251831,
            "relevance": 5
          },
          {
            "score": 0.8468641042709351,
            "relevance": 5
          },
          {
            "score": 0.8465965986251831,
            "relevance": 4
          },
          {
            "score": 0.8457452058792114,
            "relevance": 1
          },
          {
            "score": 0.8455476760864258,
            "relevance": 2
          },
          {
            "score": 0.84315025806427,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7244174209977395
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6402286291122437,
            "relevance": 5
          },
          {
            "score": 0.6291247606277466,
            "relevance": 1
          },
          {
            "score": 0.6178270578384399,
            "relevance": 2
          },
          {
            "score": 0.5925450325012207,
            "relevance": 3
          },
          {
            "score": 0.589493453502655,
            "relevance": 5
          },
          {
            "score": 0.5717322826385498,
            "relevance": 4
          },
          {
            "score": 0.5694200992584229,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5706441916394969
        }
      }
    },
    "thresh_0.100_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8487545251846313,
            "relevance": 3
          },
          {
            "score": 0.8475731611251831,
            "relevance": 5
          },
          {
            "score": 0.8468641042709351,
            "relevance": 5
          },
          {
            "score": 0.8465965986251831,
            "relevance": 4
          },
          {
            "score": 0.8457452058792114,
            "relevance": 1
          },
          {
            "score": 0.8455476760864258,
            "relevance": 2
          },
          {
            "score": 0.84315025806427,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7244174209977395
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.718116044998169,
            "relevance": 5
          },
          {
            "score": 0.7057662010192871,
            "relevance": 1
          },
          {
            "score": 0.6934925317764282,
            "relevance": 2
          },
          {
            "score": 0.6627297401428223,
            "relevance": 3
          },
          {
            "score": 0.6611809134483337,
            "relevance": 5
          },
          {
            "score": 0.6392537355422974,
            "relevance": 4
          },
          {
            "score": 0.6338316202163696,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5706441916394969
        }
      }
    },
    "thresh_0.100_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8487545251846313,
            "relevance": 3
          },
          {
            "score": 0.8475731611251831,
            "relevance": 5
          },
          {
            "score": 0.8468641042709351,
            "relevance": 5
          },
          {
            "score": 0.8465965986251831,
            "relevance": 4
          },
          {
            "score": 0.8457452058792114,
            "relevance": 1
          },
          {
            "score": 0.8455476760864258,
            "relevance": 2
          },
          {
            "score": 0.84315025806427,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7244174209977395
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8017680644989014,
            "relevance": 5
          },
          {
            "score": 0.7893390655517578,
            "relevance": 1
          },
          {
            "score": 0.7768616676330566,
            "relevance": 2
          },
          {
            "score": 0.7435554265975952,
            "relevance": 3
          },
          {
            "score": 0.7428831458091736,
            "relevance": 5
          },
          {
            "score": 0.7182890176773071,
            "relevance": 4
          },
          {
            "score": 0.7104709148406982,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5706441916394969
        }
      }
    },
    "thresh_0.110_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8487545251846313,
            "relevance": 3
          },
          {
            "score": 0.8475731611251831,
            "relevance": 5
          },
          {
            "score": 0.8468641042709351,
            "relevance": 5
          },
          {
            "score": 0.8465965986251831,
            "relevance": 4
          },
          {
            "score": 0.8457452058792114,
            "relevance": 1
          },
          {
            "score": 0.8455476760864258,
            "relevance": 2
          },
          {
            "score": 0.84315025806427,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7244174209977395
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.4845981001853943,
            "relevance": 5
          },
          {
            "score": 0.47806689143180847,
            "relevance": 1
          },
          {
            "score": 0.47008854150772095,
            "relevance": 2
          },
          {
            "score": 0.4606485068798065,
            "relevance": 3
          },
          {
            "score": 0.45362964272499084,
            "relevance": 5
          },
          {
            "score": 0.45162391662597656,
            "relevance": 2
          },
          {
            "score": 0.44663238525390625,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5706441916394969
        }
      }
    },
    "thresh_0.110_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8487545251846313,
            "relevance": 3
          },
          {
            "score": 0.8475731611251831,
            "relevance": 5
          },
          {
            "score": 0.8468641042709351,
            "relevance": 5
          },
          {
            "score": 0.8465965986251831,
            "relevance": 4
          },
          {
            "score": 0.8457452058792114,
            "relevance": 1
          },
          {
            "score": 0.8455476760864258,
            "relevance": 2
          },
          {
            "score": 0.84315025806427,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7244174209977395
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6299673914909363,
            "relevance": 5
          },
          {
            "score": 0.6183241605758667,
            "relevance": 1
          },
          {
            "score": 0.6066759824752808,
            "relevance": 2
          },
          {
            "score": 0.579753041267395,
            "relevance": 3
          },
          {
            "score": 0.5771434307098389,
            "relevance": 5
          },
          {
            "score": 0.5583988428115845,
            "relevance": 4
          },
          {
            "score": 0.5554123520851135,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5706441916394969
        }
      }
    },
    "thresh_0.110_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8487545251846313,
            "relevance": 3
          },
          {
            "score": 0.8475731611251831,
            "relevance": 5
          },
          {
            "score": 0.8468641042709351,
            "relevance": 5
          },
          {
            "score": 0.8465965986251831,
            "relevance": 4
          },
          {
            "score": 0.8457452058792114,
            "relevance": 1
          },
          {
            "score": 0.8455476760864258,
            "relevance": 2
          },
          {
            "score": 0.84315025806427,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7244174209977395
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7046621441841125,
            "relevance": 5
          },
          {
            "score": 0.6913374662399292,
            "relevance": 1
          },
          {
            "score": 0.6784065961837769,
            "relevance": 2
          },
          {
            "score": 0.6446154117584229,
            "relevance": 3
          },
          {
            "score": 0.6438462734222412,
            "relevance": 5
          },
          {
            "score": 0.6200543642044067,
            "relevance": 4
          },
          {
            "score": 0.6133962869644165,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5706441916394969
        }
      }
    },
    "thresh_0.110_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8487545251846313,
            "relevance": 3
          },
          {
            "score": 0.8475731611251831,
            "relevance": 5
          },
          {
            "score": 0.8468641042709351,
            "relevance": 5
          },
          {
            "score": 0.8465965986251831,
            "relevance": 4
          },
          {
            "score": 0.8457452058792114,
            "relevance": 1
          },
          {
            "score": 0.8455476760864258,
            "relevance": 2
          },
          {
            "score": 0.84315025806427,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7244174209977395
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7877333760261536,
            "relevance": 5
          },
          {
            "score": 0.7737151384353638,
            "relevance": 1
          },
          {
            "score": 0.7601323127746582,
            "relevance": 2
          },
          {
            "score": 0.7222796678543091,
            "relevance": 5
          },
          {
            "score": 0.7216194868087769,
            "relevance": 3
          },
          {
            "score": 0.6943496465682983,
            "relevance": 4
          },
          {
            "score": 0.6843069791793823,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5706441916394969
        }
      }
    },
    "thresh_0.120_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8487545251846313,
            "relevance": 3
          },
          {
            "score": 0.8475731611251831,
            "relevance": 5
          },
          {
            "score": 0.8468641042709351,
            "relevance": 5
          },
          {
            "score": 0.8465965986251831,
            "relevance": 4
          },
          {
            "score": 0.8457452058792114,
            "relevance": 1
          },
          {
            "score": 0.8455476760864258,
            "relevance": 2
          },
          {
            "score": 0.84315025806427,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7244174209977395
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.4851868152618408,
            "relevance": 5
          },
          {
            "score": 0.4785776734352112,
            "relevance": 1
          },
          {
            "score": 0.47057345509529114,
            "relevance": 2
          },
          {
            "score": 0.4608282148838043,
            "relevance": 3
          },
          {
            "score": 0.4539569318294525,
            "relevance": 5
          },
          {
            "score": 0.4515822231769562,
            "relevance": 2
          },
          {
            "score": 0.44678762555122375,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5706441916394969
        }
      }
    },
    "thresh_0.120_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8487545251846313,
            "relevance": 3
          },
          {
            "score": 0.8475731611251831,
            "relevance": 5
          },
          {
            "score": 0.8468641042709351,
            "relevance": 5
          },
          {
            "score": 0.8465965986251831,
            "relevance": 4
          },
          {
            "score": 0.8457452058792114,
            "relevance": 1
          },
          {
            "score": 0.8455476760864258,
            "relevance": 2
          },
          {
            "score": 0.84315025806427,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7244174209977395
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6183430552482605,
            "relevance": 5
          },
          {
            "score": 0.6061875224113464,
            "relevance": 1
          },
          {
            "score": 0.5942171812057495,
            "relevance": 2
          },
          {
            "score": 0.5657401084899902,
            "relevance": 3
          },
          {
            "score": 0.563569188117981,
            "relevance": 5
          },
          {
            "score": 0.5439096689224243,
            "relevance": 4
          },
          {
            "score": 0.5402795076370239,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5706441916394969
        }
      }
    },
    "thresh_0.120_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8487545251846313,
            "relevance": 3
          },
          {
            "score": 0.8475731611251831,
            "relevance": 5
          },
          {
            "score": 0.8468641042709351,
            "relevance": 5
          },
          {
            "score": 0.8465965986251831,
            "relevance": 4
          },
          {
            "score": 0.8457452058792114,
            "relevance": 1
          },
          {
            "score": 0.8455476760864258,
            "relevance": 2
          },
          {
            "score": 0.84315025806427,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7244174209977395
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6888208985328674,
            "relevance": 5
          },
          {
            "score": 0.6745375990867615,
            "relevance": 1
          },
          {
            "score": 0.660973310470581,
            "relevance": 2
          },
          {
            "score": 0.6242520809173584,
            "relevance": 3
          },
          {
            "score": 0.6242517232894897,
            "relevance": 5
          },
          {
            "score": 0.5986915826797485,
            "relevance": 4
          },
          {
            "score": 0.5908583402633667,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5706441916394969
        }
      }
    },
    "thresh_0.120_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8487545251846313,
            "relevance": 3
          },
          {
            "score": 0.8475731611251831,
            "relevance": 5
          },
          {
            "score": 0.8468641042709351,
            "relevance": 5
          },
          {
            "score": 0.8465965986251831,
            "relevance": 4
          },
          {
            "score": 0.8457452058792114,
            "relevance": 1
          },
          {
            "score": 0.8455476760864258,
            "relevance": 2
          },
          {
            "score": 0.84315025806427,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7244174209977395
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7698258757591248,
            "relevance": 5
          },
          {
            "score": 0.754159152507782,
            "relevance": 1
          },
          {
            "score": 0.7394466400146484,
            "relevance": 2
          },
          {
            "score": 0.6976767778396606,
            "relevance": 5
          },
          {
            "score": 0.6956658363342285,
            "relevance": 3
          },
          {
            "score": 0.6664475202560425,
            "relevance": 4
          },
          {
            "score": 0.6542329788208008,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5706441916394969
        }
      }
    },
    "thresh_0.130_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8487545251846313,
            "relevance": 3
          },
          {
            "score": 0.8475731611251831,
            "relevance": 5
          },
          {
            "score": 0.8468641042709351,
            "relevance": 5
          },
          {
            "score": 0.8465965986251831,
            "relevance": 4
          },
          {
            "score": 0.8457452058792114,
            "relevance": 1
          },
          {
            "score": 0.8455476760864258,
            "relevance": 2
          },
          {
            "score": 0.84315025806427,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7244174209977395
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.485437273979187,
            "relevance": 5
          },
          {
            "score": 0.47875791788101196,
            "relevance": 1
          },
          {
            "score": 0.4707403779029846,
            "relevance": 2
          },
          {
            "score": 0.4606904983520508,
            "relevance": 3
          },
          {
            "score": 0.45398667454719543,
            "relevance": 5
          },
          {
            "score": 0.45122748613357544,
            "relevance": 2
          },
          {
            "score": 0.44664809107780457,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5706441916394969
        }
      }
    },
    "thresh_0.130_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8487545251846313,
            "relevance": 3
          },
          {
            "score": 0.8475731611251831,
            "relevance": 5
          },
          {
            "score": 0.8468641042709351,
            "relevance": 5
          },
          {
            "score": 0.8465965986251831,
            "relevance": 4
          },
          {
            "score": 0.8457452058792114,
            "relevance": 1
          },
          {
            "score": 0.8455476760864258,
            "relevance": 2
          },
          {
            "score": 0.84315025806427,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7244174209977395
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6053842306137085,
            "relevance": 5
          },
          {
            "score": 0.5927508473396301,
            "relevance": 1
          },
          {
            "score": 0.5804915428161621,
            "relevance": 2
          },
          {
            "score": 0.5505715608596802,
            "relevance": 3
          },
          {
            "score": 0.5488297939300537,
            "relevance": 5
          },
          {
            "score": 0.5283389091491699,
            "relevance": 4
          },
          {
            "score": 0.5241050124168396,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5706441916394969
        }
      }
    },
    "thresh_0.130_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8487545251846313,
            "relevance": 3
          },
          {
            "score": 0.8475731611251831,
            "relevance": 5
          },
          {
            "score": 0.8468641042709351,
            "relevance": 5
          },
          {
            "score": 0.8465965986251831,
            "relevance": 4
          },
          {
            "score": 0.8457452058792114,
            "relevance": 1
          },
          {
            "score": 0.8455476760864258,
            "relevance": 2
          },
          {
            "score": 0.84315025806427,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7244174209977395
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.6706035137176514,
            "relevance": 5
          },
          {
            "score": 0.6553974747657776,
            "relevance": 1
          },
          {
            "score": 0.6412370800971985,
            "relevance": 2
          },
          {
            "score": 0.602491021156311,
            "relevance": 5
          },
          {
            "score": 0.6017507314682007,
            "relevance": 3
          },
          {
            "score": 0.5753027200698853,
            "relevance": 4
          },
          {
            "score": 0.5663843154907227,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5706441916394969
        }
      }
    },
    "thresh_0.130_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8487545251846313,
            "relevance": 3
          },
          {
            "score": 0.8475731611251831,
            "relevance": 5
          },
          {
            "score": 0.8468641042709351,
            "relevance": 5
          },
          {
            "score": 0.8465965986251831,
            "relevance": 4
          },
          {
            "score": 0.8457452058792114,
            "relevance": 1
          },
          {
            "score": 0.8455476760864258,
            "relevance": 2
          },
          {
            "score": 0.84315025806427,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.7244174209977395
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7478924989700317,
            "relevance": 5
          },
          {
            "score": 0.7305567860603333,
            "relevance": 1
          },
          {
            "score": 0.7147193551063538,
            "relevance": 2
          },
          {
            "score": 0.669103741645813,
            "relevance": 5
          },
          {
            "score": 0.6657663583755493,
            "relevance": 3
          },
          {
            "score": 0.6347239017486572,
            "relevance": 4
          },
          {
            "score": 0.6204688549041748,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5706441916394969
        }
      }
    }
  },
  "P10": {
    "thresh_0.090_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8124786019325256,
            "relevance": 5
          },
          {
            "score": 0.8113181591033936,
            "relevance": 2
          },
          {
            "score": 0.81078040599823,
            "relevance": 1
          },
          {
            "score": 0.8104808926582336,
            "relevance": 2
          },
          {
            "score": 0.8096487522125244,
            "relevance": 3
          },
          {
            "score": 0.8096141219139099,
            "relevance": 5
          },
          {
            "score": 0.8092257976531982,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5751544365341659
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7105985879898071,
            "relevance": 4
          },
          {
            "score": 0.6939760446548462,
            "relevance": 1
          },
          {
            "score": 0.6770904064178467,
            "relevance": 2
          },
          {
            "score": 0.6681922674179077,
            "relevance": 5
          },
          {
            "score": 0.649420976638794,
            "relevance": 3
          },
          {
            "score": 0.6458129286766052,
            "relevance": 2
          },
          {
            "score": 0.6200985908508301,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.29506161263723635
        }
      }
    },
    "thresh_0.090_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8124786019325256,
            "relevance": 5
          },
          {
            "score": 0.8113181591033936,
            "relevance": 2
          },
          {
            "score": 0.81078040599823,
            "relevance": 1
          },
          {
            "score": 0.8104808926582336,
            "relevance": 2
          },
          {
            "score": 0.8096487522125244,
            "relevance": 3
          },
          {
            "score": 0.8096141219139099,
            "relevance": 5
          },
          {
            "score": 0.8092257976531982,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5751544365341659
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9180352687835693,
            "relevance": 4
          },
          {
            "score": 0.9034349918365479,
            "relevance": 1
          },
          {
            "score": 0.8872332572937012,
            "relevance": 2
          },
          {
            "score": 0.8783760070800781,
            "relevance": 5
          },
          {
            "score": 0.8586770296096802,
            "relevance": 3
          },
          {
            "score": 0.8541484475135803,
            "relevance": 2
          },
          {
            "score": 0.8238790035247803,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.29506161263723635
        }
      }
    },
    "thresh_0.090_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8124786019325256,
            "relevance": 5
          },
          {
            "score": 0.8113181591033936,
            "relevance": 2
          },
          {
            "score": 0.81078040599823,
            "relevance": 1
          },
          {
            "score": 0.8104808926582336,
            "relevance": 2
          },
          {
            "score": 0.8096487522125244,
            "relevance": 3
          },
          {
            "score": 0.8096141219139099,
            "relevance": 5
          },
          {
            "score": 0.8092257976531982,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5751544365341659
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9749294519424438,
            "relevance": 4
          },
          {
            "score": 0.9650198221206665,
            "relevance": 1
          },
          {
            "score": 0.9522842168807983,
            "relevance": 2
          },
          {
            "score": 0.9453107118606567,
            "relevance": 5
          },
          {
            "score": 0.9298015832901001,
            "relevance": 3
          },
          {
            "score": 0.9270405173301697,
            "relevance": 2
          },
          {
            "score": 0.9012293815612793,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.29506161263723635
        }
      }
    },
    "thresh_0.090_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8124786019325256,
            "relevance": 5
          },
          {
            "score": 0.8113181591033936,
            "relevance": 2
          },
          {
            "score": 0.81078040599823,
            "relevance": 1
          },
          {
            "score": 0.8104808926582336,
            "relevance": 2
          },
          {
            "score": 0.8096487522125244,
            "relevance": 3
          },
          {
            "score": 0.8096141219139099,
            "relevance": 5
          },
          {
            "score": 0.8092257976531982,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5751544365341659
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0104990005493164,
            "relevance": 4
          },
          {
            "score": 1.0057344436645508,
            "relevance": 1
          },
          {
            "score": 0.9971483945846558,
            "relevance": 2
          },
          {
            "score": 0.992578387260437,
            "relevance": 5
          },
          {
            "score": 0.9828877449035645,
            "relevance": 3
          },
          {
            "score": 0.9828298687934875,
            "relevance": 2
          },
          {
            "score": 0.9648864269256592,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.29506161263723635
        }
      }
    },
    "thresh_0.100_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8124786019325256,
            "relevance": 5
          },
          {
            "score": 0.8113181591033936,
            "relevance": 2
          },
          {
            "score": 0.81078040599823,
            "relevance": 1
          },
          {
            "score": 0.8104808926582336,
            "relevance": 2
          },
          {
            "score": 0.8096487522125244,
            "relevance": 3
          },
          {
            "score": 0.8096141219139099,
            "relevance": 5
          },
          {
            "score": 0.8092257976531982,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5751544365341659
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7150650024414062,
            "relevance": 4
          },
          {
            "score": 0.697972297668457,
            "relevance": 1
          },
          {
            "score": 0.6807804107666016,
            "relevance": 2
          },
          {
            "score": 0.6717073917388916,
            "relevance": 5
          },
          {
            "score": 0.6525126695632935,
            "relevance": 3
          },
          {
            "score": 0.6486675143241882,
            "relevance": 2
          },
          {
            "score": 0.6224342584609985,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.29506161263723635
        }
      }
    },
    "thresh_0.100_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8124786019325256,
            "relevance": 5
          },
          {
            "score": 0.8113181591033936,
            "relevance": 2
          },
          {
            "score": 0.81078040599823,
            "relevance": 1
          },
          {
            "score": 0.8104808926582336,
            "relevance": 2
          },
          {
            "score": 0.8096487522125244,
            "relevance": 3
          },
          {
            "score": 0.8096141219139099,
            "relevance": 5
          },
          {
            "score": 0.8092257976531982,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5751544365341659
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.92405104637146,
            "relevance": 4
          },
          {
            "score": 0.9080955982208252,
            "relevance": 1
          },
          {
            "score": 0.8908424377441406,
            "relevance": 2
          },
          {
            "score": 0.8813660144805908,
            "relevance": 5
          },
          {
            "score": 0.8601266145706177,
            "relevance": 3
          },
          {
            "score": 0.8548199534416199,
            "relevance": 2
          },
          {
            "score": 0.8223551511764526,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.29506161263723635
        }
      }
    },
    "thresh_0.100_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8124786019325256,
            "relevance": 5
          },
          {
            "score": 0.8113181591033936,
            "relevance": 2
          },
          {
            "score": 0.81078040599823,
            "relevance": 1
          },
          {
            "score": 0.8104808926582336,
            "relevance": 2
          },
          {
            "score": 0.8096487522125244,
            "relevance": 3
          },
          {
            "score": 0.8096141219139099,
            "relevance": 5
          },
          {
            "score": 0.8092257976531982,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5751544365341659
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9842500686645508,
            "relevance": 4
          },
          {
            "score": 0.9729386568069458,
            "relevance": 1
          },
          {
            "score": 0.959052324295044,
            "relevance": 2
          },
          {
            "score": 0.9513763189315796,
            "relevance": 5
          },
          {
            "score": 0.9340450763702393,
            "relevance": 3
          },
          {
            "score": 0.9303340315818787,
            "relevance": 2
          },
          {
            "score": 0.9016579389572144,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.29506161263723635
        }
      }
    },
    "thresh_0.100_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8124786019325256,
            "relevance": 5
          },
          {
            "score": 0.8113181591033936,
            "relevance": 2
          },
          {
            "score": 0.81078040599823,
            "relevance": 1
          },
          {
            "score": 0.8104808926582336,
            "relevance": 2
          },
          {
            "score": 0.8096487522125244,
            "relevance": 3
          },
          {
            "score": 0.8096141219139099,
            "relevance": 5
          },
          {
            "score": 0.8092257976531982,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5751544365341659
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.023392915725708,
            "relevance": 4
          },
          {
            "score": 1.0175446271896362,
            "relevance": 1
          },
          {
            "score": 1.008015751838684,
            "relevance": 2
          },
          {
            "score": 1.0028421878814697,
            "relevance": 5
          },
          {
            "score": 0.991492509841919,
            "relevance": 3
          },
          {
            "score": 0.9905188679695129,
            "relevance": 2
          },
          {
            "score": 0.9696179628372192,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.29506161263723635
        }
      }
    },
    "thresh_0.110_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8124786019325256,
            "relevance": 5
          },
          {
            "score": 0.8113181591033936,
            "relevance": 2
          },
          {
            "score": 0.81078040599823,
            "relevance": 1
          },
          {
            "score": 0.8104808926582336,
            "relevance": 2
          },
          {
            "score": 0.8096487522125244,
            "relevance": 3
          },
          {
            "score": 0.8096141219139099,
            "relevance": 5
          },
          {
            "score": 0.8092257976531982,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5751544365341659
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7189896106719971,
            "relevance": 4
          },
          {
            "score": 0.7014323472976685,
            "relevance": 1
          },
          {
            "score": 0.6839476823806763,
            "relevance": 2
          },
          {
            "score": 0.6747064590454102,
            "relevance": 5
          },
          {
            "score": 0.6551008224487305,
            "relevance": 3
          },
          {
            "score": 0.6510143280029297,
            "relevance": 2
          },
          {
            "score": 0.6242823600769043,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.29506161263723635
        }
      }
    },
    "thresh_0.110_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8124786019325256,
            "relevance": 5
          },
          {
            "score": 0.8113181591033936,
            "relevance": 2
          },
          {
            "score": 0.81078040599823,
            "relevance": 1
          },
          {
            "score": 0.8104808926582336,
            "relevance": 2
          },
          {
            "score": 0.8096487522125244,
            "relevance": 3
          },
          {
            "score": 0.8096141219139099,
            "relevance": 5
          },
          {
            "score": 0.8092257976531982,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5751544365341659
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9289149045944214,
            "relevance": 4
          },
          {
            "score": 0.9115219116210938,
            "relevance": 1
          },
          {
            "score": 0.8931653499603271,
            "relevance": 2
          },
          {
            "score": 0.8830404281616211,
            "relevance": 5
          },
          {
            "score": 0.8601919412612915,
            "relevance": 3
          },
          {
            "score": 0.8540681600570679,
            "relevance": 2
          },
          {
            "score": 0.8193397521972656,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.29506161263723635
        }
      }
    },
    "thresh_0.110_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8124786019325256,
            "relevance": 5
          },
          {
            "score": 0.8113181591033936,
            "relevance": 2
          },
          {
            "score": 0.81078040599823,
            "relevance": 1
          },
          {
            "score": 0.8104808926582336,
            "relevance": 2
          },
          {
            "score": 0.8096487522125244,
            "relevance": 3
          },
          {
            "score": 0.8096141219139099,
            "relevance": 5
          },
          {
            "score": 0.8092257976531982,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5751544365341659
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9923954010009766,
            "relevance": 4
          },
          {
            "score": 0.9795317649841309,
            "relevance": 1
          },
          {
            "score": 0.9643807411193848,
            "relevance": 2
          },
          {
            "score": 0.9559347629547119,
            "relevance": 5
          },
          {
            "score": 0.9366132020950317,
            "relevance": 3
          },
          {
            "score": 0.9318636655807495,
            "relevance": 2
          },
          {
            "score": 0.9000988006591797,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.29506161263723635
        }
      }
    },
    "thresh_0.110_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8124786019325256,
            "relevance": 5
          },
          {
            "score": 0.8113181591033936,
            "relevance": 2
          },
          {
            "score": 0.81078040599823,
            "relevance": 1
          },
          {
            "score": 0.8104808926582336,
            "relevance": 2
          },
          {
            "score": 0.8096487522125244,
            "relevance": 3
          },
          {
            "score": 0.8096141219139099,
            "relevance": 5
          },
          {
            "score": 0.8092257976531982,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5751544365341659
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0353389978408813,
            "relevance": 4
          },
          {
            "score": 1.028225302696228,
            "relevance": 1
          },
          {
            "score": 1.017601490020752,
            "relevance": 2
          },
          {
            "score": 1.011728048324585,
            "relevance": 5
          },
          {
            "score": 0.9984619617462158,
            "relevance": 3
          },
          {
            "score": 0.9964317083358765,
            "relevance": 2
          },
          {
            "score": 0.9721527099609375,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.29506161263723635
        }
      }
    },
    "thresh_0.120_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8124786019325256,
            "relevance": 5
          },
          {
            "score": 0.8113181591033936,
            "relevance": 2
          },
          {
            "score": 0.81078040599823,
            "relevance": 1
          },
          {
            "score": 0.8104808926582336,
            "relevance": 2
          },
          {
            "score": 0.8096487522125244,
            "relevance": 3
          },
          {
            "score": 0.8096141219139099,
            "relevance": 5
          },
          {
            "score": 0.8092257976531982,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5751544365341659
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7223393321037292,
            "relevance": 4
          },
          {
            "score": 0.7043241262435913,
            "relevance": 1
          },
          {
            "score": 0.6865613460540771,
            "relevance": 2
          },
          {
            "score": 0.6771590709686279,
            "relevance": 5
          },
          {
            "score": 0.6571561098098755,
            "relevance": 3
          },
          {
            "score": 0.652825117111206,
            "relevance": 2
          },
          {
            "score": 0.6256169676780701,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.29506161263723635
        }
      }
    },
    "thresh_0.120_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8124786019325256,
            "relevance": 5
          },
          {
            "score": 0.8113181591033936,
            "relevance": 2
          },
          {
            "score": 0.81078040599823,
            "relevance": 1
          },
          {
            "score": 0.8104808926582336,
            "relevance": 2
          },
          {
            "score": 0.8096487522125244,
            "relevance": 3
          },
          {
            "score": 0.8096141219139099,
            "relevance": 5
          },
          {
            "score": 0.8092257976531982,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5751544365341659
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9325321316719055,
            "relevance": 4
          },
          {
            "score": 0.9136204719543457,
            "relevance": 1
          },
          {
            "score": 0.8941103219985962,
            "relevance": 2
          },
          {
            "score": 0.883309006690979,
            "relevance": 5
          },
          {
            "score": 0.8587887287139893,
            "relevance": 3
          },
          {
            "score": 0.8518133163452148,
            "relevance": 2
          },
          {
            "score": 0.814767062664032,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.29506161263723635
        }
      }
    },
    "thresh_0.120_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8124786019325256,
            "relevance": 5
          },
          {
            "score": 0.8113181591033936,
            "relevance": 2
          },
          {
            "score": 0.81078040599823,
            "relevance": 1
          },
          {
            "score": 0.8104808926582336,
            "relevance": 2
          },
          {
            "score": 0.8096487522125244,
            "relevance": 3
          },
          {
            "score": 0.8096141219139099,
            "relevance": 5
          },
          {
            "score": 0.8092257976531982,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5751544365341659
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9992247223854065,
            "relevance": 4
          },
          {
            "score": 0.9846476316452026,
            "relevance": 1
          },
          {
            "score": 0.9681116342544556,
            "relevance": 2
          },
          {
            "score": 0.9588252305984497,
            "relevance": 5
          },
          {
            "score": 0.9373407363891602,
            "relevance": 3
          },
          {
            "score": 0.9314647912979126,
            "relevance": 2
          },
          {
            "score": 0.8963932394981384,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.29506161263723635
        }
      }
    },
    "thresh_0.120_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8124786019325256,
            "relevance": 5
          },
          {
            "score": 0.8113181591033936,
            "relevance": 2
          },
          {
            "score": 0.81078040599823,
            "relevance": 1
          },
          {
            "score": 0.8104808926582336,
            "relevance": 2
          },
          {
            "score": 0.8096487522125244,
            "relevance": 3
          },
          {
            "score": 0.8096141219139099,
            "relevance": 5
          },
          {
            "score": 0.8092257976531982,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5751544365341659
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0461766719818115,
            "relevance": 4
          },
          {
            "score": 1.0375896692276,
            "relevance": 1
          },
          {
            "score": 1.025696039199829,
            "relevance": 2
          },
          {
            "score": 1.0190141201019287,
            "relevance": 5
          },
          {
            "score": 1.0035433769226074,
            "relevance": 3
          },
          {
            "score": 1.0003029108047485,
            "relevance": 2
          },
          {
            "score": 0.9721888899803162,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.29506161263723635
        }
      }
    },
    "thresh_0.130_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8124786019325256,
            "relevance": 5
          },
          {
            "score": 0.8113181591033936,
            "relevance": 2
          },
          {
            "score": 0.81078040599823,
            "relevance": 1
          },
          {
            "score": 0.8104808926582336,
            "relevance": 2
          },
          {
            "score": 0.8096487522125244,
            "relevance": 3
          },
          {
            "score": 0.8096141219139099,
            "relevance": 5
          },
          {
            "score": 0.8092257976531982,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5751544365341659
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.7250844240188599,
            "relevance": 4
          },
          {
            "score": 0.7066197395324707,
            "relevance": 1
          },
          {
            "score": 0.6885937452316284,
            "relevance": 2
          },
          {
            "score": 0.6790380477905273,
            "relevance": 5
          },
          {
            "score": 0.6586529612541199,
            "relevance": 3
          },
          {
            "score": 0.6540755033493042,
            "relevance": 2
          },
          {
            "score": 0.6264151334762573,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.29506161263723635
        }
      }
    },
    "thresh_0.130_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8124786019325256,
            "relevance": 5
          },
          {
            "score": 0.8113181591033936,
            "relevance": 2
          },
          {
            "score": 0.81078040599823,
            "relevance": 1
          },
          {
            "score": 0.8104808926582336,
            "relevance": 2
          },
          {
            "score": 0.8096487522125244,
            "relevance": 3
          },
          {
            "score": 0.8096141219139099,
            "relevance": 5
          },
          {
            "score": 0.8092257976531982,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5751544365341659
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.934810996055603,
            "relevance": 4
          },
          {
            "score": 0.9143023490905762,
            "relevance": 1
          },
          {
            "score": 0.8935914039611816,
            "relevance": 2
          },
          {
            "score": 0.8820887804031372,
            "relevance": 5
          },
          {
            "score": 0.8558418154716492,
            "relevance": 3
          },
          {
            "score": 0.8479849100112915,
            "relevance": 2
          },
          {
            "score": 0.8085829019546509,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.29506161263723635
        }
      }
    },
    "thresh_0.130_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8124786019325256,
            "relevance": 5
          },
          {
            "score": 0.8113181591033936,
            "relevance": 2
          },
          {
            "score": 0.81078040599823,
            "relevance": 1
          },
          {
            "score": 0.8104808926582336,
            "relevance": 2
          },
          {
            "score": 0.8096487522125244,
            "relevance": 3
          },
          {
            "score": 0.8096141219139099,
            "relevance": 5
          },
          {
            "score": 0.8092257976531982,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5751544365341659
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0045911073684692,
            "relevance": 4
          },
          {
            "score": 0.9881317615509033,
            "relevance": 1
          },
          {
            "score": 0.9700850248336792,
            "relevance": 2
          },
          {
            "score": 0.9598860740661621,
            "relevance": 5
          },
          {
            "score": 0.9360658526420593,
            "relevance": 3
          },
          {
            "score": 0.9289770126342773,
            "relevance": 2
          },
          {
            "score": 0.890393853187561,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.29506161263723635
        }
      }
    },
    "thresh_0.130_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.8124786019325256,
            "relevance": 5
          },
          {
            "score": 0.8113181591033936,
            "relevance": 2
          },
          {
            "score": 0.81078040599823,
            "relevance": 1
          },
          {
            "score": 0.8104808926582336,
            "relevance": 2
          },
          {
            "score": 0.8096487522125244,
            "relevance": 3
          },
          {
            "score": 0.8096141219139099,
            "relevance": 5
          },
          {
            "score": 0.8092257976531982,
            "relevance": 4
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.5751544365341659
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0557295083999634,
            "relevance": 4
          },
          {
            "score": 1.0454325675964355,
            "relevance": 1
          },
          {
            "score": 1.0320709943771362,
            "relevance": 2
          },
          {
            "score": 1.0244581699371338,
            "relevance": 5
          },
          {
            "score": 1.0064642429351807,
            "relevance": 3
          },
          {
            "score": 1.001847743988037,
            "relevance": 2
          },
          {
            "score": 0.9694138765335083,
            "relevance": 5
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 0.5,
          "P@3": 0.3333333333333333,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.29506161263723635
        }
      }
    }
  },
  "P11": {
    "thresh_0.090_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7668443918228149,
            "relevance": 2
          },
          {
            "score": 0.7653621435165405,
            "relevance": 5
          },
          {
            "score": 0.764845609664917,
            "relevance": 5
          },
          {
            "score": 0.7648453712463379,
            "relevance": 2
          },
          {
            "score": 0.7638894319534302,
            "relevance": 1
          },
          {
            "score": 0.7614064812660217,
            "relevance": 4
          },
          {
            "score": 0.7607407569885254,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.6555217762471743
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8745542764663696,
            "relevance": 5
          },
          {
            "score": 0.8739322423934937,
            "relevance": 5
          },
          {
            "score": 0.8665711283683777,
            "relevance": 3
          },
          {
            "score": 0.8546428084373474,
            "relevance": 4
          },
          {
            "score": 0.8410541415214539,
            "relevance": 2
          },
          {
            "score": 0.837285041809082,
            "relevance": 1
          },
          {
            "score": 0.8341262936592102,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9311043552494349
        }
      }
    },
    "thresh_0.090_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7668443918228149,
            "relevance": 2
          },
          {
            "score": 0.7653621435165405,
            "relevance": 5
          },
          {
            "score": 0.764845609664917,
            "relevance": 5
          },
          {
            "score": 0.7648453712463379,
            "relevance": 2
          },
          {
            "score": 0.7638894319534302,
            "relevance": 1
          },
          {
            "score": 0.7614064812660217,
            "relevance": 4
          },
          {
            "score": 0.7607407569885254,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.6555217762471743
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9798251390457153,
            "relevance": 5
          },
          {
            "score": 0.9767718315124512,
            "relevance": 5
          },
          {
            "score": 0.9743890166282654,
            "relevance": 3
          },
          {
            "score": 0.969312846660614,
            "relevance": 4
          },
          {
            "score": 0.9656825661659241,
            "relevance": 2
          },
          {
            "score": 0.9624720215797424,
            "relevance": 2
          },
          {
            "score": 0.960842490196228,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9311043552494349
        }
      }
    },
    "thresh_0.090_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7668443918228149,
            "relevance": 2
          },
          {
            "score": 0.7653621435165405,
            "relevance": 5
          },
          {
            "score": 0.764845609664917,
            "relevance": 5
          },
          {
            "score": 0.7648453712463379,
            "relevance": 2
          },
          {
            "score": 0.7638894319534302,
            "relevance": 1
          },
          {
            "score": 0.7614064812660217,
            "relevance": 4
          },
          {
            "score": 0.7607407569885254,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.6555217762471743
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9885760545730591,
            "relevance": 5
          },
          {
            "score": 0.9850776195526123,
            "relevance": 5
          },
          {
            "score": 0.9836223721504211,
            "relevance": 3
          },
          {
            "score": 0.9799302220344543,
            "relevance": 4
          },
          {
            "score": 0.978552520275116,
            "relevance": 2
          },
          {
            "score": 0.9762621521949768,
            "relevance": 2
          },
          {
            "score": 0.973455548286438,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9311043552494349
        }
      }
    },
    "thresh_0.090_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7668443918228149,
            "relevance": 2
          },
          {
            "score": 0.7653621435165405,
            "relevance": 5
          },
          {
            "score": 0.764845609664917,
            "relevance": 5
          },
          {
            "score": 0.7648453712463379,
            "relevance": 2
          },
          {
            "score": 0.7638894319534302,
            "relevance": 1
          },
          {
            "score": 0.7614064812660217,
            "relevance": 4
          },
          {
            "score": 0.7607407569885254,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.6555217762471743
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9909179210662842,
            "relevance": 5
          },
          {
            "score": 0.9872578382492065,
            "relevance": 5
          },
          {
            "score": 0.9861432909965515,
            "relevance": 3
          },
          {
            "score": 0.9829850792884827,
            "relevance": 4
          },
          {
            "score": 0.982538640499115,
            "relevance": 2
          },
          {
            "score": 0.9806496500968933,
            "relevance": 2
          },
          {
            "score": 0.9773318767547607,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9311043552494349
        }
      }
    },
    "thresh_0.100_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7668443918228149,
            "relevance": 2
          },
          {
            "score": 0.7653621435165405,
            "relevance": 5
          },
          {
            "score": 0.764845609664917,
            "relevance": 5
          },
          {
            "score": 0.7648453712463379,
            "relevance": 2
          },
          {
            "score": 0.7638894319534302,
            "relevance": 1
          },
          {
            "score": 0.7614064812660217,
            "relevance": 4
          },
          {
            "score": 0.7607407569885254,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.6555217762471743
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8863126039505005,
            "relevance": 5
          },
          {
            "score": 0.8858462572097778,
            "relevance": 5
          },
          {
            "score": 0.8782346248626709,
            "relevance": 3
          },
          {
            "score": 0.865967869758606,
            "relevance": 4
          },
          {
            "score": 0.8518472909927368,
            "relevance": 2
          },
          {
            "score": 0.8481699228286743,
            "relevance": 1
          },
          {
            "score": 0.8447288274765015,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9311043552494349
        }
      }
    },
    "thresh_0.100_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7668443918228149,
            "relevance": 2
          },
          {
            "score": 0.7653621435165405,
            "relevance": 5
          },
          {
            "score": 0.764845609664917,
            "relevance": 5
          },
          {
            "score": 0.7648453712463379,
            "relevance": 2
          },
          {
            "score": 0.7638894319534302,
            "relevance": 1
          },
          {
            "score": 0.7614064812660217,
            "relevance": 4
          },
          {
            "score": 0.7607407569885254,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.6555217762471743
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9958493709564209,
            "relevance": 5
          },
          {
            "score": 0.9928878545761108,
            "relevance": 5
          },
          {
            "score": 0.9903830289840698,
            "relevance": 3
          },
          {
            "score": 0.98512864112854,
            "relevance": 4
          },
          {
            "score": 0.9811615943908691,
            "relevance": 2
          },
          {
            "score": 0.9778201580047607,
            "relevance": 2
          },
          {
            "score": 0.976394534111023,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9311043552494349
        }
      }
    },
    "thresh_0.100_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7668443918228149,
            "relevance": 2
          },
          {
            "score": 0.7653621435165405,
            "relevance": 5
          },
          {
            "score": 0.764845609664917,
            "relevance": 5
          },
          {
            "score": 0.7648453712463379,
            "relevance": 2
          },
          {
            "score": 0.7638894319534302,
            "relevance": 1
          },
          {
            "score": 0.7614064812660217,
            "relevance": 4
          },
          {
            "score": 0.7607407569885254,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.6555217762471743
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0054179430007935,
            "relevance": 5
          },
          {
            "score": 1.0019723176956177,
            "relevance": 5
          },
          {
            "score": 1.0004761219024658,
            "relevance": 3
          },
          {
            "score": 0.9967248439788818,
            "relevance": 4
          },
          {
            "score": 0.9951988458633423,
            "relevance": 2
          },
          {
            "score": 0.992853045463562,
            "relevance": 2
          },
          {
            "score": 0.9901537895202637,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9311043552494349
        }
      }
    },
    "thresh_0.100_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7668443918228149,
            "relevance": 2
          },
          {
            "score": 0.7653621435165405,
            "relevance": 5
          },
          {
            "score": 0.764845609664917,
            "relevance": 5
          },
          {
            "score": 0.7648453712463379,
            "relevance": 2
          },
          {
            "score": 0.7638894319534302,
            "relevance": 1
          },
          {
            "score": 0.7614064812660217,
            "relevance": 4
          },
          {
            "score": 0.7607407569885254,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.6555217762471743
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0080654621124268,
            "relevance": 5
          },
          {
            "score": 1.0044375658035278,
            "relevance": 5
          },
          {
            "score": 1.00332510471344,
            "relevance": 3
          },
          {
            "score": 1.0001752376556396,
            "relevance": 4
          },
          {
            "score": 0.9996963739395142,
            "relevance": 2
          },
          {
            "score": 0.9978014230728149,
            "relevance": 2
          },
          {
            "score": 0.9945278167724609,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9311043552494349
        }
      }
    },
    "thresh_0.110_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7668443918228149,
            "relevance": 2
          },
          {
            "score": 0.7653621435165405,
            "relevance": 5
          },
          {
            "score": 0.764845609664917,
            "relevance": 5
          },
          {
            "score": 0.7648453712463379,
            "relevance": 2
          },
          {
            "score": 0.7638894319534302,
            "relevance": 1
          },
          {
            "score": 0.7614064812660217,
            "relevance": 4
          },
          {
            "score": 0.7607407569885254,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.6555217762471743
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.8976694345474243,
            "relevance": 5
          },
          {
            "score": 0.8973699808120728,
            "relevance": 5
          },
          {
            "score": 0.8895038366317749,
            "relevance": 3
          },
          {
            "score": 0.8768973350524902,
            "relevance": 4
          },
          {
            "score": 0.8622341156005859,
            "relevance": 2
          },
          {
            "score": 0.8586612939834595,
            "relevance": 1
          },
          {
            "score": 0.8549250960350037,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9311043552494349
        }
      }
    },
    "thresh_0.110_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7668443918228149,
            "relevance": 2
          },
          {
            "score": 0.7653621435165405,
            "relevance": 5
          },
          {
            "score": 0.764845609664917,
            "relevance": 5
          },
          {
            "score": 0.7648453712463379,
            "relevance": 2
          },
          {
            "score": 0.7638894319534302,
            "relevance": 1
          },
          {
            "score": 0.7614064812660217,
            "relevance": 4
          },
          {
            "score": 0.7607407569885254,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.6555217762471743
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.011578917503357,
            "relevance": 5
          },
          {
            "score": 1.0087225437164307,
            "relevance": 5
          },
          {
            "score": 1.0060861110687256,
            "relevance": 3
          },
          {
            "score": 1.0006425380706787,
            "relevance": 4
          },
          {
            "score": 0.996308445930481,
            "relevance": 2
          },
          {
            "score": 0.9928275942802429,
            "relevance": 2
          },
          {
            "score": 0.9916296005249023,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9311043552494349
        }
      }
    },
    "thresh_0.110_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7668443918228149,
            "relevance": 2
          },
          {
            "score": 0.7653621435165405,
            "relevance": 5
          },
          {
            "score": 0.764845609664917,
            "relevance": 5
          },
          {
            "score": 0.7648453712463379,
            "relevance": 2
          },
          {
            "score": 0.7638894319534302,
            "relevance": 1
          },
          {
            "score": 0.7614064812660217,
            "relevance": 4
          },
          {
            "score": 0.7607407569885254,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.6555217762471743
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0220364332199097,
            "relevance": 5
          },
          {
            "score": 1.0186538696289062,
            "relevance": 5
          },
          {
            "score": 1.0171133279800415,
            "relevance": 3
          },
          {
            "score": 1.0133002996444702,
            "relevance": 4
          },
          {
            "score": 1.0116084814071655,
            "relevance": 2
          },
          {
            "score": 1.0092034339904785,
            "relevance": 2
          },
          {
            "score": 1.0066293478012085,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9311043552494349
        }
      }
    },
    "thresh_0.110_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7668443918228149,
            "relevance": 2
          },
          {
            "score": 0.7653621435165405,
            "relevance": 5
          },
          {
            "score": 0.764845609664917,
            "relevance": 5
          },
          {
            "score": 0.7648453712463379,
            "relevance": 2
          },
          {
            "score": 0.7638894319534302,
            "relevance": 1
          },
          {
            "score": 0.7614064812660217,
            "relevance": 4
          },
          {
            "score": 0.7607407569885254,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.6555217762471743
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0250279903411865,
            "relevance": 5
          },
          {
            "score": 1.0214402675628662,
            "relevance": 5
          },
          {
            "score": 1.020331859588623,
            "relevance": 3
          },
          {
            "score": 1.017195701599121,
            "relevance": 4
          },
          {
            "score": 1.0166804790496826,
            "relevance": 2
          },
          {
            "score": 1.0147812366485596,
            "relevance": 2
          },
          {
            "score": 1.011562466621399,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9311043552494349
        }
      }
    },
    "thresh_0.120_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7668443918228149,
            "relevance": 2
          },
          {
            "score": 0.7653621435165405,
            "relevance": 5
          },
          {
            "score": 0.764845609664917,
            "relevance": 5
          },
          {
            "score": 0.7648453712463379,
            "relevance": 2
          },
          {
            "score": 0.7638894319534302,
            "relevance": 1
          },
          {
            "score": 0.7614064812660217,
            "relevance": 4
          },
          {
            "score": 0.7607407569885254,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.6555217762471743
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9085791110992432,
            "relevance": 5
          },
          {
            "score": 0.9084569215774536,
            "relevance": 5
          },
          {
            "score": 0.9003322124481201,
            "relevance": 3
          },
          {
            "score": 0.8873847723007202,
            "relevance": 4
          },
          {
            "score": 0.8721679449081421,
            "relevance": 2
          },
          {
            "score": 0.8687118291854858,
            "relevance": 1
          },
          {
            "score": 0.8646682500839233,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9311043552494349
        }
      }
    },
    "thresh_0.120_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7668443918228149,
            "relevance": 2
          },
          {
            "score": 0.7653621435165405,
            "relevance": 5
          },
          {
            "score": 0.764845609664917,
            "relevance": 5
          },
          {
            "score": 0.7648453712463379,
            "relevance": 2
          },
          {
            "score": 0.7638894319534302,
            "relevance": 1
          },
          {
            "score": 0.7614064812660217,
            "relevance": 4
          },
          {
            "score": 0.7607407569885254,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.6555217762471743
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0269626379013062,
            "relevance": 5
          },
          {
            "score": 1.0242252349853516,
            "relevance": 5
          },
          {
            "score": 1.0214464664459229,
            "relevance": 3
          },
          {
            "score": 1.0157999992370605,
            "relevance": 4
          },
          {
            "score": 1.0110653638839722,
            "relevance": 2
          },
          {
            "score": 1.007434606552124,
            "relevance": 2
          },
          {
            "score": 1.0064899921417236,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9311043552494349
        }
      }
    },
    "thresh_0.120_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7668443918228149,
            "relevance": 2
          },
          {
            "score": 0.7653621435165405,
            "relevance": 5
          },
          {
            "score": 0.764845609664917,
            "relevance": 5
          },
          {
            "score": 0.7648453712463379,
            "relevance": 2
          },
          {
            "score": 0.7638894319534302,
            "relevance": 1
          },
          {
            "score": 0.7614064812660217,
            "relevance": 4
          },
          {
            "score": 0.7607407569885254,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.6555217762471743
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.038385033607483,
            "relevance": 5
          },
          {
            "score": 1.0350767374038696,
            "relevance": 5
          },
          {
            "score": 1.0334872007369995,
            "relevance": 3
          },
          {
            "score": 1.029607892036438,
            "relevance": 4
          },
          {
            "score": 1.0277297496795654,
            "relevance": 2
          },
          {
            "score": 1.025259256362915,
            "relevance": 2
          },
          {
            "score": 1.0228298902511597,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9311043552494349
        }
      }
    },
    "thresh_0.120_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7668443918228149,
            "relevance": 2
          },
          {
            "score": 0.7653621435165405,
            "relevance": 5
          },
          {
            "score": 0.764845609664917,
            "relevance": 5
          },
          {
            "score": 0.7648453712463379,
            "relevance": 2
          },
          {
            "score": 0.7638894319534302,
            "relevance": 1
          },
          {
            "score": 0.7614064812660217,
            "relevance": 4
          },
          {
            "score": 0.7607407569885254,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.6555217762471743
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.041764259338379,
            "relevance": 5
          },
          {
            "score": 1.0382248163223267,
            "relevance": 5
          },
          {
            "score": 1.0371218919754028,
            "relevance": 3
          },
          {
            "score": 1.0340032577514648,
            "relevance": 4
          },
          {
            "score": 1.0334463119506836,
            "relevance": 2
          },
          {
            "score": 1.0315431356430054,
            "relevance": 2
          },
          {
            "score": 1.0283907651901245,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9311043552494349
        }
      }
    },
    "thresh_0.130_steep_5.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7668443918228149,
            "relevance": 2
          },
          {
            "score": 0.7653621435165405,
            "relevance": 5
          },
          {
            "score": 0.764845609664917,
            "relevance": 5
          },
          {
            "score": 0.7648453712463379,
            "relevance": 2
          },
          {
            "score": 0.7638894319534302,
            "relevance": 1
          },
          {
            "score": 0.7614064812660217,
            "relevance": 4
          },
          {
            "score": 0.7607407569885254,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.6555217762471743
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 0.9190632700920105,
            "relevance": 5
          },
          {
            "score": 0.9189977645874023,
            "relevance": 5
          },
          {
            "score": 0.9106758832931519,
            "relevance": 3
          },
          {
            "score": 0.8973844051361084,
            "relevance": 4
          },
          {
            "score": 0.8816040754318237,
            "relevance": 2
          },
          {
            "score": 0.8782764077186584,
            "relevance": 1
          },
          {
            "score": 0.8739132881164551,
            "relevance": 2
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9311043552494349
        }
      }
    },
    "thresh_0.130_steep_10.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7668443918228149,
            "relevance": 2
          },
          {
            "score": 0.7653621435165405,
            "relevance": 5
          },
          {
            "score": 0.764845609664917,
            "relevance": 5
          },
          {
            "score": 0.7648453712463379,
            "relevance": 2
          },
          {
            "score": 0.7638894319534302,
            "relevance": 1
          },
          {
            "score": 0.7614064812660217,
            "relevance": 4
          },
          {
            "score": 0.7607407569885254,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.6555217762471743
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.0419501066207886,
            "relevance": 5
          },
          {
            "score": 1.0393462181091309,
            "relevance": 5
          },
          {
            "score": 1.0364124774932861,
            "relevance": 3
          },
          {
            "score": 1.0305466651916504,
            "relevance": 4
          },
          {
            "score": 1.025374174118042,
            "relevance": 2
          },
          {
            "score": 1.0215814113616943,
            "relevance": 2
          },
          {
            "score": 1.0209169387817383,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9311043552494349
        }
      }
    },
    "thresh_0.130_steep_13.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7668443918228149,
            "relevance": 2
          },
          {
            "score": 0.7653621435165405,
            "relevance": 5
          },
          {
            "score": 0.764845609664917,
            "relevance": 5
          },
          {
            "score": 0.7648453712463379,
            "relevance": 2
          },
          {
            "score": 0.7638894319534302,
            "relevance": 1
          },
          {
            "score": 0.7614064812660217,
            "relevance": 4
          },
          {
            "score": 0.7607407569885254,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.6555217762471743
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.054419755935669,
            "relevance": 5
          },
          {
            "score": 1.0511963367462158,
            "relevance": 5
          },
          {
            "score": 1.0495519638061523,
            "relevance": 3
          },
          {
            "score": 1.0455986261367798,
            "relevance": 4
          },
          {
            "score": 1.0435101985931396,
            "relevance": 2
          },
          {
            "score": 1.0409671068191528,
            "relevance": 2
          },
          {
            "score": 1.038703203201294,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9311043552494349
        }
      }
    },
    "thresh_0.130_steep_17.0": {
      "query_type": "prohibition_NOT",
      "BGE": {
        "ranking": [
          {
            "score": 0.7668443918228149,
            "relevance": 2
          },
          {
            "score": 0.7653621435165405,
            "relevance": 5
          },
          {
            "score": 0.764845609664917,
            "relevance": 5
          },
          {
            "score": 0.7648453712463379,
            "relevance": 2
          },
          {
            "score": 0.7638894319534302,
            "relevance": 1
          },
          {
            "score": 0.7614064812660217,
            "relevance": 4
          },
          {
            "score": 0.7607407569885254,
            "relevance": 3
          }
        ],
        "metrics": {
          "P@1": 0.0,
          "P@2": 0.5,
          "P@3": 0.6666666666666666,
          "P@Full": 0.5714285714285714,
          "MRR": 0.5,
          "NDCG@3": 0.6555217762471743
        }
      },
      "Roberta": {
        "ranking": [
          {
            "score": 1.058234691619873,
            "relevance": 5
          },
          {
            "score": 1.0547516345977783,
            "relevance": 5
          },
          {
            "score": 1.0536545515060425,
            "relevance": 3
          },
          {
            "score": 1.0505560636520386,
            "relevance": 4
          },
          {
            "score": 1.0499491691589355,
            "relevance": 2
          },
          {
            "score": 1.048041582107544,
            "relevance": 2
          },
          {
            "score": 1.0449678897857666,
            "relevance": 1
          }
        ],
        "metrics": {
          "P@1": 1.0,
          "P@2": 1.0,
          "P@3": 1.0,
          "P@Full": 0.5714285714285714,
          "MRR": 1.0,
          "NDCG@3": 0.9311043552494349
        }
      }
    }
  }
}